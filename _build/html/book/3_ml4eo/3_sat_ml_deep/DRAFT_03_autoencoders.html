
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Autoencoders &#8212; SENSE Training Resources</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'book/3_ml4eo/3_sat_ml_deep/DRAFT_03_autoencoders';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/Sense-logo-4_transpCol-1024x431.png" class="logo__image only-light" alt="SENSE Training Resources - Home"/>
    <script>document.write(`<img src="../../../_static/Sense-logo-4_transpCol-1024x431.png" class="logo__image only-dark" alt="SENSE Training Resources - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../intro.html">
                    Welcome to the SENSE tutorials on Earth Observation!
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Book 1 - Python Software Carpentry</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../1_python_zero2hero/book1_overview.html">0 - Overview</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../1_python_zero2hero/1_intro.html">1 - Intro to Python</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../1_python_zero2hero/1_intro/00-Introduction.html">1.0 Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../1_python_zero2hero/1_intro/01-How-to-Run-Python-Code.html">1.1 How to Run Python Code</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../1_python_zero2hero/1_intro/02-Jupyter-Notebook.html">1.2 Jupyter Notebooks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../1_python_zero2hero/1_intro/03-Basic-Python-Syntax.html">1.3 Python Language Syntax</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../1_python_zero2hero/2_python_basics.html">2 - Python Basics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../1_python_zero2hero/2_python_basics/01-Semantics-Variables.html">2.1 Variables and Objects in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../1_python_zero2hero/2_python_basics/02-Semantics-Operators.html">2.2 Basic Python Semantics: Operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../1_python_zero2hero/2_python_basics/03-Built-in-Scalar-Types.html">2.3 Built-In Types: Simple Values</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../1_python_zero2hero/2_python_basics/04-Built-in-Data-Structures.html">2.4 Built-In Data Structures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../1_python_zero2hero/2_python_basics/05-Ex-Try-Python-Basics.html">Exercise</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../1_python_zero2hero/2_python_basics/06-Control-Flow-Statements.html">2.5 Control Flow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../1_python_zero2hero/2_python_basics/07-Defining-Functions.html">2.6 Defining and Using Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../1_python_zero2hero/2_python_basics/09-Modules-and-Packages.html">Modules and Packages</a></li>

</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../1_python_zero2hero/3_data_analysis_visualisation.html">3 - Plotting</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../1_python_zero2hero/3_data_analysis_visualisation/01-Numpy-Intro.html"> Introduction to NumPy</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../1_python_zero2hero/3_data_analysis_visualisation/02-Matplotlib.html">Matplotlib - Intro</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../1_python_zero2hero/3_data_analysis_visualisation/03-Working-with-datetime.html">Working with dates and times</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../1_python_zero2hero/3_data_analysis_visualisation/04-Pandas-Intro.html">Introduction to pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../1_python_zero2hero/3_data_analysis_visualisation/05-Plotting-with-Seaborn.html">Statistical plotting with Seaborn</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Book 2 - GeoPython</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../2_geo_python/book2_overview.html">0 - Overview</a></li>

<li class="toctree-l1 has-children"><a class="reference internal" href="../../2_geo_python/1_spatial_data_tools.html">1 - GeoPython Tools</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../2_geo_python/1_spatial_data_tools/00_intro_to_geospatial_data.html">Introduction to Geospatial Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../2_geo_python/1_spatial_data_tools/cartopy.html">Cartopy</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../2_geo_python/1_spatial_data_tools/geopandas.html">GeoPandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../2_geo_python/1_spatial_data_tools/rasterio.html">Rasterio</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../2_geo_python/1_spatial_data_tools/rioxarray.html">Rioxarray</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../2_geo_python/1_spatial_data_tools/xarray.html">Xarray</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../2_geo_python/1_spatial_data_tools/20-Xarray-NetCDF-Intro.html">Working with NetCDF files</a></li>








</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../2_geo_python/2_eo_data.html">2 - EO data</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../2_geo_python/3_gee_python.html">3 - GEE Python</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../2_geo_python/3_gee_python/0_First_steps.html">Linking Google Colab to your GitHub page</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../2_geo_python/3_gee_python/1_Open_and_display.html">Google Earth Engine: JavaScript, but Python</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../2_geo_python/3_gee_python/2_Time_series.html">ImageCollection</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Book 3 - Machine Learning for EO</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../book3_overview.html">0 - Overview</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../2_sat_ml_intro.html">2 - Classical ML with satellite data</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../2_sat_ml_intro/1_linear_regression.html">Practical 1: Linear Regression</a></li>





<li class="toctree-l2"><a class="reference internal" href="../2_sat_ml_intro/2_classification.html">Practical 2: Classification</a></li>


<li class="toctree-l2"><a class="reference internal" href="../2_sat_ml_intro/3_kalman_filter.html">Practical 3: Kalman Filter</a></li>


</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../3_sat_ml_deep.html">3 - Deep Learning with PyTorch</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="00_intro.html">Satellite image deep learning with PyTorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_segmentation_unet.html">Semantic segmentation of Aerial Imaginary with U-Net-like architectures</a></li>

</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../4_embeddings.html">4 - Embeddings</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../4_embeddings/notebooks/1a_Use_PCA_analysis_to_study_tile_embeddings.html">Use PCA analysis on tile embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../4_embeddings/notebooks/1b_Exploring_embedding_space_with_clustering_methods.html">How are the study tiles clustered in the embedding space?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../4_embeddings/notebooks/2_Working_with_your_own_data.html">Working with your own input data</a></li>

</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/executablebooks/jupyter-book/blob/master/docs/book/3_ml4eo/3_sat_ml_deep/DRAFT_03_autoencoders.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fbook/3_ml4eo/3_sat_ml_deep/DRAFT_03_autoencoders.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/book/3_ml4eo/3_sat_ml_deep/DRAFT_03_autoencoders.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Autoencoders</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Autoencoders</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#table-of-contents">Table of contents<font><a class="anchor" id="top"></a></font></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#download-data">Download data</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#preparing-the-data">Preparing the data</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#training-the-autoencoder">Training the autoencoder</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#variational-autoencoder">Variational Autoencoder</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#semi-supervised-learning">Semi-supervised learning</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#autoencoder-treasure-hunt">Autoencoder treasure hunt</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#pushing-autoencoders-further">Pushing autoencoders further</a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="autoencoders">
<h1>Autoencoders<a class="headerlink" href="#autoencoders" title="Link to this heading">#</a></h1>
<section id="table-of-contents">
<h2>Table of contents<font><a class='anchor' id='top'></a><a class="headerlink" href="#table-of-contents" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="#intro"><span class="xref myst">Introduction</span></a></p></li>
<li><p><a class="reference internal" href="#download"><span class="xref myst">Downloading the dataset</span></a></p></li>
<li><p><a class="reference internal" href="#preparing"><span class="xref myst">Preparing the dataset</span></a></p></li>
<li><p><a class="reference internal" href="#autoencoder"><span class="xref myst">Training the autoencoder</span></a></p></li>
<li><p><a class="reference internal" href="#variationalautoencoder"><span class="xref myst">Training the variational autoencoder</span></a></p></li>
<li><p><a class="reference internal" href="#ssl"><span class="xref myst">Semi-supervised learning</span></a></p></li>
<li><p><a class="reference internal" href="#treasurehunt"><span class="xref myst">Treasure hunt</span></a></p></li>
<li><p><a class="reference internal" href="#stretchgoals"><span class="xref myst">Further exercises</span></a></p></li>
</ul>
<p><a name="intro"></a></p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">#</a></h1>
<p>In this training, we will use autoencoders, a type of artificial neural network, to analyse and extract meaningful information from satellite imagery covering the landscapes of the UK. Autoencoders are particularly useful for tasks like image denoising, feature extraction, and even generation of new images.</p>
<p>Usually in a conventional neural network, one tries to predict a target vector <span class="math notranslate nohighlight">\(\bf{y}\)</span> from input vectors <span class="math notranslate nohighlight">\(\bf{x}\)</span>. In an auto-encoder network, one tries to predict <span class="math notranslate nohighlight">\(\bf{x}\)</span> from <span class="math notranslate nohighlight">\(\bf{x}\)</span>. It is trivial to learn a mapping from <span class="math notranslate nohighlight">\(\bf{x}\)</span> to <span class="math notranslate nohighlight">\(\bf{x}\)</span> if the network has no constraints, but if the network is constrained the learning process becomes more interesting.</p>
<p>By limiting the amount of information that can flow through the network, autoencoders can learn the most important attributes of the input data and how to best reconstruct the original input from an “encoded” state. Ideally, this encoding will learn and describe latent attributes of the input data.</p>
<p><img alt="image.png" src="data:image/png;base64,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" /></p>
<p>An autoencoder consists of some main components:</p>
<ol class="arabic simple">
<li><p>A section of the network compresses the input (the <strong>encoder</strong>)</p></li>
<li><p>Another section reverses the process (the <strong>decoder</strong>)</p></li>
</ol>
<p>In the middle of these sections, there’s a crucial component: a <strong>bottleneck</strong>.</p>
<p>The bottleneck forces the network to simplify the input data, compressing it down into a simpler, streamlined form known as a ‘latent space’. Anything that’s not essential, goes away.</p>
<p>In the end, the bottleneck gives us a compact representation of the dataset.
This is the main goal of the autoencoder - to create a good, compressed representation of the data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="c1"># Check if GPU is available</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="n">device</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>device(type=&#39;cuda&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="c1"># Check if CUDA (GPU support) is available</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="c1"># Get the number of available GPUs</span>
    <span class="n">gpus</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span>
    
    <span class="c1"># Set memory growth or other configurations for each GPU</span>
    <span class="k">for</span> <span class="n">gpu</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">gpus</span><span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_per_process_memory_fraction</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">gpu</span><span class="p">)</span>  <span class="c1"># Similar to memory growth in TensorFlow</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No GPUs available.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check if CUDA (GPU support) is available</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Can&#39;t find a GPU to use. Are you on the right kernel?</span><span class="se">\n</span><span class="s2">(Go to Runtime &gt; Change runtime type)&quot;</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GPU ready to use. :)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GPU ready to use. :)
</pre></div>
</div>
</div>
</div>
<p><a name="download"></a></p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="download-data">
<h1>Download data<a class="headerlink" href="#download-data" title="Link to this heading">#</a></h1>
<p>First, we download and unzip the dataset. This consists of red-green-blue Sentinel-2 images over the UK, with an associated .csv file that contains some metadata.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># the ! means we can use command line linux commands</span>
<span class="o">!</span>wget<span class="w"> </span>https://gws-access.jasmin.ac.uk/public/sensecdt/eesjb/sense_ae.zip
<span class="o">!</span>unzip<span class="w"> </span>sense_ae.zip
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--2025-03-18 10:29:52--  https://gws-access.jasmin.ac.uk/public/sensecdt/eesjb/sense_ae.zip
Resolving gws-access.jasmin.ac.uk (gws-access.jasmin.ac.uk)... 130.246.128.97
Connecting to gws-access.jasmin.ac.uk (gws-access.jasmin.ac.uk)|130.246.128.97|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 210219517 (200M) [application/zip]
Saving to: ‘sense_ae.zip’

sense_ae.zip        100%[===================&gt;] 200.48M   145MB/s    in 1.4s    

2025-03-18 10:30:00 (145 MB/s) - ‘sense_ae.zip’ saved [210219517/210219517]

Archive:  sense_ae.zip
   creating: sense_ae_data/
  inflating: sense_ae_data/sense_ae_metadata.csv  
   creating: sense_ae_data/leeds/
  inflating: sense_ae_data/leeds/image_2020_leeds_6_5401_7575.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_8527_6325.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_7230_9067.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_7474_7618.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10794_7144.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_9978_2612.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9639_1124.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8543_1121.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2339_7255.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3592_9311.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_359_2956.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5600_6135.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7352_6263.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7815_3958.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8643_10149.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4460_9334.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5008_9807.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7432_6890.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2521_820.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_5_9669_4985.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_5_8200_9257.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_5_6136_5217.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_5_10633_4790.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_5_8191_2722.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6634_9000.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1755_303.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2949_6618.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8366_5991.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3563_6633.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3678_9025.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1982_10000.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9216_5097.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3503_8897.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2004_1687.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8341_10392.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9470_7495.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8248_3699.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_377_10288.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_41_2061.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3720_8492.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9166_2974.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4522_9129.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5281_1945.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3182_1247.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10169_7358.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8382_10043.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_835_10031.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7548_1571.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4949_8233.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7408_911.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9813_1548.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4203_5826.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1413_7927.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6195_5515.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_505_7941.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8635_4864.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3973_2090.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1102_8541.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4734_9073.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1276_4041.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10334_8722.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9909_3848.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7868_2482.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8938_3508.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1862_9272.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5759_696.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9426_6711.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8680_6186.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6592_8637.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5847_6172.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3066_5567.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4339_7616.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8184_340.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6986_2664.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9286_10053.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_270_3172.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5056_5491.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7670_481.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1479_1136.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7828_10461.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9888_9456.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4615_1139.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1897_904.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7795_10532.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3104_10273.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6244_7782.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3077_2953.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6641_1927.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7131_6818.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5008_5447.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_920_8550.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5416_3897.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6464_7845.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9651_9720.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_914_870.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1054_2010.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_589_4839.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5636_3810.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6173_9199.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5026_1992.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6384_9025.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10147_239.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3762_8524.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5573_7459.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5550_2505.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_597_10004.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6902_8410.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6713_7427.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1390_304.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8030_4118.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2761_6138.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_192_8092.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_741_9735.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3482_5673.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6078_7000.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5033_8163.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1474_8072.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2999_3961.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4469_1857.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2533_7610.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1026_3020.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10127_10062.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4003_6679.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10845_6303.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6395_1584.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5686_8084.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4817_8463.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4990_10545.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_938_7735.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5643_5953.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2963_9714.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10580_4392.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10314_6658.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2736_1584.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4604_10031.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7775_8840.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4115_6802.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7068_612.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6766_9896.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1703_2344.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3202_8748.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10887_10390.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2310_81.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8494_839.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7413_7632.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4392_1439.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10913_6087.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1916_4104.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3938_2605.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3093_9909.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5130_10002.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3448_3343.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7539_10621.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3168_7581.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4867_8753.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8158_3147.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1385_5429.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8294_6505.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_609_5709.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9971_2566.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10135_7412.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10046_2142.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2690_4461.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2271_5931.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5634_1482.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7351_803.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1669_9918.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2804_4422.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7857_10081.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5741_4598.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4667_7812.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_373_9879.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10002_5980.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_96_892.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9255_10659.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1375_2860.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5682_5502.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6856_2870.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9303_2215.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1629_5409.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4009_10835.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7807_5267.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9813_1528.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10561_7046.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6792_7594.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7199_7355.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7636_910.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_627_8240.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9719_1187.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6893_5443.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5377_8727.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3150_2791.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4256_10626.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5094_6527.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6413_4230.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6953_7202.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_572_5555.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8785_1473.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_913_658.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1094_9665.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1698_10883.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9133_2178.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3406_690.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5949_4837.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5692_6756.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7957_3865.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9785_1259.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3600_3756.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2208_4217.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5189_9613.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3214_10332.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8503_7717.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9132_6511.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7027_5422.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1770_7452.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2413_6966.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6957_7050.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7116_4906.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10119_8847.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7154_7407.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7983_8828.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4414_10874.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4996_9957.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4687_4764.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5647_8576.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9217_6601.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1664_8121.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7797_6258.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1540_9243.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1122_7950.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9021_6349.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8891_5854.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4428_9019.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8101_8980.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2112_3706.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10145_5260.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9087_2615.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4848_8803.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9821_10564.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4859_10152.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2694_4251.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3993_745.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1515_8962.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10825_1014.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2225_9891.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4353_7284.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7585_5975.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7453_3618.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8699_5470.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5047_1926.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3125_7408.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1092_6518.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_905_7688.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8464_10082.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4444_9453.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3566_9018.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6392_5955.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7005_7719.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5596_4720.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2064_8455.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9413_6488.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7309_9123.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9465_7202.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3306_6188.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9799_7979.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1501_6659.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7409_3413.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5279_793.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3914_504.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6160_9305.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1240_298.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2784_6547.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2729_10373.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8285_860.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7112_5814.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7291_8109.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7427_2378.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7286_4062.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3963_351.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3367_3623.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3453_4509.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2227_2338.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7504_8474.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2024_10105.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1621_3758.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_200_7741.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7809_8094.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_272_654.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10448_6423.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9142_2600.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8957_8402.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8722_4883.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3235_8023.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2924_4114.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9843_8546.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4860_5628.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_925_10852.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_625_1184.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_122_919.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7152_1418.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7671_1848.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7640_3214.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6101_8098.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5534_6314.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3621_8310.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8248_7787.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1825_6605.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7362_5698.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10180_6328.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4091_6336.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3007_3781.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4728_8508.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7671_4648.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10282_5769.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8254_7569.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2388_4841.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1380_4194.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3660_7192.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8685_708.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9719_1188.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4676_7995.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6265_2864.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4316_1616.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10172_5279.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10781_7561.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8599_479.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9832_1115.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6483_10053.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7252_5038.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2868_2737.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10726_10469.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6922_8485.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9386_4960.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1494_9590.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5909_4664.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5144_8804.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4541_8099.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_434_4057.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2513_5309.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2794_7510.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1019_3088.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1477_3961.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5903_3659.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10877_2877.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4850_3311.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1164_6934.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2507_5455.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9998_2796.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7850_2369.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7931_3615.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4749_7001.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1594_5695.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5671_9633.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2823_1113.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10111_6337.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1515_2942.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1104_6996.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8697_4146.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10571_10255.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1811_10143.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8621_6507.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8214_7491.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9608_5787.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4479_9180.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4302_997.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4126_3876.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9060_8514.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9347_5246.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5045_6334.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2636_1735.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9595_4531.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4651_10825.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1880_5547.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2757_7566.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3089_6182.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7383_5624.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10341_7794.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7585_4468.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9153_7827.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2346_1212.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1203_7550.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3636_2573.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7343_4773.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1309_7131.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_113_5342.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8824_1643.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7645_10589.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10116_6122.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_305_2868.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2915_1487.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9217_7681.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6140_8632.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5877_10277.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3160_3558.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5456_2201.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_880_10145.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3545_9848.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2216_3761.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10895_10034.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1467_7495.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_289_780.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4732_5571.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1933_4455.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_633_9077.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6725_6922.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8096_5911.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3705_3191.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_4944_10073.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_5758_9904.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_8260_3955.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_7192_3528.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10141_6247.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_9553_4374.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_5108_8584.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_5791_9650.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10073_9230.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10432_9676.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_8170_4437.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_9931_3775.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10075_423.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_7810_3914.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_7196_2900.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10202_637.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_9884_4682.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_5592_6540.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10468_4767.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_5_7212_2963.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_4_7344_3960.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_4_4917_9623.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_4_8243_6314.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_4_6358_9639.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_4_7414_7061.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_4_5396_9674.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_4_5858_9520.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_4_8112_280.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_4_10173_1502.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_4_10745_1146.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_4_7303_10276.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_4_7230_10572.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2494_7514.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4187_6243.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2778_10402.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2804_2696.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2145_8049.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6131_37.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2617_4961.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10838_10605.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7166_410.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1428_2895.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8328_3047.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8289_2901.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2406_6058.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10214_2854.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3391_570.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8892_3228.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5128_2848.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3489_6598.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5933_6763.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3762_2882.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_525_8980.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1017_1549.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8195_10259.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4931_5457.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10104_1172.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10251_1780.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6576_259.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1450_4620.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9759_7160.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1239_637.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6410_6669.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6290_4414.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1556_5071.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7092_6192.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8260_6828.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9465_1126.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3958_9737.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7576_2255.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6680_10142.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1851_9233.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10487_1771.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10857_3550.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7148_9537.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10388_9089.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3514_213.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9565_3099.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2776_8514.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5203_5373.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8866_10823.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6985_1317.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5469_10551.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9300_9215.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1811_8912.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9930_3155.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1440_10138.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4559_5174.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_57_7158.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6919_4517.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2449_920.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3921_4795.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_928_8729.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5423_2658.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2457_6922.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4535_3037.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8026_2627.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2951_2735.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4313_9824.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1872_7948.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9543_7959.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_656_551.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7072_8630.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8074_5546.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6885_2850.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7416_9443.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1825_2917.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4420_9570.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3523_2078.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6799_6496.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6806_7911.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4767_3326.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10073_1601.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9533_4177.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7345_504.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_884_3559.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2371_4107.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1224_6302.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7756_9068.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4281_5093.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5387_3122.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3572_2960.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7587_1259.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6579_3387.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4406_5415.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6206_7482.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_244_4420.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5536_9604.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2541_2964.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1054_4358.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7273_7686.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8275_10738.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1873_3799.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7312_5014.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8763_9234.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4324_721.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8554_407.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5248_5970.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8700_10190.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10311_10171.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8818_1949.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3547_363.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7561_5232.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_613_3270.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7507_3173.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10057_2178.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2837_9764.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7791_5787.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2572_7649.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1421_5189.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9735_10910.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2366_9513.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3573_1292.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2065_9226.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4983_6629.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7902_6622.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5726_5572.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7036_3486.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4220_9029.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1610_6709.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1230_9798.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2149_6285.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9784_10752.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7941_1871.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10556_2006.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10176_1186.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9497_2155.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4730_6372.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4702_4804.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10000_2330.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3884_2531.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9092_7795.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4233_4100.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6615_3100.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_622_3645.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4588_99.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_677_7738.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10357_6991.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8601_1471.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2804_4034.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4152_5900.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9718_7080.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5838_3729.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2797_1619.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4854_4205.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5498_6111.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6779_3883.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9841_4489.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8360_2579.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2342_4464.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5630_1138.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7457_2033.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2608_4008.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1358_4316.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5859_9056.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8638_8518.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2611_2081.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5107_5569.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8304_1228.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1725_19.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3268_6073.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6849_3756.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_339_3987.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6091_2486.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5224_9335.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3599_5393.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8051_4706.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7517_10464.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5551_2639.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8206_1159.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6266_1544.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7107_6280.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9589_152.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_799_996.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_552_5533.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8364_9762.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_61_1491.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_214_251.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4126_3212.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5583_1099.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_462_4163.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5695_7962.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3321_1472.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9476_3957.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5809_3925.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6585_7415.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4428_6706.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1850_10616.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6988_7584.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8607_5357.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10519_5946.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3311_9193.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6333_10792.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6590_10683.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9752_541.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5814_10169.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3894_2770.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4704_10868.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_730_6885.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2961_6182.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1516_7065.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8548_1166.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6636_180.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4399_9583.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10369_10125.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2421_5944.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_240_6049.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2191_808.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9560_8904.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6752_6186.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6124_4199.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6049_9344.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9076_10621.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5088_5545.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2758_4024.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5039_7895.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8676_8148.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6069_9755.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4235_1361.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3909_7306.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8325_2293.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_775_1099.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7919_5869.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6428_6600.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3138_10540.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_922_10510.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7576_520.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_601_8312.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6344_10262.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4609_2107.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10412_6329.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6299_5683.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5998_3710.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6842_3176.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8221_4.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8290_3008.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4227_5298.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_163_1032.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_915_10022.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5165_10450.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1307_3087.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2311_7358.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10072_10008.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1740_8496.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7788_7991.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10385_2640.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8404_5928.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10890_10097.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8858_9436.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6694_9768.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_863_2671.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2547_10687.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2780_3497.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9693_6805.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9032_6096.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2870_6805.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7860_9402.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1774_8909.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1871_1930.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9976_2017.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8803_2341.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4073_838.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2280_2665.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6221_4806.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9938_6611.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4028_8712.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3535_827.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8289_4054.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6390_810.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8370_9296.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10362_7136.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3169_3509.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4005_8176.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4613_1041.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3678_7625.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2344_9971.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3912_3811.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6515_7818.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5625_10331.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7822_8654.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6994_6036.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_571_10893.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2697_8926.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2323_8500.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9077_7862.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1305_4690.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8844_7741.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5085_8348.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_63_5598.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6533_6804.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_151_1629.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9226_4401.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8399_8556.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9622_1608.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3748_2896.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_880_8536.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1383_10226.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4922_1490.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1026_9788.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10364_7027.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_625_4488.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_544_10722.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6691_10527.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8466_8401.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5808_399.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8513_10735.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7271_1886.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7698_6547.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6240_2088.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2810_4277.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3813_1600.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3614_0.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5649_2718.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8356_2102.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6094_2513.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3893_6977.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5007_10336.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4929_2800.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8092_9763.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3421_171.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8153_9366.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4065_7191.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1_9246.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6615_464.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1355_371.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4851_588.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5432_4197.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9853_4726.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2633_6936.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7815_9787.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7191_9069.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2163_4962.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2036_358.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6936_10818.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10494_4049.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8955_4543.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6843_7702.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_550_9361.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6658_3666.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3533_6102.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4304_10254.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6646_5250.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_965_1415.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1688_870.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8917_141.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6785_9720.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2198_5390.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7985_4815.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_654_3782.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4580_8042.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1624_5879.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5060_3964.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3942_9528.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8148_7045.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8427_3272.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9207_5544.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10006_4534.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4696_3294.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6857_5232.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7056_8237.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1295_3635.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4830_7080.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10502_1695.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2044_2108.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7463_3911.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9531_7494.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7517_6316.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6388_5063.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1988_2873.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9482_3400.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5767_8991.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6512_7274.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6712_2257.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2578_3889.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4681_7793.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3439_6855.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7300_7203.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7395_7262.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2318_6581.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6350_1622.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4792_3561.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9676_2632.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4345_8446.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_346_8500.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3074_3491.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9815_307.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4769_7140.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9614_6408.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9471_2847.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6144_9451.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5384_2676.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1974_4058.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10263_10148.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2754_7877.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7867_6923.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7767_6437.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8847_316.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8194_8784.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3403_7595.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4532_10565.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9647_93.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7899_4419.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7222_9474.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3358_9188.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2358_8496.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4720_1897.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8024_6327.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2066_10830.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3198_5963.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_211_3765.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7978_846.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7469_10758.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9693_9694.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4299_4934.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9188_4349.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4925_4664.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7417_10379.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5257_7872.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3999_929.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10503_3748.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_6206_2854.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10427_4710.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4534_3257.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_6743_2867.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2467_9957.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3179_9109.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1990_7730.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7397_206.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8532_10567.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4778_9103.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3155_4937.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1552_5528.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5565_3695.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1232_7968.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4074_7998.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4605_133.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10081_1066.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1571_10479.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8530_9463.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1999_7644.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9445_1220.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9181_2223.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2387_8196.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10001_5685.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10627_5840.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2421_7767.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3391_8839.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3425_6452.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10062_1305.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9806_10753.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3920_3644.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10767_10360.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_6484_2227.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1735_7110.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_588_8886.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2121_4575.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3880_1095.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1326_6452.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3918_9698.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2981_9327.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3912_7667.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_339_2741.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1094_6266.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5563_1420.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9108_9355.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2065_10327.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_619_10412.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9047_5785.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10026_7799.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10465_3504.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1613_10212.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3526_2846.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3253_10626.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10115_3727.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8283_5559.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10438_186.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8563_1815.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3494_1611.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2938_5705.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4956_6296.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8861_9614.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5741_7997.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9271_9166.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2224_7276.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9241_2549.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8640_10097.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4500_5894.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10450_2407.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3638_10385.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3216_10234.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10527_5112.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7115_797.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4566_9017.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8547_477.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8172_9923.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9016_10889.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_6022_2216.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7544_6720.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2780_2788.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9363_6214.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8951_311.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_895_5889.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2128_7513.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7136_1601.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10169_902.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8922_5182.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2798_5723.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4327_3631.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5141_6906.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_16_6281.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_429_8339.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_352_8112.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_6960_938.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_6563_1370.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9019_10685.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1846_5123.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1153_3085.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4094_1436.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10718_2909.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1604_8055.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_221_9973.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8954_856.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8226_7637.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10808_229.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2577_10700.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_378_3824.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2916_10346.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4782_3938.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_6823_206.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10063_6346.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2477_4889.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9220_4325.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7251_1221.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5171_2702.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10742_4318.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8680_572.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2570_8275.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10717_5174.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9294_469.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9420_1033.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_234_3042.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1485_5431.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8162_8547.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9544_3514.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10159_789.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9376_1882.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10131_1742.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9748_3395.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10241_2042.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5463_2795.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3172_9830.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4476_5866.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_631_3105.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2361_4018.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10297_3751.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_5_6670_4570.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10776_8253.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_7061_6820.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_8269_5150.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2311_5376.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7252_1118.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2618_643.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8368_9462.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10781_7348.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_212_1203.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7853_10575.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_7474_7914.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3298_6398.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1972_3312.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1194_7561.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7729_3524.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3179_5675.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8667_4943.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6151_2815.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8033_10029.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6618_4598.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3502_1061.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8891_8582.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5328_4964.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4700_5740.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6611_10362.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3236_10564.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9327_10277.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1950_124.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10112_4694.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_6_9786_3942.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_6_8310_3908.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_6_867_7496.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1146_4927.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10679_612.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2915_4383.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6017_5880.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4079_10229.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9274_800.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8039_9277.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7844_7948.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9138_3763.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2459_9727.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4279_4911.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3785_9762.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10662_865.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5606_5685.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3633_10903.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3002_6062.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1440_3670.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8041_7522.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9377_1017.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3693_5688.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7659_9270.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4049_455.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5193_6035.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7617_3114.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6043_6837.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10438_23.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9959_9370.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4807_2818.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2514_7651.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9178_2632.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10739_2941.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_144_6077.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4514_2503.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3307_750.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9270_244.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7652_1552.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8524_1529.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2961_4871.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6542_2692.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2674_10711.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_44_4650.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9057_1128.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_632_5967.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2219_5158.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_86_9912.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6321_9959.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8845_7917.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1850_2739.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8171_7233.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4387_10723.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5391_10148.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9876_2069.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3727_548.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10187_10142.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7616_1492.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8613_319.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5016_9278.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4644_1793.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1026_7001.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10524_3463.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6848_2201.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4263_2424.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5338_3658.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4210_5303.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1111_7035.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4825_8183.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_233_7114.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4665_8838.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_255_8594.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9763_3033.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7617_3141.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7586_9924.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2892_4269.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10842_896.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_154_1817.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8421_8505.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5521_970.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1928_2143.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1135_2107.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10356_6488.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7222_10370.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7123_7966.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9619_9039.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4703_10405.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4995_3648.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8758_8533.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6889_10785.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7717_4110.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2726_5902.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2579_10511.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2233_916.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2240_2865.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2687_9737.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6022_7982.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4893_9855.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10728_10139.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2773_5954.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9935_5390.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1337_8572.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9114_2920.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1799_8802.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10032_5499.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1782_8911.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3983_550.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7781_6510.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_453_7776.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8988_5561.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10541_7090.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_435_1786.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8011_5699.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2601_3007.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6263_198.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10401_3774.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8366_10249.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1781_7416.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6016_2183.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2127_2876.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2316_9644.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3987_2786.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_897_9255.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8403_7971.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3304_3841.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6913_1292.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1849_3382.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5147_5028.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3440_6497.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8240_7760.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2962_7250.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5711_3165.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4236_1316.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3273_4820.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9398_6716.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2387_4133.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8830_6765.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4595_2625.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7322_127.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3590_10628.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1966_1336.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6072_8779.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2758_3810.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3620_6398.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3464_4908.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_271_8839.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7673_4946.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6069_3861.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7708_1274.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7658_8056.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_320_10584.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1174_3704.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2398_7375.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8942_3095.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3278_1531.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4897_5.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9493_4988.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2290_5623.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6370_9389.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_185_622.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8117_5795.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1884_9174.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1169_4691.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4247_502.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1136_5399.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5605_3866.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2280_5324.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7836_2107.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6758_4854.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3605_8117.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7780_7485.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7209_5881.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4051_7111.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8055_1739.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4717_9327.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5863_1583.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5903_10116.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8774_1295.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9430_1574.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10643_5369.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_318_8091.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9985_4782.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8173_4136.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4731_3753.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_658_7827.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4796_4191.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9163_3330.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9402_642.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1249_3460.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6182_6879.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5666_10129.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9757_581.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1407_9764.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10362_9516.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7172_10370.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4531_4460.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2322_10065.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10109_10474.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_268_6843.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4567_10900.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5195_224.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5401_9402.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6707_1822.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1026_7891.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7925_10218.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9235_6779.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3531_9575.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7312_2170.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_854_3754.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7498_1327.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9692_6410.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4531_6615.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10061_3058.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1038_463.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6469_5717.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5615_2002.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3553_7173.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3754_5712.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9342_5158.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3315_1479.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2705_5550.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6765_9306.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3659_10876.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3017_4988.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_383_7394.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6008_8524.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_25_2313.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8820_9800.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4118_6606.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10866_2384.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8006_10678.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8253_7852.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1961_8969.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4614_862.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5468_6548.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8334_2455.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10047_5089.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2947_9091.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9712_1344.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2316_1577.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6225_8643.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9046_3547.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8512_1313.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2070_2388.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2143_2766.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2802_490.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9669_8131.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2377_8068.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8376_2081.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8406_9469.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2699_858.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3350_1477.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_630_9838.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_562_7282.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8078_4727.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3399_1347.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_181_2601.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8905_8887.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5481_7219.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7827_5734.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3762_2747.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9786_7928.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4264_7158.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3209_6989.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3704_408.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5970_10451.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_343_2004.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4251_8868.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8975_2905.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10641_4045.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_249_146.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7861_6954.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7323_6001.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10336_1577.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_470_9666.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1863_9824.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_395_5241.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6964_5655.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10131_4458.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5880_2186.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8181_3244.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2142_3870.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6519_2004.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1764_2517.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10801_8101.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2211_8847.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9354_3280.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1506_5329.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7252_1060.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5136_6342.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4942_2132.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1024_7046.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10031_8852.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4126_5743.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10800_7259.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8382_5751.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8210_6788.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8115_1851.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1755_5532.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9752_7811.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_458_6651.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2631_1892.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2199_10483.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1541_7321.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3353_2240.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7838_9173.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10226_5210.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3125_4020.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3899_3623.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7293_7261.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5758_9210.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10317_9083.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_645_9018.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7741_8113.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2480_9941.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5725_4510.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10229_7032.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10793_6870.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8479_2989.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2858_4465.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3271_7120.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7027_2530.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5950_10210.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1066_10294.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2990_2963.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8824_1060.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6009_9374.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4288_10138.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_204_9204.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9798_7695.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_367_2162.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7770_8326.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8898_2805.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1805_1237.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2389_754.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8219_1231.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10890_2869.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8610_8736.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1771_439.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8922_10570.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4034_4987.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1347_10028.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1369_2726.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6495_6563.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7904_9919.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6603_3366.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9458_10103.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8934_8235.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7721_3893.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7515_9793.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6509_7481.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9448_4196.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10768_10343.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3964_858.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2070_4767.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5040_7775.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3794_1830.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6514_7291.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2921_7423.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8878_10525.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6394_9698.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1331_10696.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10813_4296.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2505_3710.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5660_6065.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1383_3441.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1401_8948.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3800_1580.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3796_8761.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1846_4244.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7905_3247.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1495_8286.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_18_9818.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7443_178.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1084_2305.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10856_1761.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1841_7757.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4743_3187.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8730_4384.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7314_6786.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4337_4947.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2369_35.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2735_4640.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3353_6463.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5838_4652.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6056_2033.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4459_9057.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2426_1785.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6189_6269.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3374_3741.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2268_4159.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6472_7107.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1358_8209.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10345_6195.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4204_2157.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7620_3406.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3987_1042.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_112_4652.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6823_4067.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8969_2068.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_551_2823.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_46_936.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4342_4655.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6508_9842.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8611_2655.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10575_7466.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_5177_8722.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_9320_4390.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_5605_6832.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10533_9627.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_6234_8419.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10364_3070.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10493_7980.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_6623_6454.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_7608_5314.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_8428_4413.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_9255_3653.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_8932_4745.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_6490_2731.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_8467_4848.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_7592_5512.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_9703_5054.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10347_4012.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_9658_5480.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_5711_9968.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_4_8755_658.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_4_9556_3811.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_4_7691_7081.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_4_5251_8485.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7816_2046.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2656_6127.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2688_4811.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7977_7207.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3199_9026.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10467_2336.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8266_3105.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1532_5151.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2250_6341.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2415_37.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4135_10567.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4669_264.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6071_3150.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5163_3018.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9096_464.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3094_364.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1069_6849.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3509_7175.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8322_10738.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5494_7534.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10839_6876.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_998_744.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5185_7349.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8153_6662.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3296_489.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1223_8541.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1036_135.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1354_2558.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4837_3072.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10254_6063.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3801_3046.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1239_4801.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8791_8878.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8657_10112.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_564_8623.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5957_161.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1435_5197.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10402_1185.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1371_2581.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9113_9580.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9771_9255.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5236_2251.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_422_4733.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2096_2188.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9107_1033.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6512_7535.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9842_2764.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9136_9308.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7846_7732.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4535_9087.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1031_701.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3113_2641.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6099_7842.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8532_6141.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6527_9378.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9852_1828.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3817_940.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6942_1593.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5037_4067.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5299_9424.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_551_1388.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4567_228.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_905_2540.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3200_3253.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7676_935.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4351_10820.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10573_9043.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8259_10367.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4283_6652.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8801_10499.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8865_2538.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8079_529.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2365_210.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10400_3422.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8719_7723.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10404_7434.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10689_977.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9657_7394.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10372_2230.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7268_1025.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4706_3302.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6780_9188.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4193_1929.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7816_8873.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_928_434.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4895_6513.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9347_5690.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_381_6873.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10190_8219.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10562_1931.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2799_3201.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5387_10534.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4573_4514.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3183_3062.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5954_6402.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1080_1197.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3200_6513.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6317_7424.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1474_6893.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_164_488.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8535_4856.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2021_6992.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_671_2919.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3137_5490.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_50_4747.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6177_1473.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1589_9964.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3914_7462.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10396_7159.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2491_1010.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7545_3259.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1196_8177.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3568_2578.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6769_10857.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3232_4461.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_679_457.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8093_953.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_820_10183.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7990_3068.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10567_8685.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1304_4420.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6750_2588.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5826_3659.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7953_10138.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3593_8747.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7050_5595.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7422_1760.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4521_9986.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7881_9153.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2964_6196.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9524_7600.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1742_5379.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6402_2081.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8658_6750.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2972_9400.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9335_9878.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9578_3043.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6334_7495.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8662_207.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4085_3823.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4198_10491.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8769_4468.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_303_4131.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8902_5934.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6699_8155.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7710_2584.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10728_524.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8289_5653.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5432_9493.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7021_8745.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10688_8925.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6991_1667.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10355_10567.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7617_6519.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9501_1550.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3640_9855.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4778_1149.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8095_2652.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3486_7140.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3947_9237.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2415_1915.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9007_1617.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7422_5983.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5835_8600.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_39_9474.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9492_7780.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8883_3231.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_665_6749.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9753_10638.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6223_3041.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6721_9783.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10847_7624.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_514_3182.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_390_645.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9084_2466.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3661_7892.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2715_3176.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6975_5446.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5104_4153.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8597_8334.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4216_2339.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10590_4388.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6762_2027.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4216_8446.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2906_7432.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3913_7533.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9942_7499.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4848_3884.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9270_582.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3839_3200.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9499_2558.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7287_8860.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6775_9425.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3884_5377.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5320_945.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10060_641.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4282_545.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10029_10406.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10367_4229.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2001_6487.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3159_9577.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9652_1439.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6354_9661.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7685_2853.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1063_3943.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8420_2485.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8199_425.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_302_10749.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8177_7094.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5500_10720.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6166_5406.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4951_5972.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8433_6782.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10912_7987.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_817_8716.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2036_6205.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9075_4031.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2391_7439.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8616_10192.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2350_4427.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9128_7254.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6526_7164.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7914_5787.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_677_6236.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9542_4807.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5039_2018.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_868_3447.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3033_9463.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9559_10447.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7797_3655.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5619_2830.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10712_4849.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4527_2874.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6867_1896.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_218_3280.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_609_6009.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3854_10022.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5367_4923.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10011_3073.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2155_1030.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8121_3230.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4088_9240.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1866_2184.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5981_5342.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9592_2504.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10124_2807.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7536_690.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1695_3754.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1326_4364.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9735_1654.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7874_3902.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8538_9667.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9759_1891.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6313_9132.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5447_494.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10835_4373.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9828_280.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6768_636.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8634_3900.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1316_1757.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4253_8746.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7186_9795.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7022_10068.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7288_1999.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8391_5075.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5431_1032.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7557_5829.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3109_9470.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7899_2867.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1259_4497.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3972_6275.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7169_7666.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9529_8905.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1438_7210.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7771_3349.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9303_8668.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9827_9682.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7004_9308.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7852_3897.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1263_8930.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1282_786.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5689_8703.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8969_7082.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1863_8304.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9375_10694.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5903_3161.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5881_8750.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_229_9362.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5601_9731.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7709_6612.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9419_2817.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3173_3764.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6991_9770.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10697_5133.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7799_8525.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8488_5111.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8429_3002.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9628_5063.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1282_4202.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10034_6948.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4900_10839.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_232_1746.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9400_1972.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10558_2918.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4577_1317.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10435_5958.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8139_2591.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2802_4995.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8567_6532.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3472_1327.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4156_1319.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7843_2678.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5199_1844.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4706_2138.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3537_10225.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8214_867.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4495_1409.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10278_4525.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4867_1409.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1984_2962.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3981_7323.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6407_2432.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5067_3953.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9239_6788.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4998_2619.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2454_7862.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3471_1775.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2509_3824.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5985_6069.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6609_922.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1400_1883.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9149_10304.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3490_2761.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7320_3412.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_671_10861.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3049_10908.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2414_10348.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_689_9703.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7981_5845.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4016_8084.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9649_5638.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3007_8107.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3431_2949.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9168_6208.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3664_6611.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2321_9157.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_740_2867.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4487_7039.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_204_7004.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1991_9475.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6955_1485.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7570_8834.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7471_9137.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10306_7008.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6875_574.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10309_4076.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2785_491.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6355_2804.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4346_6326.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6874_9520.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7102_4717.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5184_8295.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3541_5417.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9540_3305.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3455_2540.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_992_675.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10748_4401.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1432_1591.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4226_3248.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7310_5757.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3485_10259.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2583_528.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9234_1320.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3541_1694.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6624_499.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3326_9603.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10588_6299.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4382_4540.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5835_10046.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5471_3464.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5871_1505.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3432_1553.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7940_6186.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1904_9628.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9757_9006.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3088_2519.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9738_518.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3951_416.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1415_1042.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8347_3108.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9124_5159.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5701_3149.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7307_1916.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7845_4063.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4647_5661.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2756_8771.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_26_4346.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2607_5642.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10251_4381.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9048_9226.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10807_5482.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6184_6308.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4093_6796.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3480_3191.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_173_5499.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_24_8692.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2909_4657.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10512_9744.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9637_7370.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8570_725.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_910_5705.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3572_2278.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7488_10793.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9391_1930.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8254_5806.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2508_9645.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10797_3907.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5587_2040.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5175_3346.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4742_8061.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2610_10190.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3668_2891.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10121_8127.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3495_2104.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9216_9230.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9827_10209.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9072_6173.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_83_3565.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1621_7434.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3285_3257.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10365_456.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4528_10580.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2878_9950.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_481_5583.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4697_3631.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8295_1189.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7171_31.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8314_817.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7471_485.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9918_3806.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2163_1278.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4931_4799.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1798_8167.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9380_9570.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_6721_1329.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7603_6278.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_6896_5095.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10335_5094.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3496_8126.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_951_9988.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3227_3477.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_270_8410.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3611_5242.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8595_275.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4562_2629.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9093_1473.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7243_1359.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3714_8347.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8596_8106.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5210_3881.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2853_3320.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2693_9070.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8534_1671.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2649_6342.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3497_6130.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2227_6147.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2366_10143.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3948_9199.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10484_9636.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2144_10880.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8521_8393.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_932_7955.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8802_6868.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2964_2291.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8424_2500.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5403_2755.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5838_3172.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2429_3028.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10143_9490.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_848_2336.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8710_10304.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2467_7978.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_437_3855.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_957_2544.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10393_10466.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9594_339.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9232_6506.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4216_1286.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4233_9301.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7828_694.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4007_4385.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9733_2086.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2539_906.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10541_8819.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9694_5482.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_30_9452.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_832_3840.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10581_1474.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10671_7698.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10520_9874.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8534_1126.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3158_10362.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9980_9318.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3079_3758.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2585_8998.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10741_4913.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3317_1358.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8556_3263.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4833_4240.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9928_7669.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7857_1288.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9609_691.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8347_2879.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9747_2029.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8779_309.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4537_6324.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1033_8205.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9858_5680.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10290_7752.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8350_593.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9321_3358.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9466_5734.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3779_3698.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2325_8303.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3480_2580.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9212_10298.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9360_10074.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_800_10679.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9552_1695.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8253_1109.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9521_1888.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1904_7083.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5889_3056.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4341_8898.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5958_1929.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3827_2132.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3550_3165.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1594_10851.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9214_7765.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1291_465.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_7765_9000.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_5_5475_6827.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_7471_4840.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6509_5859.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4516_4241.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8952_21.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7256_3826.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7374_1967.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4028_9797.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1182_1416.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4778_3920.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4050_39.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2190_2060.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7728_3949.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2764_5156.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2108_8476.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4000_8825.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8579_930.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8963_2604.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2087_7606.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8315_6012.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5566_7152.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2837_6969.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5402_4918.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3973_3995.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7238_7438.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_709_5489.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6962_5947.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9917_8787.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1032_6670.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1588_7116.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2672_625.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2718_682.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8397_6019.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2194_8682.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4802_1006.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5482_8433.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3898_10181.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2000_7453.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1662_858.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9907_5137.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_147_4120.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7012_1362.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9904_8834.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6747_3829.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1080_3600.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8993_10589.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8720_9669.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4110_7557.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_439_778.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7967_1955.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2313_1133.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4781_6553.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4624_4736.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5594_3735.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3203_2823.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7678_270.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6929_7389.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8408_10881.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6655_7169.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3463_1060.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2639_9828.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9553_5423.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6099_1846.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9531_4281.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6196_8881.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9052_657.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2993_10619.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4178_778.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2734_8368.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8106_7498.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8228_9309.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7328_2276.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5534_9609.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_63_3523.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6697_7188.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7948_3016.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4247_6672.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8904_7505.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2918_4077.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9871_867.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6691_3069.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_768_6739.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2890_2733.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4594_10082.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4823_8992.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8447_7325.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6039_10823.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1785_3091.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_460_167.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6409_9514.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3711_6975.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5189_1971.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7420_6612.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3841_2448.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4850_435.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10694_7415.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7121_7303.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2688_196.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9651_2332.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5455_5139.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1205_6032.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2071_8310.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7957_10698.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1137_10694.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1311_8581.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2221_6132.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3336_8578.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8651_5675.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5100_10677.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5029_7677.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9591_10598.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8187_9636.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_846_2689.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1821_5986.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4511_1637.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10720_7840.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7173_4437.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9418_3117.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10439_3299.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1860_1539.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4113_3369.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7209_10452.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8499_9110.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6676_7295.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7193_2821.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2855_1866.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1228_6623.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1255_5218.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5678_4156.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7537_195.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1694_3334.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10011_10149.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1870_7804.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3982_5494.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_738_6802.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5626_10586.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_360_6821.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8753_10126.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6168_1684.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6546_2419.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8468_4467.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9036_3053.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_173_5756.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3313_8320.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7237_1416.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4101_1483.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3595_7576.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4105_8206.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9514_5928.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6448_9323.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6059_6667.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2087_2407.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1336_2307.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6925_6910.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6424_8519.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3244_201.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3090_9115.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10026_1628.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9699_2004.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7157_2585.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5690_1051.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10902_3915.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4980_2442.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6220_9332.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10554_6714.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_817_2191.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1375_6382.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8581_1913.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6515_7841.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5965_766.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1527_4552.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10682_4960.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3092_6703.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2091_5756.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7715_6126.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1103_7618.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2863_5341.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2898_6455.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6594_4363.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2142_7045.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2144_9859.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1999_3012.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8208_5976.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4518_3744.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8277_2969.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2532_8215.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4636_1599.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5252_5388.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5648_861.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8053_3735.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_464_2929.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10908_6485.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7573_4767.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8602_7633.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4112_3919.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8275_9902.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_256_2763.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3118_2001.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10629_384.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_717_3884.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1634_8202.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2138_904.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3428_4702.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1731_4406.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5338_6978.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1934_4673.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7357_3068.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7103_1760.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7660_7960.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9815_259.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4921_8531.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5068_7679.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1747_9889.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2258_9552.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3903_1158.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7151_3059.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2430_8758.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10609_9131.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9012_2633.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6244_4203.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_140_1917.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6912_3393.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4856_7571.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1150_3828.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6540_6946.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1211_3500.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1281_1140.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10308_193.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9413_8956.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10684_9708.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8468_2789.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6963_3007.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10637_3656.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1651_8103.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1664_1826.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4356_832.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8498_2505.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_864_9285.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7785_2105.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9090_1806.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5807_10637.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9594_8153.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4406_4625.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8542_2893.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3063_3932.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5146_1489.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1604_10484.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8831_10226.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1095_6533.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9778_6919.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1702_4219.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5181_4724.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4006_7993.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2937_9219.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8297_6605.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6767_55.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5586_6197.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10506_8433.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3880_921.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8272_9095.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4821_3308.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2134_8482.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_466_9568.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4511_2542.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3432_5050.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4899_2492.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2332_2421.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_198_3711.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8777_6720.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1452_2897.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1077_634.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6616_8815.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3041_9744.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3816_3311.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_813_5386.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10891_2108.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_271_3441.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9670_8531.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7084_3299.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9325_252.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3354_3264.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10336_5966.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8589_5701.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9770_7835.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8788_4158.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4245_6521.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4128_1379.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_715_2854.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8007_9192.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2962_5862.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2218_9819.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4198_9659.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9000_4153.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6845_872.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9125_10362.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9409_3638.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3199_3456.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2038_5379.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_974_9177.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1589_4387.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2310_8397.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4551_7359.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6919_7748.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7815_4346.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8714_5441.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7662_1156.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2005_1434.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4968_2563.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2702_5685.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6108_2272.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1570_6623.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_910_3809.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_494_6249.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1950_1235.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5875_3122.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4905_3610.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4405_617.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1776_2384.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5904_10478.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5978_683.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3149_9415.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2874_5053.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8073_5283.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9188_5449.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3660_5716.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3488_1562.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3487_5218.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8729_9936.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4637_8641.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4453_415.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9632_90.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5659_5165.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1221_7958.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1681_5118.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5091_25.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_367_4560.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7491_10465.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5019_2917.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1183_912.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7893_3796.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3090_10446.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3146_8771.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2357_1525.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6022_10667.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8186_1642.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8511_2350.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_177_3237.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2951_617.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7127_9452.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8884_8809.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2807_2242.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9452_3578.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5578_5205.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2771_1502.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2573_8565.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4589_5193.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8734_8520.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8079_7726.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8165_7232.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9577_9043.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1304_3117.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7002_6404.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7792_1310.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8643_5842.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5137_2671.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1206_3226.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_500_4635.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8468_10277.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9161_1861.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5009_2438.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3250_7116.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_51_7481.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4612_9598.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9618_7101.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6555_1088.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5718_10499.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1556_9427.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1079_7397.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7679_2660.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_382_2561.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4039_364.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7085_7381.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9490_7812.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2744_10328.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9618_1201.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_497_2031.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7647_10605.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5447_9232.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8394_626.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7400_2423.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2974_1087.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6044_8573.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5042_4454.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1495_2358.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3644_6124.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7369_6523.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9440_3940.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8897_3.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5364_1290.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9094_3194.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1530_10296.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8544_4834.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1276_10229.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6990_5970.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8695_1866.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7808_2733.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5070_4114.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7986_6541.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5658_9920.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4009_5879.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1376_3174.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3114_4730.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8132_4093.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10161_9450.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7053_2299.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_794_7955.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4967_6000.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_536_214.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6394_1589.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8183_1789.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3796_4200.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_873_8373.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1027_8145.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10078_9702.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8373_10014.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2202_1690.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10030_7829.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_8172_3753.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_5797_6531.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_9104_3142.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10579_2273.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10321_3485.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10022_4347.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_7250_3528.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_9502_3708.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10358_8236.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_9950_8069.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_5173_7927.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_5592_9902.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_5587_7169.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_7438_5015.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_7900_4182.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_5028_10887.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10086_7073.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_9604_144.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_9282_4172.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_4_7254_10237.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_4_5091_8205.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_4_7562_1325.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_4_7129_9889.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_4_8226_6739.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_4_5588_5865.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_316_6770.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5303_4178.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3942_7524.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5978_9582.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5511_6128.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5864_2750.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_304_7208.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6398_10194.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1584_7385.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4667_4428.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6504_6502.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3037_4566.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4340_9450.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10159_2466.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6195_1274.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2543_3782.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2208_2356.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6150_5269.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4747_7876.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3485_3372.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6848_3789.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7843_3310.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8564_3739.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4399_70.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6262_61.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6169_828.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3292_3546.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1613_7236.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1888_5668.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2088_5658.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4307_5176.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4032_10162.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_999_1327.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_105_5406.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10085_4654.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2399_5730.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3621_7369.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3350_7313.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1795_2379.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7437_2853.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8242_100.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6613_8528.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2945_4449.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3003_481.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2585_770.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3858_10859.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9952_6072.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10729_5240.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7633_10128.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3929_7354.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8895_9272.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7452_9955.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_630_10217.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_544_5643.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2772_8992.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3324_7205.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8301_6013.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8327_6864.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_729_7958.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5332_6812.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9307_10737.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6017_2578.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7066_3885.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1989_5379.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6504_2379.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2670_7694.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4996_5040.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1868_9544.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9900_3016.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8481_7409.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3257_9707.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4607_592.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6690_4792.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7700_9564.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9624_7999.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1743_1345.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3554_7052.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3718_7723.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3169_6677.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1181_8931.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_222_9921.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10297_2636.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3152_4068.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9915_10483.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7295_9771.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8498_1196.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8552_7038.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9280_8561.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8268_3170.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_46_3569.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2251_5784.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7987_6237.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_612_6189.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1985_5757.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6993_7863.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8096_44.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1618_1308.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6154_7123.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5781_5728.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9121_3584.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8111_10709.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1813_3098.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2565_1819.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7556_10493.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8741_5545.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5865_10849.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10616_6217.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8104_7075.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4986_2900.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3207_2329.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10396_7132.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4056_9359.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4991_2672.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8662_6223.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3362_4750.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7950_8669.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_725_9343.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1299_7805.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1481_3566.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_914_3703.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3292_6002.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1590_3390.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2652_10394.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7287_10185.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9508_2492.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_270_1471.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4932_5635.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6459_220.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8997_2644.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6921_10398.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4152_2791.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1685_4540.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10038_10255.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1683_6635.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5561_3248.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7673_7914.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_289_10429.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7826_4049.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9352_1960.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10227_5563.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8449_4907.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8306_8256.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9771_5460.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7293_6831.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2622_10372.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3038_5626.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1827_3219.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4824_6431.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_363_3128.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4362_4158.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3410_84.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1436_10413.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5558_8411.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4010_8756.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3702_826.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2118_10337.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1739_2665.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6152_9766.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_92_6364.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10352_7892.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2503_10290.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9461_6624.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7559_1249.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9502_6637.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6101_9315.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3365_9626.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1723_2272.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6488_9114.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6163_1044.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8567_6311.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8216_10495.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7978_1610.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7092_3309.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10854_9049.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3922_5157.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7040_3102.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4201_5694.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9990_8013.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10539_8487.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7644_10032.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1844_10555.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10012_2311.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7733_1174.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2644_10486.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3731_3735.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5622_2160.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3317_1898.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_603_6199.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1360_243.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8391_1557.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1754_1119.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4549_3311.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3957_2594.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7594_6362.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7971_2300.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10079_1509.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5500_8610.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4022_5434.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6407_2331.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9601_5118.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6729_1361.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6659_973.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_470_9157.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7605_1228.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8231_5154.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8408_1023.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9244_87.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1515_568.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7240_8607.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3187_9573.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_51_4140.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2871_8910.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7293_5230.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7421_5464.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8740_8681.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7378_10589.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9660_2519.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9207_4138.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3399_5214.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9818_8362.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5726_7570.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4854_10501.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1831_7084.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4537_6648.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_485_4760.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4995_5756.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9301_1318.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2574_7964.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1197_6644.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3881_10063.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7587_9370.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10009_8997.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_59_6478.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9799_10437.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5860_2577.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4827_2991.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10225_779.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1071_10387.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9495_9323.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9231_8733.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6032_9189.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7189_5885.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9051_6392.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1112_10345.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4178_2739.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5216_8320.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3287_3231.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4001_9073.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6550_4226.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1889_400.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8858_7173.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2904_9691.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10339_8070.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6426_5019.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3910_9581.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8054_2138.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1130_4620.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4132_4244.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4555_6540.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6700_671.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9600_7176.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6192_1974.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4132_7494.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2978_9318.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4197_8746.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6309_7064.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7091_5632.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7012_5500.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9274_7864.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3036_10136.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10432_8044.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7822_5574.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8325_9744.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5465_10351.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2581_10602.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8144_2140.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5554_8679.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8954_1549.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1433_3894.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10402_289.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6315_5520.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6131_10021.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9329_3087.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8257_2489.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6354_7395.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9403_1229.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5293_5810.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3433_7535.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8334_3304.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_317_3622.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6079_8484.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6706_6965.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2644_8657.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1357_5631.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7398_9162.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_53_9454.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9636_2918.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7974_7050.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2312_2257.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4573_8823.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3522_5347.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3340_4717.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4561_8471.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6577_8700.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3169_9067.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8565_8585.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8564_10336.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4431_6640.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7915_10445.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_215_3638.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4563_4842.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9957_2412.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8373_1477.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5456_3346.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9868_5395.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7060_1004.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5548_1843.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7908_3327.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3341_9565.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7823_8232.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2867_5140.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3023_1905.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6070_3464.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7579_1625.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1327_9015.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3580_2246.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_636_2303.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9569_8436.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6983_7634.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_858_1477.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6859_5420.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8702_566.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_387_5367.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3970_8852.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1092_2742.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3220_7185.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2767_10731.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_971_450.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7107_4339.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1825_10763.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8928_8492.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7176_7141.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6318_3080.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1561_8447.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9169_9146.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9956_258.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7768_4041.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5453_159.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9341_5080.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4705_991.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3236_4128.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6847_3984.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1104_8159.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10327_2893.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8115_10532.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9303_9356.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6612_6459.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9577_1147.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6317_6039.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7231_10884.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2380_10776.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2068_3632.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10150_9198.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9735_8848.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5438_7256.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9097_181.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5594_9597.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7753_2127.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9643_5681.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7369_3379.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10204_2082.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5929_9962.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8633_9416.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1372_7224.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3046_8773.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6521_2612.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_981_5142.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_222_2764.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6881_5589.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9621_10423.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10659_6542.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6447_1860.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8827_9282.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7874_9541.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7675_5179.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5030_6325.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6780_2206.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2558_6276.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2205_4826.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9770_509.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6058_7011.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9742_4267.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3146_3999.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1092_7592.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7745_3627.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7186_1529.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7586_15.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3320_853.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9178_255.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1244_6364.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5096_4896.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8339_917.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_6110_3714.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2145_2377.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10213_2832.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3153_10757.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4887_3616.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9889_10740.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5041_4766.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2487_6061.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1666_7552.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3971_9118.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_6188_2555.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9400_634.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9889_8673.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8387_10819.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7059_819.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4313_8797.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9346_3012.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_6522_133.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3138_9695.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3096_1879.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4584_3818.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1481_2384.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3959_3751.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1392_3413.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1675_8179.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7835_10303.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9877_3286.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8303_649.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1096_6901.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1442_6299.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1503_8964.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1322_4973.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10116_6570.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8260_4420.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2562_10632.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_124_5393.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9917_6092.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3230_6705.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10764_2450.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2537_4679.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8907_8694.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7951_245.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2523_8804.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8195_8363.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3553_2955.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1326_8764.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3833_4966.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5515_1055.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8020_1522.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3867_7961.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1026_8192.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2512_9492.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2937_2245.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3910_6969.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5515_775.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2067_9925.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4942_8938.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3767_10359.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4809_5364.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3754_5236.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4785_10538.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10304_8466.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2957_7564.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10750_7165.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4751_6616.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7428_229.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2969_4914.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2575_6605.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5508_2639.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10095_6035.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3239_1706.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10166_5914.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3313_7168.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8802_9229.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10723_2278.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3993_9713.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4995_4575.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8204_3117.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9063_1802.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4155_7487.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_814_9450.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9722_7622.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3481_5480.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1119_7081.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8232_7074.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10070_2298.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3200_2574.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10897_2948.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_507_7926.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1319_5531.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1901_5879.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10431_10135.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4139_8968.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10220_8046.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5818_4797.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3143_7609.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5616_2697.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9374_3272.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4374_9966.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_97_4409.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2549_1053.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_352_7901.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3598_4091.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3472_10428.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3504_3775.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9186_1594.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3191_5780.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4039_8887.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1179_9983.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7373_396.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2513_10910.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2873_2345.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3636_8675.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5290_2981.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1861_10631.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9738_7763.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2138_9257.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2710_4917.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3046_7656.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5716_5507.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9864_943.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_494_6679.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2920_8322.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4775_10558.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4608_9128.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8997_7170.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1994_7593.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8748_5809.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1303_10688.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1086_5140.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10566_6464.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4224_8234.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9749_10832.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_159_4347.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8264_268.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_897_5504.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8843_6023.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_947_7662.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8636_9951.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1573_8928.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10197_10016.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10601_7912.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5864_4876.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2973_9828.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_9040_3816.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_6_8208_8968.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_6_959_9753.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_5_7823_1640.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_5_7317_3051.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_5757_7881.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10559_10365.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_9157_6605.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10437_5621.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_5115_9092.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_9276_5082.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10092_4319.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1692_3404.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6495_1728.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_806_9408.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7269_8470.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9819_4977.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5126_5050.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10443_1254.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8384_8642.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10450_1549.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8735_366.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10529_7655.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10139_8878.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_6_10891_4742.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_5_8762_3722.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_5_9162_1519.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2627_5726.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_5_7066_2855.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2254_2025.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10313_9439.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8170_9327.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9603_2208.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3709_10100.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8169_1319.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4199_6919.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6487_584.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10245_8642.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8872_7123.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5920_1555.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1743_1281.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8372_9104.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5730_4288.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8466_2770.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8754_4146.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8337_5235.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4336_8024.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6295_6285.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8579_5882.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8382_2867.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7262_7816.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4574_5281.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1574_9685.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1083_5335.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9613_502.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9886_424.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10271_8153.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3104_3225.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6687_9753.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8201_9495.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9351_8230.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3197_4585.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1732_7807.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8744_10497.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6821_6172.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7627_1746.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_748_6052.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10075_6393.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2075_2055.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1852_3579.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2595_6137.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6420_8021.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2048_6810.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6728_1573.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7669_3307.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6651_9435.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8106_6256.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3332_4176.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5023_9179.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3836_4246.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8970_298.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1857_4703.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3641_4688.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2739_10650.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7178_9776.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7688_9351.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9211_5340.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4682_7683.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8302_2704.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3559_6435.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3529_10728.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3762_562.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_598_1743.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9747_5460.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_972_10860.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3532_10016.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7784_7071.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7919_10341.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4561_9283.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1572_8250.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4743_6664.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4891_1454.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1523_1943.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3661_3952.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10600_2322.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8274_8654.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6164_6540.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8313_5931.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9422_7394.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1270_6668.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9593_1196.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2924_7490.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5429_4964.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2085_3192.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7386_8068.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3289_2948.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4631_5597.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_296_369.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9159_1945.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8585_4153.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1829_2698.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4359_10359.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3559_8982.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4110_9536.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1247_9757.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2696_9148.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4325_9915.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10307_4414.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7326_1676.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10120_996.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2548_166.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7305_1158.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3310_9582.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10911_7956.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6458_8769.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6007_9014.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3899_3871.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3486_628.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6371_3241.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_725_7423.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8022_10820.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6841_8913.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5896_9083.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4702_1365.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4425_1733.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10512_9107.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3996_8147.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_12_6335.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1261_5813.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_959_9095.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2076_5405.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8730_5823.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10025_10821.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4311_3363.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_522_4667.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9142_3624.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6141_7792.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9170_3532.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2469_7461.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5996_779.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3789_4190.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8764_5509.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_851_6615.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_460_6092.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10157_7187.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5666_10489.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2279_1609.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8996_10317.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6041_6064.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_188_10642.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3236_10580.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1484_5024.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_713_7170.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1989_536.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1316_3436.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8185_9071.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8283_6384.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5992_5763.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3559_6342.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1785_3445.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6677_2285.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7025_4477.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7629_1729.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4291_3357.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7009_5930.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7191_7434.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5588_6649.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1339_3444.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5305_9948.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7513_4482.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4709_8910.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8184_1954.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4225_8706.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_588_9358.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2086_1710.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6187_3432.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3177_6757.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9340_10139.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4478_6384.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10397_4176.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10374_7124.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9766_5603.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3209_9079.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8283_3606.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9769_756.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10830_5546.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7786_1229.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4888_9645.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10343_10018.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6652_3242.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6160_3295.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3277_10152.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7051_9528.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6281_5217.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4196_447.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1140_4475.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1801_645.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6743_3692.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8426_4576.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9902_6229.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2058_5151.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5995_2605.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_380_7435.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10144_7961.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10090_616.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1374_5506.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10597_1082.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7723_9400.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6200_1691.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4097_7240.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7720_3467.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8797_3406.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8728_5962.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6080_2349.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1361_5327.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4566_8231.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9872_7528.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_32_10723.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2488_5513.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_882_10089.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1337_4448.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_415_9244.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3301_7018.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_201_6453.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3159_5725.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2584_10060.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8215_888.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4031_1973.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3376_794.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5381_3122.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_502_7912.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10744_7661.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2480_4668.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10243_5600.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10158_10482.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7584_2625.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3444_6959.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3716_8630.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5970_10391.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4483_9638.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10243_3500.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3524_687.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1086_2644.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6831_10499.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7237_3071.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6122_1523.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8965_1697.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2125_4257.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9621_8277.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_817_3253.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1611_8575.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10039_2253.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2829_2199.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6641_7557.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4145_1492.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_378_199.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7791_8944.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5010_1765.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6736_4720.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9935_1390.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8332_8720.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_823_5389.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6274_10321.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5761_3076.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7775_2595.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4872_10126.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2100_707.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6278_9089.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9609_10420.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9245_2093.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8775_8156.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6302_3895.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7130_1254.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6739_10323.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10725_8416.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7584_3482.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8839_4935.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4471_2363.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1517_7213.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1366_5181.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10221_1993.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4896_1076.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10440_2401.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2268_6079.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7299_9131.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7439_4743.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3263_3061.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3166_6280.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2971_7017.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9003_10762.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3237_7356.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8704_937.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5826_2024.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2286_5663.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7321_1777.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3915_4380.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_180_739.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1480_3371.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_190_6266.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6266_7569.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4039_3111.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6865_2233.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5666_5717.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9604_6581.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7354_6400.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7620_8897.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_121_2821.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9385_1672.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6425_4219.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10642_5064.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6831_4228.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_781_5082.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7246_9720.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8993_4101.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1917_8281.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1775_4473.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1817_6805.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10750_4289.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_755_3554.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2603_5786.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8966_8354.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6347_320.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1063_7616.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8733_7010.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8048_10711.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2811_2831.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1547_6569.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3981_2299.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2358_2067.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7807_5191.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5740_7943.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4621_8815.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1388_6888.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2202_5063.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10060_7474.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2772_1071.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7251_3849.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6211_5036.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4836_8888.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2885_4825.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8513_7550.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9503_48.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8745_2140.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3718_7695.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3207_4620.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1931_2165.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1416_2524.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5475_2161.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7778_4661.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9923_10746.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8871_540.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3338_3985.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2813_9319.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1591_1288.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4298_3518.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1213_2817.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10755_858.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9697_9685.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7532_8475.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10408_4969.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5455_2855.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10872_4822.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2568_10374.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5990_905.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7181_3969.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_471_1251.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8138_5677.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4436_1554.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7645_8449.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6954_7002.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9658_6654.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6609_842.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8089_48.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8011_1008.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2553_39.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1419_1904.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4331_5338.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2981_7106.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9967_9361.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7155_3203.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8188_8874.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2326_4819.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3512_1721.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1942_7890.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3419_9792.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6302_5949.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4180_1294.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10219_2205.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7300_7074.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9940_1384.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8124_7931.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5520_9205.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4348_6541.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4146_9913.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10443_9980.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_916_3858.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7656_7560.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9422_8505.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10571_8492.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10238_9075.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9976_7584.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3091_2479.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5419_3556.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2397_6962.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1240_6242.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3953_6130.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5057_3614.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9908_5643.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4320_3711.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8017_7928.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1258_6316.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2145_107.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9669_4107.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_162_6265.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10374_2256.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10005_648.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4100_4017.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5573_7124.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1245_9038.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5665_3325.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6426_10680.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7057_4338.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5168_1989.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2773_5228.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7080_5158.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10773_10427.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10224_8023.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_7825_3652.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10709_5662.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_7506_6071.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10851_2593.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_7184_3059.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_5365_10788.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_5700_7085.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_8177_4257.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_7673_4245.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10378_950.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10394_4790.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10770_4768.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_9512_4154.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_8851_4772.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10088_8961.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10250_9926.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_9705_3371.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10715_8918.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_7166_3149.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_9450_4407.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10352_3055.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_6672_7581.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_4_6188_9196.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_4_4997_9199.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_183_568.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5174_8689.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8823_704.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_606_7242.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1933_3251.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5504_37.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3533_10696.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4125_425.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2229_100.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8588_7119.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4756_10505.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9494_4195.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2171_1369.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3898_3704.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8794_6974.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2556_10127.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4086_819.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_595_4770.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9609_7060.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10140_2893.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7405_10859.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8559_8377.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9081_5716.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3379_8461.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10802_6536.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_23_417.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_925_9502.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6154_5407.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1120_10578.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5715_3427.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10777_6838.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7567_6680.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1305_3358.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3703_7737.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_846_5436.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2263_3224.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5972_10776.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1351_1316.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8336_9528.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5795_9667.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4560_2142.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6309_3130.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9228_8954.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9720_10039.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2315_10882.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5770_1845.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1612_2982.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3098_1560.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3237_3273.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7658_8506.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1284_5803.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2205_10776.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10802_7037.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8738_1231.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6814_3100.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8725_6089.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1287_1760.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8955_9738.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3707_4059.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2566_184.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7663_9633.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4734_1548.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9173_6848.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7653_2581.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3483_431.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8960_1298.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8310_6372.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2644_660.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10671_7663.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5026_10236.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2335_1621.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2546_5259.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2536_6324.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10468_10555.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3054_4446.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9054_5724.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_791_3574.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_551_3202.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7561_1951.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2749_2346.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1033_3558.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10457_8817.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3413_7658.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2834_7258.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6409_5693.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4543_3557.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4779_566.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3332_6658.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7547_6302.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1616_1771.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1837_9000.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5504_8380.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9882_4609.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10819_8971.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3389_2616.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9643_1801.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2097_9747.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2373_10607.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2951_5934.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6070_10393.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8437_9817.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4764_2864.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3855_5520.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9526_8288.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7811_2037.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2477_4014.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7889_8430.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7958_619.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3202_6177.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2344_10539.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4802_5069.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3869_10875.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8953_2109.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7730_8840.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3060_10849.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4592_6582.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1489_6101.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4632_8783.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5849_8704.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2285_9362.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8340_10438.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1149_3145.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4814_10694.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1014_1946.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1029_9919.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6216_108.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4561_5761.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_108_7501.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6384_6213.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10298_4484.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3998_8119.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1545_10684.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4317_10887.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_797_6806.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6642_4599.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1876_167.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7764_6455.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1046_1801.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3949_2062.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1547_4110.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5531_619.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5675_459.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5911_993.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1901_755.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2733_9642.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5470_3659.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9379_10703.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9993_4033.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1723_9896.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8601_7760.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3989_7712.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9789_2873.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2005_3532.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4572_3651.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8034_2474.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9125_8239.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8996_8036.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_309_3284.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4764_4422.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1600_1566.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9897_8273.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10720_6096.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3915_9153.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10751_5903.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6544_3569.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1630_1920.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3757_8224.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3142_3523.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1669_9461.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7947_9205.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4680_179.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8847_771.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4504_1596.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4431_8509.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_633_688.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4802_6071.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2771_5240.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5552_4236.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4138_2373.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10769_3601.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7333_695.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4596_10021.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2413_10570.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_384_5754.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10846_2441.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5978_1004.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6206_7616.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5576_9286.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1608_2959.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4273_10737.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1765_1690.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9439_5135.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6874_258.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5297_3612.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1255_4949.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5680_6950.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3404_9502.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10710_5978.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8163_10583.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2743_3933.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_357_7434.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10129_3678.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9549_3079.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6770_4436.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10545_8539.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10150_1074.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5759_5522.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2759_1279.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8470_9104.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10742_6772.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5102_10166.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7071_10670.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2566_10756.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5960_7055.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3158_3478.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3143_1461.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8239_6526.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8936_4591.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9656_8981.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10772_1041.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10051_7563.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8289_1500.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2706_9525.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2381_5319.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3776_6056.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_413_1018.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5796_9197.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4835_1652.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2673_7117.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6239_821.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2728_2176.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4549_5523.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10649_7035.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5264_6770.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5639_4181.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5644_1680.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1357_8165.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9809_6495.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3003_4860.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3385_456.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10287_5981.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5767_10132.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6549_8685.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2488_1306.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3049_4591.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8366_10123.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1645_10142.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10086_5037.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8491_6470.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3735_6692.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4343_4141.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5719_9721.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2500_4755.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6031_7793.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7048_8623.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7169_1377.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9410_2516.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9351_1758.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1741_8615.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2451_6111.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3587_10413.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3460_5633.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7601_2646.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1339_7838.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1875_3622.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8372_8484.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7086_185.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5844_3944.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7147_542.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6574_773.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_886_1679.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4873_9932.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1457_6000.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9911_1315.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2837_2070.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10524_4579.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9347_5823.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5809_6081.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1394_2461.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10008_7756.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3784_3555.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2092_8249.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6390_1639.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8961_5274.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7961_82.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6350_10027.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4627_7919.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_204_9630.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5370_3603.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5028_1463.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6233_5942.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5464_2642.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3223_7103.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2289_5708.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8068_6010.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6253_2984.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4001_10149.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6821_7780.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3319_8628.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4223_6562.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6329_4069.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_897_2731.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5261_4815.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7252_8928.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8017_9456.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7591_5666.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9597_3199.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9288_8004.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6243_3000.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9881_10703.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6095_1970.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7193_3446.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3464_866.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7204_9335.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7980_77.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1260_9930.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1788_3035.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10304_638.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7829_8213.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3238_7381.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10517_10530.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3490_1916.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10824_789.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7881_9776.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10439_2733.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1631_5368.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2303_6729.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1374_10298.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2668_3023.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1980_1790.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1350_2069.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5546_405.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6262_3535.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5773_2180.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7824_6493.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7310_6154.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6948_5657.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5130_10887.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9332_7696.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10401_8812.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2361_8399.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9954_6965.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5817_6202.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_400_2969.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4809_9202.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8664_6691.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10894_10117.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8957_4808.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7493_9987.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7738_9611.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8692_10642.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6096_10754.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10385_6282.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3532_7197.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6388_8928.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_554_6756.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1777_4418.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10354_6198.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6222_7940.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10608_10156.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10891_8377.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5039_8482.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1488_1834.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9305_4906.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8876_4787.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1228_2196.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6952_8265.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10724_2022.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5805_9330.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8321_6409.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3217_6436.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10167_5882.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8473_2221.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9252_3446.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9882_1625.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8272_5598.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8871_5651.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_430_931.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1463_2443.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_178_1786.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3725_6613.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1253_442.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4405_8189.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3922_5676.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3034_4299.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2082_3035.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_48_9386.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9594_575.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10252_4916.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8493_5431.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8461_1242.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9269_8668.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10277_9900.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_533_8669.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9195_7926.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3289_9628.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1184_3025.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2903_5024.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2124_8699.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2711_9250.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2938_2431.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8768_2646.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3399_5088.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9591_8893.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9539_3009.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_707_7716.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5973_8852.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4583_4998.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_773_7514.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_31_4291.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9471_3029.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8442_9890.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3989_6887.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9668_4541.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_774_4301.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9465_6516.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1826_8105.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4832_4705.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2136_8734.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5217_2531.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3751_2832.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_65_9030.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8518_9801.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_57_8573.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9707_209.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3284_3981.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5453_496.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8350_84.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1277_8531.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5349_4804.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3664_10504.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_6822_203.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7845_8471.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4256_8718.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5462_3517.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3840_4192.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1197_10315.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10581_10472.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5653_8333.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10302_4836.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2950_2409.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9689_1486.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10138_4214.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2278_5317.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5980_3816.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9936_3438.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3589_9327.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7009_1329.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10742_7153.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1316_9467.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8346_1770.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8214_6763.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5942_5851.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7540_10815.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7153_1746.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10792_835.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4217_10488.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9091_1489.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3281_3905.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9239_10272.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9971_1256.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2523_5790.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4835_4061.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5364_5897.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2904_8166.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3507_1400.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8293_10630.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7139_481.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3976_10586.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2728_7152.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1920_6839.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3995_4082.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8144_9574.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5940_1026.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_150_4305.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_6593_3723.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1114_4200.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8828_7406.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4067_2319.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7918_839.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8794_8312.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_484_7627.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_816_5285.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2344_6349.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1380_10592.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_121_6061.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_61_7219.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4687_10813.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_91_2634.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4757_6009.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_878_9861.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_985_2680.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10886_4603.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1338_10567.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10912_268.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2362_2970.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9071_8251.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_204_7219.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3540_5162.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7862_6917.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10050_5256.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_6114_218.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5533_3694.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10022_9751.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2098_7918.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2895_6517.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_352_3295.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10792_8662.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7863_118.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3583_4113.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_909_5558.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7657_154.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7757_6615.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3383_9165.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1548_9233.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_6297_1654.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3766_1527.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9537_6907.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1180_7962.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_6679_895.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_105_6666.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3426_7878.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1665_7015.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4974_9799.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5039_7073.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_478_4284.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4521_3363.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4223_9365.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7080_805.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10387_6422.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_5_9005_6771.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_6724_8633.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1978_7107.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6616_8404.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1797_5610.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8317_5336.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10663_2939.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9280_8443.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3964_6157.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9860_1016.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_6_9799_4106.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_5_7994_6742.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3046_6394.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8486_8991.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7286_7264.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3792_6275.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1054_4195.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2587_8911.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2143_6102.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7947_9788.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8167_6628.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6709_9730.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2686_1774.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6687_10517.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3778_2738.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7175_1892.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2707_4163.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4252_8828.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6274_1889.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6864_3404.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1251_9351.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3390_6003.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5729_2544.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4978_7781.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9987_8071.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7136_8939.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9449_3243.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_211_545.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8658_527.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1258_1961.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4476_3730.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6658_2133.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4476_8047.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5471_8389.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3905_4430.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9654_6150.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6905_9316.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5208_4117.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3336_10805.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7372_9697.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2245_3655.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10873_2044.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5832_5761.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4822_5319.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6784_3025.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9819_5754.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_397_7094.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4496_6268.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8397_3143.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1356_4623.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5925_7568.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8806_7045.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7263_673.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7682_8884.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3987_3859.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8431_8346.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8444_9986.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8956_8067.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9371_4886.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9390_7052.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6384_3937.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1733_8840.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4626_1476.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2319_8541.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1725_8253.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5007_36.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2510_5920.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9123_9678.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_219_6027.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_3015_6949.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_957_1762.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9303_5105.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5597_3520.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1416_6531.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10001_10562.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7560_5654.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4365_346.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10770_3864.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_4862_1748.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_485_3401.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1285_6110.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1330_5029.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5333_9188.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2772_6152.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1253_513.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_10798_3474.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5876_888.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2463_7264.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_2937_8407.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_7774_9851.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5460_5173.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_1146_3403.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8825_7921.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1528_2137.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5377_6311.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3763_2240.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_4860_7001.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5344_9859.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_9766_6763.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1865_9988.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2310_2933.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_6457_7637.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_5354_7961.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_2117_2630.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9727_8992.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1689_7509.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_8522_2486.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_3673_7916.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_5365_6923.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_5_10304_1285.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8103_7067.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_8541_3528.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_9860_4585.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_7309_1893.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_1836_5271.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_4_6148_8537.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10693_5062.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_6726_3245.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10233_3323.tif  
  inflating: sense_ae_data/leeds/image_2020_leeds_6_10303_5268.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_4_5184_9099.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_4_7634_4051.tif  
  inflating: sense_ae_data/leeds/image_2023_leeds_4_8449_7372.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3578_6846.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1009_8522.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3595_7941.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_359_2753.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6335_10428.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5332_10.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5939_6858.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3642_8860.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7816_1828.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7191_6034.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1341_8718.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2225_2796.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6060_10789.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7318_1699.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6094_5955.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10167_598.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6088_771.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_532_4749.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2671_4792.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9853_8937.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7228_7760.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4052_10510.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5255_9484.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7250_7188.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_713_6108.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6744_6556.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_996_6778.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4875_7052.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2576_9591.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2064_3981.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3295_7875.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7421_7834.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9715_752.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6665_481.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5980_5305.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8530_6106.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1732_8221.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9608_8217.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1310_9703.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2378_1414.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6510_1260.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3538_2875.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5414_807.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2159_1015.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8143_9243.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1079_1880.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_759_3537.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6435_1672.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3104_3389.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10771_7545.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5506_7495.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8929_9708.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3391_2514.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_5209_1506.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4577_5772.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6219_7463.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7326_5553.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_2170_2842.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_1138_9261.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_10122_1765.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3372_4607.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4852_6792.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_8702_577.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_9302_1516.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7538_4085.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_7842_2713.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_3240_3746.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_4194_4689.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_661_3719.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_952_9382.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_6_6834_8301.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5657_1646.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7226_7453.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7729_6782.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4200_6954.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9580_1276.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4383_10412.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5803_10398.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1237_2934.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7935_3357.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5579_10181.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9226_9039.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8518_2377.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8231_6595.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4404_8949.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8223_401.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5004_4635.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4249_2628.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10607_3373.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9268_10740.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3616_8050.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5521_1036.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4874_9490.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_905_3804.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_492_5525.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1082_6618.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6526_7617.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2935_8672.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1793_10851.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6167_2896.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7824_611.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7303_8378.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10887_8018.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2837_10208.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10618_8534.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_5014_1419.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10766_8412.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4870_10202.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7277_957.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4061_9300.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2516_9079.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3554_6355.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7398_8914.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_7893_6899.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_3493_3818.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4994_9761.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2961_4111.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1838_10311.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4930_4183.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_9965_2858.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_8536_533.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6404_7.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_1312_6364.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_4365_861.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_6441_2718.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_2644_6097.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_5_10249_9645.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4048_9061.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1599_10150.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2094_9940.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9498_3508.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9063_8116.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1305_9962.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9097_739.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9694_8405.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2882_4819.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2630_5020.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4694_7854.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9741_807.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3904_7160.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2858_3603.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2438_8301.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9870_8760.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1365_7935.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10155_4869.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9479_9235.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_5588_1760.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8206_9821.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9787_5538.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2288_10207.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1333_5498.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1503_10412.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7778_822.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_10130_6275.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_38_6998.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8679_2205.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2697_5905.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_161_4304.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2182_8734.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_8927_6458.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4552_2683.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9864_4221.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_4689_8429.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2280_4521.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2505_5518.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_1875_5173.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_9160_1423.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_7827_10704.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_2937_8489.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_3426_10672.tif  
  inflating: sense_ae_data/leeds/image_2018_leeds_4_597_9004.tif  
   creating: sense_ae_data/edinburgh/
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_8282_5431.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_9889_13048.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_5041_15783.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_10503_7594.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_5401_13801.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2252_416.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2390_6086.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_9539_10966.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_9400_14390.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_10062_16504.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_5668_16430.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_5580_9236.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_6183_5662.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_4944_9015.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10679_14256.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2254_18409.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7844_13058.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9603_7116.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9470_10288.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_5606_14464.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9166_15041.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10245_1247.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8041_12532.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9907_13645.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_147_11320.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7617_9669.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8993_14048.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9886_17932.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9178_17134.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2313_12711.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9270_5281.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_144_15953.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4514_17913.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4781_18474.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10271_15106.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3973_12693.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4734_11385.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10334_1573.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7868_13000.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10075_12979.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_5847_15634.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_5023_16724.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6321_17162.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_6441_16280.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10850_9776.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8613_6672.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_63_10461.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7688_19453.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9871_12016.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8302_6818.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6691_16206.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6244_10724.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_598_9283.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9987_12167.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6409_18355.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7136_9720.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10694_6664.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3780_11540.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7919_18394.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7586_15438.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1572_3952.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9593_435.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_914_14732.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7957_9924.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7386_16018.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9422_15658.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9651_15647.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8266_6032.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5550_10004.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_597_10606.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10127_18241.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6713_14915.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10720_17300.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_8964_15641.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_9668_15876.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_8321_11231.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_5596_14193.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_9465_8105.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_7835_10303.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3482_545.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5033_15109.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8758_18329.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_6676_15155.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9159_3730.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2240_10598.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4110_3117.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10887_839.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1860_3369.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_9918_4539.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_10001_3806.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_6721_9570.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_6424_16758.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_6835_20365.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_10335_3408.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_5453_20804.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_8260_9988.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2863_15817.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7237_9909.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_8211_19637.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1782_4156.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4604_12942.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3983_18170.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9142_2307.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6371_19718.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10541_14759.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2161_16207.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6263_20488.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10401_19437.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8366_7576.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10585_12958.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_5666_17276.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2316_12167.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9514_19531.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1849_7185.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4867_17401.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5023_19009.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2252_14297.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_741_10628.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8277_4766.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6424_12010.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10475_14346.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10902_20245.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9815_5424.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7857_19409.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4667_10642.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10830_7240.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10643_10561.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6153_16920.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3236_1552.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7263_14314.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_713_12171.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8185_13457.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_7054_20098.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9217_761.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10109_10564.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7636_13791.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6893_11438.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5377_18338.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3150_12226.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4256_3012.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5094_19816.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10744_3253.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6953_2107.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1999_17245.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7584_7719.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9342_2253.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2532_17288.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5189_13862.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8820_11674.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_256_12859.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5968_14663.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_717_642.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7051_13460.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8543_4964.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7357_14196.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9402_17000.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_380_17466.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10090_13995.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8891_3623.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6200_15635.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7116_10874.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10663_17618.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10119_19790.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9327_15117.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8996_15978.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6080_11496.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10354_2601.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1540_14435.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_6274_11944.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4455_14315.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5195_13669.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9235_14697.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_6739_10451.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6507_16719.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6540_19884.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7809_12397.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10145_16577.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8905_5698.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8431_19391.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9670_18617.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10440_15319.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10239_15376.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7207_18889.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3754_14970.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3993_18489.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8498_18190.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10336_18000.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10001_18516.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1086_13475.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6392_11032.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5196_19797.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8254_16038.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6641_17305.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4145_20625.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10801_14213.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9413_5376.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4614_20210.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10047_12523.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_4942_15654.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9712_19788.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9797_14209.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8210_16409.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7252_19301.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2510_15430.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5586_12746.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7256_11414.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1978_11417.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2339_15217.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9188_6996.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5600_13800.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1194_15902.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10229_2137.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7352_17204.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8033_19855.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8317_13646.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10755_3226.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8186_18245.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5610_14065.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8884_6182.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6278_18747.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9918_11066.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6302_12146.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7130_14445.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7504_12657.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_4917_14682.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_1508_17890.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_6_6988_13533.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_6_7876_13031.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10768_17871.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4392_12952.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_9602_4232.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_6262_6401.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_6_8360_12040.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_393_3966.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_6514_14311.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9303_11173.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3525_3061.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8722_20274.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7383_9057.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9325_20542.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3263_1777.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1038_9824.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9940_4114.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8704_11167.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6811_20165.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8788_10362.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6101_13813.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10180_18388.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4198_13639.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3007_15270.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1299_11637.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1817_8354.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4551_19785.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9354_18947.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7986_16268.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4944_12830.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2603_2270.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9065_17499.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4968_17619.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8382_17001.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8599_4020.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1755_13683.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_10767_16659.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_10084_14736.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_9580_625.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_9236_13971.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_5653_20273.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_10138_17906.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_9047_14018.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1776_9210.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3125_15061.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10773_5067.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3899_17272.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10060_13954.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_6508_11771.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5144_16432.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10078_3528.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1783_16799.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8373_8332.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4541_11667.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10224_10188.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5758_7695.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8729_19180.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4453_18908.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7027_10667.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9998_19787.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2463_14015.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2823_2162.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10218_19189.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10834_11962.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8621_12880.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7770_8565.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9876_12646.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9608_19110.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7645_11689.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8079_15975.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6954_20277.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8934_11314.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_500_17472.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8468_11703.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9448_7397.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8878_1212.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8750_14583.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1401_17471.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7343_6523.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2310_3574.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3091_2201.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8824_18870.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3545_1475.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8897_4834.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7867_6265.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3673_8625.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10895_9809.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8544_14698.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2145_12286.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_3995_674.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_599_2918.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_3610_16437.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_3809_18797.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_4130_5888.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2710_20323.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_9202_15379.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1363_10649.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_10693_4427.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_5655_4217.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_10579_4374.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1464_1391.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_9387_17604.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_7403_3034.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_9148_2730.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1593_19126.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_3419_19629.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_3836_17839.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_7729_115.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_6726_77.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1519_540.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2615_2393.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_3180_3528.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_146_4558.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2631_4254.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_265_305.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_4775_15815.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_4095_5836.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_131_1365.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_4102_4853.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_7506_14880.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_10358_2281.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1728_4473.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_7673_15377.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1376_5902.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_8515_16124.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2588_6106.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_3367_5763.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_959_2886.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1836_7811.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_301_5963.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_10249_4513.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_5094_7498.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_5592_6439.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2856_6298.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_10899_5896.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1544_11797.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_5869_10465.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_5344_17279.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_8084_1967.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_10413_16500.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2347_14973.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_839_17199.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_418_3694.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1473_19019.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_10151_8178.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_7165_14541.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1837_2511.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_13_6334.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2003_423.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_5502_14294.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2755_18359.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_4915_13743.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_9931_17908.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_4774_15743.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_968_3634.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_5100_3629.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_10852_2896.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_8640_15657.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_3327_15805.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2453_10887.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1538_4012.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_4917_9352.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_9862_3796.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_8581_18058.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2617_6177.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_10883_4172.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_4007_365.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_4402_7206.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1729_808.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1994_2441.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_7743_2901.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_8650_4493.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_78_2764.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_8839_4352.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_10468_1041.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_3307_4216.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_390_18092.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1843_6451.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_7677_15728.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_5753_15814.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_6_4880_16388.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_240_4304.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_342_18309.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_9900_17941.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_264_5684.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_6_9226_13384.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_3974_15689.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_3857_3428.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_4832_15350.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_1981_19348.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_5_8814_3602.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_5_10815_8150.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_5_10324_6627.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3578_6846.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_316_13986.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10467_13254.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4447_6243.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4187_15412.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_150_16794.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6131_19285.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2617_9582.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10838_2750.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7166_7242.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8289_3150.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5511_19402.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_606_15764.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3533_12708.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1584_14595.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8892_19266.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2229_10505.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5494_15770.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4756_20088.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1017_12118.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8195_16643.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10251_13510.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6195_16873.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_595_7160.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9609_13269.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10140_13918.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2208_12776.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9759_13967.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1354_20173.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9081_3072.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6848_5071.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10254_14902.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7092_4801.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3801_19930.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6169_8878.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8657_16545.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5531_13186.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1435_14250.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10802_417.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2088_13720.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10649_15177.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1851_10578.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10085_6838.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5236_6680.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3621_13682.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1305_8204.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9565_14328.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9107_19608.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3703_7535.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2263_11402.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7437_4449.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3837_17701.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8336_8718.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8866_9215.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9136_17085.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5469_6072.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7846_14444.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1811_7842.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8532_4452.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6709_18212.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9844_18526.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2225_19514.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9852_17324.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_31_20901.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7318_13922.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6919_9272.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9228_9955.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3929_12062.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9720_1845.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7694_1560.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5423_15492.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2457_19421.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9935_10929.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8327_12587.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_729_14751.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3316_10776.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2205_7037.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10573_6652.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4283_18962.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8738_19484.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6814_6089.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8865_1760.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5178_11552.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8725_14138.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8079_16935.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8955_19806.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_656_8630.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7072_7434.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4996_6848.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7663_14715.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10404_18965.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4734_18096.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9173_2230.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10689_5546.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7653_17900.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10372_19234.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8074_11211.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3483_11448.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9900_15428.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7416_5690.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8232_1298.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5255_6372.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4420_13639.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8960_13279.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8310_15037.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_713_16402.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6744_7925.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10073_18846.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9533_1281.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7345_18005.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_410_7999.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10671_3559.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3196_17729.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7700_20491.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5026_10555.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10861_9068.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10468_16162.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3718_19020.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5954_4068.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9054_2346.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3200_11564.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8535_9291.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2021_7258.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10297_2964.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7587_1196.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_671_8561.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6206_3170.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10457_5784.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3413_19643.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2834_13288.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9915_6658.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3137_14776.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5536_14930.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7295_10992.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4543_11033.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8498_12070.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1054_15248.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7421_16791.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_46_7863.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_280_6302.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7987_1308.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8275_7123.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4688_10171.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2360_19452.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8554_16747.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6993_16083.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8096_4420.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_679_18972.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8093_10709.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6154_15454.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_820_16865.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8818_4609.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10567_2178.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6750_8971.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8111_12057.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5980_16258.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5826_4145.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7507_12022.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7791_10607.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8741_5520.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5865_12627.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9608_2329.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2964_14434.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2065_8292.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2951_15063.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_860_10752.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7902_1871.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9526_9878.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8104_11262.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4775_4014.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4986_8430.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10396_14482.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4220_6223.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1230_14386.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7811_17003.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9784_12455.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4056_8669.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10556_17644.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9335_6372.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8662_4382.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8662_20852.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7958_14970.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9497_13611.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4702_10394.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1481_7738.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8953_2875.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8769_11951.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_914_17855.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8902_5653.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4233_5635.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3292_12152.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6699_6582.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10728_9362.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10357_11694.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5414_19175.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2804_9855.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2285_20659.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8997_14844.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6991_4076.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10355_20267.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4152_6436.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1079_9919.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1683_15091.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8340_4049.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1149_15655.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_759_8256.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4854_20873.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4814_12077.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3652_14943.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1014_18299.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7826_11681.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8095_17330.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6384_10684.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7378_13993.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7235_20393.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10298_5983.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1121_8518.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3104_14859.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4317_10413.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7457_20494.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1876_7780.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7422_12625.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4824_17210.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5506_17377.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4362_9708.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1547_11989.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8883_17890.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1739_12880.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_92_12521.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6849_5393.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6721_13772.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_339_6637.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10847_12387.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6219_3651.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5224_17928.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9461_16327.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7559_4153.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9789_152.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9502_16315.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8206_11659.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9864_17875.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9650_18411.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9589_1099.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10627_14475.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_799_13489.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9721_17428.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9897_6311.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_61_14933.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10720_17994.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2170_12110.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8597_11811.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4216_9205.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1138_12340.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6544_9049.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10590_337.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1630_15248.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3142_11911.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6163_3884.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8567_8487.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10854_11822.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10313_5713.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9476_10032.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9270_6071.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7938_945.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7287_695.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8607_7277.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4852_4229.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10060_18825.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10769_4085.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8702_11731.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6333_19097.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9752_18074.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2001_7647.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10846_18684.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5978_3943.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6206_12202.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4704_14115.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7538_1509.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2961_10125.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8548_9382.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4549_11868.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3957_14593.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6636_8610.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9652_10749.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3240_14015.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10473_1361.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4399_17756.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8420_3458.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6874_9669.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5297_17987.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6407_8853.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2191_7276.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10087_12976.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10710_20498.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5500_9809.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2743_1646.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6659_17357.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9549_1023.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8231_7453.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5763_13259.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8433_17023.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6770_1074.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1515_4024.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3440_16264.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2758_9104.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5339_20524.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9075_10412.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5102_17113.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9580_20811.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8616_8681.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3909_7254.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4383_2934.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7919_16904.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3811_13985.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6428_3571.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3158_10885.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9780_1041.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7914_9525.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7935_12742.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1121_1318.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6344_16170.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5248_13448.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4730_10022.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5652_13058.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5998_5890.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4537_19471.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5039_9197.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8289_2874.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9226_3280.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2381_7991.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_163_10437.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3776_8962.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_413_5928.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2860_19375.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5796_10097.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1889_4738.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6867_4807.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1740_9768.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4827_17168.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1678_16785.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1071_11798.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4404_18888.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2728_16108.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1885_17222.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5639_2665.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2870_4806.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9695_17211.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5644_2628.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1112_4054.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3803_12909.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1357_9667.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7536_1891.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1326_3509.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8339_1041.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2280_16878.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9938_19757.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4028_5037.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3535_17443.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1083_13441.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4249_11559.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8289_13594.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5767_9691.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8370_8070.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2488_1436.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4001_1757.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3049_20525.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4613_3929.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5447_3579.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_10086_18383.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8491_8050.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3678_9581.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5174_19251.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4253_14487.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3912_18142.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5719_6540.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2500_6275.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7288_16054.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3616_1974.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6515_8905.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3910_10893.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8054_19733.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5431_15974.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5625_14279.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7822_8500.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2468_8044.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5521_12544.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6994_3804.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6192_7741.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2978_20006.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7012_6804.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9303_1629.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2697_1549.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9077_4412.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7601_18063.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1339_19280.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3_16232.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5085_786.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6533_2984.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_151_7082.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5839_15515.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7147_7027.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8954_3087.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1206_4488.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8399_18873.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3748_1229.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1263_11448.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1457_14184.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6315_6612.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5689_5823.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_738_6547.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8969_18472.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_91_18845.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1026_15058.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_492_14265.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9375_3555.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9403_4277.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5293_8249.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5881_11624.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3433_7617.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_229_11757.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6991_2102.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3430_6948.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4990_2513.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_317_8672.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3784_9454.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7799_15126.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2092_2918.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6526_18130.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5331_20206.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6390_4665.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3614_7919.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8488_10831.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1282_17847.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_782_2800.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2935_11171.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4900_8700.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_291_9246.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_91_6010.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7974_12690.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_204_1844.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3442_6640.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4577_3638.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5370_16848.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5028_18522.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_10435_588.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2312_20581.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6233_4726.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4573_15110.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3522_4842.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3340_1477.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2802_16917.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3472_358.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1_13746.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7303_4651.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5199_10818.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8565_12036.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7915_20909.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4001_8094.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1355_11957.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_10545_7702.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5479_3199.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7815_1905.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4563_19384.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3537_19848.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5114_3953.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5778_10604.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4223_18354.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4495_953.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5261_866.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4666_18687.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7252_13281.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8955_18159.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1984_10254.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6070_77.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6407_14975.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5067_19145.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9881_3412.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6095_9930.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3961_3035.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4998_5367.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3464_2742.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1327_12107.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2509_14190.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6983_4815.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_671_17173.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6859_19117.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2414_7045.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7981_10298.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2198_16289.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_587_8080.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2991_11095.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5055_13318.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_654_2069.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4580_11575.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6318_4534.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7881_11103.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1561_5232.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5060_13238.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9169_2180.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2303_20377.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3942_9475.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8148_17869.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4061_3635.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1374_13898.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3664_9928.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2516_7655.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2205_7696.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2668_10345.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1105_4076.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9207_16875.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1980_14772.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5546_19353.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_47_4783.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4705_3911.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5773_3984.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1991_6899.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6955_8159.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1295_20854.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7471_20202.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4830_9987.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_854_13443.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6875_4717.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2785_19784.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7398_20273.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5868_7203.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6055_19005.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1988_2540.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8115_16565.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3493_675.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8957_20785.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7738_1622.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5184_12336.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_10385_18511.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3541_15688.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6612_20567.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7300_9603.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7231_19016.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_10354_19242.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2961_8265.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5438_18406.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_10891_9416.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1838_17937.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4226_14231.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7391_2612.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1488_9451.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5594_14939.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7753_2764.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2583_2519.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6624_12663.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9305_3446.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8876_1625.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1228_12357.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9965_3108.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5835_1453.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3046_5179.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_473_7595.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1155_11521.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6144_13124.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_10167_20683.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1974_20803.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8272_3999.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8871_10995.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8347_13770.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_541_14883.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1463_16326.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3208_11978.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6447_19419.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5030_15890.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3725_13675.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4647_3465.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9770_344.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6058_7729.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9742_20490.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7899_14493.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3604_7603.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9048_1242.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7745_16770.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4093_17544.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8916_10442.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3480_16579.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_8693_13271.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_7978_17626.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5057_12799.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_9269_17230.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7708_15277.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_1272_3185.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_6_10224_16476.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_8562_14838.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_8768_5088.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_6632_19641.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_9591_7716.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_7883_10190.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_9498_14713.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_9063_6778.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_8532_9103.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_7452_9000.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_8426_15805.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2826_6605.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_5785_7295.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_9914_11978.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_6711_6998.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_7743_1798.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2915_4383.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9917_10229.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7286_6394.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1982_12199.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2718_17009.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8169_2974.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4199_11769.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10169_11830.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2587_2770.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3693_20213.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7947_13832.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7659_8233.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7548_19237.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9959_2867.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8579_7816.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4487_10958.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1413_3225.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_6709_17936.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6888_12922.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3104_11244.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9909_4041.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8524_13752.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9057_11209.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6319_12795.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8167_8230.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9351_20119.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5594_15157.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2595_657.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6420_20560.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6655_12960.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_5534_13536.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9426_17537.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5133_11521.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6651_18660.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1850_10517.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6099_10053.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9052_13633.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2993_3172.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10187_16932.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4339_12373.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7616_7683.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9286_19400.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2707_2704.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5056_13556.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_6864_14575.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8904_10107.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9888_1927.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_768_10823.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7131_18585.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_4743_16551.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3762_10341.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_920_11066.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7784_870.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4561_12394.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10842_10924.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_290_13593.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5729_6540.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5573_14428.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3066_15022.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5455_18889.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_5029_16753.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8187_15377.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8421_970.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8030_10694.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1137_11937.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10728_9737.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_9426_4937.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_7692_11003.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_10300_4742.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_8097_9463.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_8138_9950.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10439_5986.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8651_18203.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4643_12043.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7123_3961.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7209_16047.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1026_10973.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6022_20537.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8585_14311.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7326_1158.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_4931_19216.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_9707_17713.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_7603_8839.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_10062_7854.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_8276_14636.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_6174_17938.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_6848_19290.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_7782_17485.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9114_15397.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10913_18989.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_10304_9603.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_10155_15579.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_8214_10212.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_7221_18197.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7305_13724.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10911_15277.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10481_6667.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10025_3624.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7695_4404.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_435_11607.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_5711_14264.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1694_11701.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8106_12437.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_738_16582.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10321_1684.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9699_11564.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10873_2442.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9036_16279.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_897_16233.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9819_1531.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8403_12919.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8283_4477.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8397_7434.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_5992_11869.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9813_12187.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7025_15400.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8247_17163.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7780_11574.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1966_12362.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10538_17074.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8602_9645.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7351_8067.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1669_13275.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10374_16831.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10554_14054.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_373_10580.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2279_12343.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6069_16101.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_122_14579.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_397_12053.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10362_15601.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2398_13512.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6125_1729.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1527_12777.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8184_14741.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10682_16283.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1785_1187.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6792_3444.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9872_10152.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5136_7943.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6370_14047.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5305_6527.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8117_10954.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2144_15374.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_4848_19455.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1169_16088.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10655_18094.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10693_20128.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2086_3735.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8785_2372.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10243_1513.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7836_20790.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8806_12839.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9594_7202.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8294_3330.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_4444_17774.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4478_20303.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_658_3606.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1770_17613.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7573_6590.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7786_16124.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6652_19844.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8512_19199.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9785_12688.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9902_10129.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2058_11742.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8667_10126.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6182_13065.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7723_11848.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7983_19443.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4414_5962.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9280_1762.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4531_18733.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8728_14525.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3320_12742.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4890_11624.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10609_18138.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7291_8531.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9669_2401.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1122_16608.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1337_13206.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_415_12865.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8101_3706.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10234_12526.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10221_10992.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1233_14321.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_4896_15939.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1664_14464.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9003_20857.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9770_20673.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1515_11218.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10518_18310.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3444_3932.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7785_20641.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4406_10484.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3566_15413.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2125_17246.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5596_6659.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9778_16208.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10750_15683.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8733_9941.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5007_13505.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1501_14700.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7374_11670.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2618_1061.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7275_11752.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3179_11308.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7491_16823.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8579_11429.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_66_15093.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3236_16874.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10529_15482.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_4784_2557.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7432_18762.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_9607_18921.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10111_10343.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4821_2093.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6160_20279.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8027_15055.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7775_11209.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7465_16735.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8219_15884.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8406_18722.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10725_14497.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7904_15351.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_6603_20838.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8839_17038.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8011_13028.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_6_10856_16381.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_6_9379_12548.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_6_9804_12626.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_1772_13132.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_10116_13084.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_6_8319_18177.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_4292_14671.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_877_18901.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_6_6488_13477.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_6772_17750.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1366_5734.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2285_11048.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_9277_15072.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_1840_19293.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_813_12828.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_7883_15712.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_272_252.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7155_14768.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10813_10229.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9843_11189.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3166_1855.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4251_6328.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7640_20537.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2286_15422.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10856_4585.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8248_5064.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7645_11832.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9000_11203.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10131_14604.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8017_14656.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5725_14246.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7671_19887.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10282_18243.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8541_15831.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1589_13768.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8301_12674.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8966_5751.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4320_13904.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10031_18235.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_485_5532.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_6472_18010.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9832_17067.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_558_12392.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8115_14863.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7602_11379.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_9741_11825.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_10764_4575.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_7951_8804.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_8322_10315.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_9135_17264.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_5563_18100.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_7328_14631.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7998_16824.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5978_20441.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2202_5218.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8096_6454.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2772_2140.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_434_4620.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1164_13086.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5460_16251.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2357_18209.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6022_12241.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4288_17738.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1146_11567.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8697_10374.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5455_17938.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10872_5205.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3763_15249.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8898_8514.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2389_10028.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7181_7002.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4589_12289.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8922_15885.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7792_7101.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7721_5547.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2636_15827.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4612_18945.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9967_5949.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5344_17826.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8188_18589.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7085_18415.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3419_2573.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7300_12331.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7647_8492.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4348_19014.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1495_12460.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5354_14868.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_18_15953.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3644_19942.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5649_11922.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2117_11354.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4337_13428.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5456_12358.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_880_3192.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6056_14836.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1635_10746.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_4866_14875.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1126_20137.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_4773_11230.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1922_17830.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_9_1305.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2594_11344.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2736_11081.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_9320_4390.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_5605_10555.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_4263_454.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_4022_6225.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_6927_6359.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_411_13716.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_6127_17258.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_5945_6825.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_3045_4505.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_10022_2485.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_871_14453.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1328_4165.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_4489_11267.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2765_5798.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_10379_7436.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2117_3708.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_5169_143.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_8073_12947.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_3875_16921.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_10604_4613.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_8473_9579.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_6979_11464.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_6623_1161.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_10183_14399.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_5403_17005.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_8564_15506.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_4210_15733.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_4862_15205.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_8077_14563.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_10662_7989.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_7608_528.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1996_2501.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_4757_14574.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1733_2731.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_4933_15471.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_9370_17667.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_948_9902.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_5173_6268.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2266_13089.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_10112_16889.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_8467_7169.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2950_18016.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_4579_4327.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_3197_2271.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_6063_15267.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_385_5831.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_9512_3333.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1075_17864.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_559_264.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2357_619.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_736_18781.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1157_19340.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_5758_7520.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_8957_15672.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_9703_8198.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_6295_16798.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2885_9384.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_8059_53.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1903_311.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2952_16796.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_6713_20404.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1190_2403.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_4243_507.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_9680_10926.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_7022_875.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_6731_5484.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2719_4586.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_5028_9362.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1980_4599.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_9604_2512.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_8069_4141.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_3388_14705.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_3525_2440.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2646_688.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_3323_2347.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_308_3980.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_8424_13575.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_3923_18596.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_6_5217_16416.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_6_7883_13312.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_5_8503_4509.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7816_2046.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2494_7207.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7977_19489.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1532_8522.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1009_16421.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2250_15760.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8823_19279.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8328_8286.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5978_16421.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10336_570.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5504_19137.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5163_12182.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2406_16848.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9096_2848.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4125_6598.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5128_7534.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8588_6502.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_525_10428.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8322_1369.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10104_17658.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5332_10988.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8794_3782.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6576_6662.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8153_14343.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4086_10859.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5939_8377.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1450_16519.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9675_2558.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7405_17021.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8559_20798.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1239_15666.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6410_8461.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3379_12949.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4837_6828.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8564_16445.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8260_17212.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5491_5119.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3642_14597.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8338_10112.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3292_12338.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8791_8991.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1613_17569.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6680_5407.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4307_13382.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1120_9580.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9113_17711.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5715_3550.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_422_15027.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10388_2188.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7191_3099.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3350_11688.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3514_17417.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6512_5373.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2776_15098.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8242_10664.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6613_17154.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2945_11692.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5795_6141.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4535_19539.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9952_15608.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3113_9378.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10729_13262.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1910_12630.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6309_14949.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7633_13674.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6094_11205.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5037_12083.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_630_13241.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1612_15459.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10167_17304.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_905_15518.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6088_15558.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3324_13488.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9057_12279.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1432_14935.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7676_17319.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5332_15298.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8026_10737.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10802_2735.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2951_10367.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8259_17615.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4313_7948.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8801_3399.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6504_20443.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10400_9633.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8719_7394.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_629_10510.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7228_3214.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7268_2917.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4052_18313.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6780_7409.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7250_9707.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9347_6873.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3523_16976.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6806_17985.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2644_20561.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3257_7663.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6690_11873.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10190_5259.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10562_7052.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_432_3201.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2335_19446.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9624_7052.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3554_14644.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7756_9776.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4281_15051.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6317_7644.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1474_7482.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_791_4420.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6579_4747.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_360_15033.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1033_19953.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7582_14738.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3295_8187.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2541_18962.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8552_10738.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1589_6189.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9280_13557.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8268_5970.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10396_10190.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7545_16428.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7273_1771.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9715_17337.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1873_10183.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6769_13592.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3232_14969.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10311_3098.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1304_14867.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6665_10910.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6092_16199.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1118_11492.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7953_17676.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3593_8221.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7050_9747.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7422_13425.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3389_10393.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7556_7600.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7881_7075.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2097_13919.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1310_16264.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4983_9798.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2378_16591.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7036_19056.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3207_15658.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5607_5153.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2149_17091.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6402_15378.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7941_9343.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8658_14213.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2972_20207.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10176_18539.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9578_5069.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6334_18915.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4991_19950.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7719_20515.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3202_20087.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6510_5934.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4085_8840.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4730_8155.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10000_14057.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3884_20029.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3869_16908.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9268_16483.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9137_18876.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_303_17191.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1590_12303.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7710_8783.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6615_14946.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8601_17934.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4932_4540.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4592_15120.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1489_12866.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4632_6635.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5849_3145.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5432_20113.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7021_1619.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4152_11733.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6921_10694.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7617_11876.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9501_17533.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1685_7914.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10038_16492.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9718_7140.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5561_4651.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4778_16249.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7673_2579.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1029_10372.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_289_15793.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9998_1672.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4561_4464.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3486_8119.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9352_19773.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10227_3219.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8306_4599.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8360_4008.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3038_12477.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_797_8411.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6642_15496.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10771_15604.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10210_17003.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7764_11667.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5859_6749.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1436_12309.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5558_9642.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4010_9766.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5531_20043.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5675_16106.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8304_12150.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5911_20371.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9753_17029.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8929_15163.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3268_18850.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5470_20603.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9379_15379.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9993_1249.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4577_10464.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_390_17543.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6091_9315.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8601_11280.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2088_9626.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8051_5553.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7517_3284.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5551_4422.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4572_9762.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6975_11900.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3365_18723.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8034_9261.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8996_3212.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8364_14744.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10751_11628.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4126_19486.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7978_8509.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7947_11146.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7040_3257.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4201_18942.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9942_10928.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9990_18695.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4848_10616.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10539_9425.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4431_13182.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6585_13623.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9499_10486.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1844_13833.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10012_16307.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6988_17900.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8019_5754.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3884_10683.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10029_1004.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7333_9577.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4596_17503.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9302_6182.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_986_7065.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10519_17550.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5622_3311.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_384_16080.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6590_1439.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_603_10737.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_388_20130.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8391_11739.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4273_6950.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_178_11212.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7594_808.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7971_8904.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6354_8483.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1063_16295.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4620_11886.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4194_10583.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_661_20583.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10369_13655.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_952_14624.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8199_6243.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5500_17007.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3404_15893.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8177_9808.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_240_11154.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9560_15633.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6834_8084.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9601_17822.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8163_17441.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6124_12681.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5657_5972.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9076_3678.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_470_17612.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7226_7381.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9244_8716.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2257_20820.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4295_16952.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5759_514.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7240_18805.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5039_6772.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8676_4503.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2759_15962.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5037_7439.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_10742_17660.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7071_6221.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5803_16385.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8325_2519.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2871_19862.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7293_20522.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2566_3585.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2350_15243.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8740_12143.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9128_5787.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1237_4591.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7378_3357.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6202_15064.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5960_18491.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7576_5360.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3143_20094.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3399_13312.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5726_4760.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4854_1500.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8936_9463.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1831_9039.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_10412_3176.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2934_20039.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5579_17416.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_868_13008.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3033_15758.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6842_18036.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8221_7117.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8290_8997.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3881_779.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1307_11639.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5099_4923.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4527_15208.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2673_16153.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8231_10387.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_10009_923.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3854_12027.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_872_5523.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5385_6805.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3384_11354.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8858_2184.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2155_16353.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4821_4708.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2547_10345.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4549_2807.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6032_4818.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8121_3754.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9032_12173.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5981_20352.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3401_12172.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3003_7136.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9976_19615.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1695_17690.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4178_9132.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3688_14174.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5216_400.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3385_7625.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7874_6692.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8538_7173.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3169_3900.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6313_14948.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6550_375.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4005_16004.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1889_10969.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9268_5019.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2344_12245.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3735_2138.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8858_1032.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2904_13051.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6768_5829.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3665_9470.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8634_18986.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4343_20628.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6552_20881.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_466_9730.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6031_7176.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_631_7210.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8391_17176.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7169_8746.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_59_17376.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9351_5452.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1741_12329.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1259_13527.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3972_4690.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7199_7838.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1438_8348.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5983_13525.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4197_16569.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4874_542.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7004_20281.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7822_8536.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2581_13033.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8844_13653.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8144_6395.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5554_9788.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7852_12282.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1433_19545.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_880_8750.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1383_9362.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_853_9731.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4922_2817.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3020_18270.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1030_15785.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4002_14548.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_10364_3764.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2837_9770.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6691_15800.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5903_12604.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_10524_6965.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7709_18023.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1530_16384.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9347_16224.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7698_19102.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1394_20586.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8334_12388.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6079_13911.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6706_12972.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_10697_6977.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2810_11870.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8429_2466.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1357_9630.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1425_3603.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7398_16555.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6094_19026.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3893_13691.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_232_13449.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6093_13806.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1793_611.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7961_19322.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4081_8378.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_989_14668.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8139_18796.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6167_4962.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3242_14868.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2289_20210.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8068_18227.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3169_17793.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4431_9565.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6821_8928.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3319_5666.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5432_8232.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2633_16981.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9957_2914.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8373_18816.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2036_10208.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9868_6569.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_897_3446.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7060_14200.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5548_18009.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8214_11512.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4815_2619.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4867_15159.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2591_9335.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8017_3854.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6843_20208.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4682_922.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_550_15554.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3981_1419.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3023_1883.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9288_10304.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6243_12404.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4821_5250.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5253_1477.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2837_8412.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7193_141.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6658_12882.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_636_10731.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2454_13678.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3533_14110.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9569_10202.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3471_8084.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5985_4339.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6609_12752.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5014_10711.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_965_7141.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3490_19333.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1260_16640.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1319_14921.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1688_11403.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6785_9776.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8702_8447.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1788_20348.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_10304_957.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_387_15290.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3049_13520.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3220_15188.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2767_12362.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4870_9079.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4016_12668.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7107_19656.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7985_8249.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3238_11826.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7176_16543.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3431_11573.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3490_9157.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_10620_19678.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7277_991.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1631_13569.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7768_574.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3833_7480.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5453_1695.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1350_2108.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3554_10093.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_740_14659.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4487_6202.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_204_13809.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4696_11038.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6262_7494.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7824_14537.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7310_10117.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6948_2893.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7570_19188.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2361_8991.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3236_15251.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7517_12253.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6388_10884.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7893_20016.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1104_9198.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6355_4111.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4346_8377.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7102_19632.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5767_11731.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2578_2703.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4681_17704.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6388_1694.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6317_13265.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2380_8446.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2433_15427.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_10150_8912.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6350_1505.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1432_4214.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9643_518.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4930_5882.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1041_5159.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_52_6437.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_10204_860.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8633_18244.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5871_19533.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8321_15598.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9614_1916.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3217_18590.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_222_8771.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9757_509.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3088_4346.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1415_15613.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6881_20765.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9621_20011.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_10659_1529.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7767_13110.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1312_9645.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4365_4087.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2644_2158.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2558_11892.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2198_5816.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2205_3006.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4532_8706.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7259_17593.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_26_15392.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1253_14928.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3922_7382.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3034_825.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3146_12012.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2607_4557.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7222_17356.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_771_15383.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1092_1603.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_10807_20787.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3676_17765.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7586_7509.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2082_2944.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3320_1482.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2358_4241.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_8203_12695.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_10213_20688.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_6072_13941.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_2341_2311.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_10177_9645.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_6163_18692.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_3399_20826.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2543_12045.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1288_12487.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_5083_6938.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_10797_7690.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_8339_9744.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_176_4210.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_6_8739_17256.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_4842_1104.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_3951_11119.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_9839_7914.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_10709_15493.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2264_19556.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_3385_10073.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4079_12193.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2459_10000.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8170_20147.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2672_13014.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2004_15042.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8341_10392.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3709_8682.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8872_6062.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3182_14916.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6820_4120.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8486_17746.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8382_10589.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_835_12782.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4949_17517.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8720_2503.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6542_12663.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9245_2739.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10226_6172.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8408_15907.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8228_11937.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7828_18273.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9918_15525.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7042_18127.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6641_11022.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9747_14262.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5189_11157.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9449_3033.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3661_8654.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4978_7114.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8274_12210.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6164_18716.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2688_11896.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_6889_16911.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_154_12483.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6902_14974.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_4849_20159.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_9445_14743.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_211_5675.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2999_3648.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9591_1584.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10845_19073.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6395_12304.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10750_4430.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_6766_9896.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10756_17923.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_9877_16869.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_9380_15803.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7413_17823.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8499_16934.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_10742_11343.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_8346_6249.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_10465_7955.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_725_16787.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6554_17201.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1870_15209.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_694_12349.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_5832_13964.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2087_15806.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7009_13992.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_609_17720.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7322_16823.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9453_10081.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6220_14524.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7103_12438.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10343_3467.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10629_1158.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10002_7094.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6856_19625.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8581_12491.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3559_20747.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7199_9859.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2898_10976.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_6912_11808.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1339_11545.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10061_3500.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10684_11985.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7513_1473.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2397_1285.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1136_13259.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6187_20520.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_913_14686.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7238_4767.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5338_16370.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9757_17140.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7027_4837.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10866_1124.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7005_17502.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4112_14680.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8275_14862.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8283_19679.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5949_20140.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7791_18112.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6160_14669.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6281_15073.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7853_6969.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7269_8482.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1249_11990.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_6618_15341.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1407_4906.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6244_6349.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6707_12990.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4856_16052.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7498_17711.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4531_6946.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_3704_20485.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4356_11188.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8699_11886.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_6865_10711.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1409_1492.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6641_10139.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7246_15869.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9759_20689.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_10172_3474.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_6347_15174.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1725_14391.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3222_1503.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5038_16172.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_6483_14704.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8332_20333.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1182_17933.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6616_17314.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3298_13034.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8513_13200.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7728_15246.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8479_12350.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6676_8878.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_5903_17615.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2764_11394.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10450_19692.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8643_12476.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4700_12822.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4593_18979.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5402_13672.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_10485_14837.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2855_10379.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7286_15644.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9347_178.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4471_12299.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8777_18984.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9161_6242.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_4_726_6100.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3816_19131.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_6_6499_17368.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3762_14149.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7931_16786.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2971_3075.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10641_20842.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6562_13670.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4743_11733.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8181_14595.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_5838_16598.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9094_2068.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_4459_19207.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_9669_15220.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3660_12312.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_8214_4992.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1169_13486.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6779_12426.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2293_3122.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10800_4010.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_8350_16932.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_7369_16859.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_8195_18793.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_7867_9070.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_7960_17804.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_6883_20424.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_8826_9199.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_4_10484_7946.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_7309_11154.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4905_16204.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7646_12146.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_4_6725_16761.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4836_2530.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8745_20180.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_6889_16924.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5950_18734.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_7931_15167.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_8871_16331.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9697_17138.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10408_20353.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5578_12252.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9060_13332.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_4860_10277.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_9577_18822.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2070_16218.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5718_18555.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_2757_11960.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_643_11670.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1331_14027.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_3617_15284.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_5447_13994.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_113_15900.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_10116_11576.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_5_1530_12058.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_8923_12237.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_455_6133.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1379_12720.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_814_18825.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_149_6036.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1441_11427.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_9669_12161.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_6173_17144.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_4099_12079.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_5028_15586.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2257_6343.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_467_2593.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_684_17253.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_5991_12549.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_8730_9346.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_9742_9764.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_10529_4965.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_10222_17358.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_5707_9230.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_10073_10103.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_5795_4098.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_8459_12537.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_3066_17326.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_6572_659.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_7860_17582.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_7954_9978.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_9950_17951.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_9255_17386.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_8663_4790.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_355_6154.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_7551_12760.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_4915_14814.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_7791_20742.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_4354_16749.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_532_20825.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_915_5931.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_7808_214.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_8327_10145.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_9753_17953.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_23_832.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_3875_4690.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_6302_14192.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2860_10896.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_9758_15428.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_9593_11386.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2800_13865.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_337_6271.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_4073_3337.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_6907_985.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2984_14326.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_7196_10430.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_345_20405.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_7007_11887.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_9556_19217.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_10303_16227.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_6807_16528.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_217_17614.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_7911_755.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2077_18665.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_2031_3684.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_1605_10834.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_507_20877.tif  
  inflating: sense_ae_data/edinburgh/image_2020_edinburgh_6_5323_17353.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_6_6245_13236.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_5_8815_3982.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_5_7288_8889.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_5_10858_5143.tif  
  inflating: sense_ae_data/edinburgh/image_2023_edinburgh_5_7395_10627.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3199_11942.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8266_5151.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2415_8689.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5303_5009.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2804_16421.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4669_19431.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1933_19238.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6071_16349.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10214_364.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3391_10194.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6398_15702.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1069_20812.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3489_6876.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5933_14260.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10839_12053.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6504_10259.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9494_13006.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6335_1780.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_998_15948.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6290_20123.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7843_7427.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4399_12961.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6262_14785.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1239_17510.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9465_13178.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3958_13285.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5957_13916.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7576_6536.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10402_5668.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1888_10142.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_925_11065.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7816_1873.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1371_9233.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9771_19811.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10777_3358.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7567_6034.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10857_11945.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7148_16597.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2585_13982.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1351_15444.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6985_9667.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_255_15140.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1031_14988.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4021_12163.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9930_5240.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1440_16488.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4559_10128.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6060_16317.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4560_7354.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6942_13502.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8895_20451.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3921_19042.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_928_15120.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8301_4749.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7658_5803.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10621_10820.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1284_12468.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6017_18922.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9543_5379.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9853_9738.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7066_16594.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9657_17409.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6885_7188.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4816_6513.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4193_15153.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7816_660.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4895_6556.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8481_11348.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6799_4792.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10371_20898.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_996_12898.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2799_9591.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5387_19958.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2576_8817.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_551_9771.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3572_14218.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7561_7462.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4828_16069.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6409_7686.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6177_3799.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3914_17105.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7786_16072.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2491_20845.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3332_13731.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3568_15358.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7312_15375.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8763_15220.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4324_5728.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5248_9000.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8700_5232.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1618_11524.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1616_8380.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7990_11154.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5781_3270.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9121_20043.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_613_9153.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10057_11483.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4521_14119.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9643_5379.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9449_1414.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1732_19870.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10616_2081.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8437_18421.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4764_18390.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3855_14516.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7889_11404.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9198_3390.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9092_16379.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8754_15519.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7730_15067.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7287_4034.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_622_8745.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8289_15761.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6459_3537.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10688_20589.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9669_19632.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8143_15255.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5498_11005.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6779_4484.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6216_18001.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8449_18417.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3947_12033.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9771_167.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7293_6431.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2415_19512.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6435_7495.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2342_14902.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5630_9474.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1358_16843.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8638_16403.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3410_10337.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_39_17139.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9492_20140.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5107_5772.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1901_7463.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2733_9335.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3391_7892.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9084_3646.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3599_8239.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3989_5048.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2005_17380.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6101_6171.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_2715_17950.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6266_6096.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8630_8334.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7107_2272.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9125_19953.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4764_8446.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6762_1765.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_462_7533.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6488_17980.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4216_13921.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5695_12026.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4680_13669.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_8847_15906.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3913_19584.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4504_10555.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5809_6792.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5552_10169.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4138_19154.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3731_12960.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10367_13398.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3317_19343.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5814_14860.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_3894_14142.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7842_19996.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_7685_14112.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10178_6186.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_10079_12290.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_1153_16968.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_9439_16897.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_4022_10144.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_302_19540.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_5680_11808.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6752_4994.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_6_6729_18734.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4951_15030.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6049_3933.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_357_19463.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5088_5154.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_817_3672.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_10150_1279.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8470_4031.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3609_1361.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7729_10166.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2036_10192.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3187_13208.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6652_1099.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_51_6479.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5107_6526.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2126_14711.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3138_16912.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_601_17139.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9656_3008.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_10772_6056.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7797_6478.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1197_14785.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5165_18961.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5619_13130.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2311_11513.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_218_12617.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4835_16459.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7788_1030.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9799_821.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5367_3497.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6102_4181.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_863_9402.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6239_18064.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5069_17808.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7189_4860.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8223_2017.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4088_4364.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5264_1654.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7860_2338.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1774_20286.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1871_15584.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4073_20610.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6221_12231.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6390_4373.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9759_16664.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8366_20195.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1645_10068.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4123_7818.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1308_11003.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3170_7666.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7022_1036.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6426_12511.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1130_7494.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7048_9318.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4132_8926.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6700_19030.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7169_14429.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2451_9744.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3587_19326.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4132_13617.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3460_18524.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4835_10545.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9827_9893.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2323_4401.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3036_17992.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_10432_20278.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1305_14805.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_905_8930.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5465_17185.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5211_5520.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_63_15329.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1875_17874.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7086_13288.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5844_9693.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_77_410.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9226_17245.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_886_12789.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4873_12873.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_89_6081.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_544_19688.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6354_8484.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5601_8657.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5808_6328.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8513_2861.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5809_3002.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6240_13130.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3173_12474.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3813_10839.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4750_2918.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5345_10027.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9628_17701.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5649_15731.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8356_9366.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6350_2984.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4627_1319.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5423_9067.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5610_2678.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1753_14507.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5464_8018.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4065_10225.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4561_13700.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8567_19730.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6577_20453.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5254_13518.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4566_15579.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6253_3327.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4156_867.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_215_12511.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7633_1409.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4706_16918.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4851_20433.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_10887_9361.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7191_14294.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4503_20050.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7908_6884.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6936_14021.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_10278_2246.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7823_6102.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1688_1415.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9239_5420.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2906_20105.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3580_16169.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_10618_5845.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4304_481.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6646_7381.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7320_3782.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8917_19464.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3970_12430.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1092_6729.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7829_9300.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1825_19407.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8928_3188.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3007_14802.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8427_7080.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2321_8399.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_10006_4128.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9412_4994.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1521_6691.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_417_11857.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1587_9550.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9332_4808.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2213_8295.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2110_5417.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_400_7197.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7463_4418.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4809_3305.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4098_10156.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8692_1591.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6096_3561.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9303_18218.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3532_528.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3439_13373.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9540_18580.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2068_533.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3455_18466.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9097_19848.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_992_15465.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2318_7140.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_83_7224.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3485_16759.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5039_2847.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4792_11979.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9234_2676.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3541_3405.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7369_16800.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3326_18605.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4345_525.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_346_13318.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_4382_14420.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3074_6923.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5929_861.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7413_18170.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_1904_5661.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5384_16013.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3951_4267.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3260_4575.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2754_7592.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6404_13695.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3670_4390.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_5701_17237.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6441_3191.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_8194_6342.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7874_19336.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7675_20210.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3403_15651.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_6780_7166.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7580_13812.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_2756_19148.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9647_4817.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_7186_20829.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_10249_19770.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_9848_19479.tif  
  inflating: sense_ae_data/edinburgh/image_2018_edinburgh_5_3358_10220.tif  
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;sense_ae_data/sense_ae_metadata.csv&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;---&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="s1">&#39;location&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                            filename  year location  month
0  sense_ae_data/leeds/image_2018_leeds_5_9622_16...  2018    leeds      5
1  sense_ae_data/leeds/image_2020_leeds_4_1698_10...  2020    leeds      4
2  sense_ae_data/leeds/image_2020_leeds_4_8503_77...  2020    leeds      4
3  sense_ae_data/leeds/image_2020_leeds_4_10448_6...  2020    leeds      4
4  sense_ae_data/leeds/image_2018_leeds_5_1_9246.tif  2018    leeds      5
---
location
leeds        4305
edinburgh    2648
Name: count, dtype: int64
</pre></div>
</div>
</div>
</div>
<p><a name="preparing"></a></p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="preparing-the-data">
<h1>Preparing the data<a class="headerlink" href="#preparing-the-data" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Library imports</span>

<span class="c1"># We use PyTorch for our neural networks</span>
<span class="c1"># import torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>

<span class="c1"># We use these libraries to find and load TIFF files</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">glob</span><span class="w"> </span><span class="kn">import</span> <span class="n">glob</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tifffile</span>

<span class="c1"># For maths and plotting</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># For progress bars</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>

<span class="c1"># For randomization</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#load a directory of tiff files for keras</span>
<span class="k">def</span><span class="w"> </span><span class="nf">load_tiff_files</span><span class="p">(</span><span class="n">directory</span><span class="p">):</span>
    <span class="n">files</span> <span class="o">=</span> <span class="n">glob</span><span class="p">(</span><span class="n">directory</span> <span class="o">+</span> <span class="s1">&#39;/*/*.tif&#39;</span><span class="p">)</span>
    <span class="c1">#we shuffle when we can to avoid any biases being introduced later on</span>
    <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">files</span><span class="p">)</span>
    <span class="n">images</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">filepaths</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">files</span><span class="p">):</span>
      <span class="n">img</span> <span class="o">=</span> <span class="n">tifffile</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">img</span><span class="p">)):</span>
        <span class="n">images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        <span class="n">filepaths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">images</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">filepaths</span><span class="p">)</span>

<span class="c1"># Load the data</span>
<span class="n">data</span><span class="p">,</span> <span class="n">filepaths</span> <span class="o">=</span> <span class="n">load_tiff_files</span><span class="p">(</span><span class="s1">&#39;sense_ae_data&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Found </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="s1"> files&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  2%|▏         | 113/6953 [00:00&lt;00:06, 1128.64it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 6953/6953 [00:09&lt;00:00, 766.87it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Found 6953 files
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_mean</span><span class="p">,</span> <span class="n">data_std</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">data</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;data_mean&#39;</span><span class="p">,</span> <span class="n">data_mean</span><span class="p">,</span> <span class="s1">&#39;data_std&#39;</span><span class="p">,</span> <span class="n">data_std</span><span class="p">)</span>

<span class="c1">#normalise the data so that the dataset has a mean of 0 and a standard deviation of 1.</span>
<span class="c1">#This will improve the model training (see what happens when you train a model without this step)</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span> <span class="o">-</span> <span class="n">data_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">data_std</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>data_mean [0.05510596 0.0637589  0.03778712] data_std [0.00029924 0.00031184 0.00031571]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">unnormalise</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">data_mean</span><span class="p">,</span> <span class="n">std_</span><span class="o">=</span><span class="n">data_std</span><span class="p">):</span>
  <span class="c1">#a useful function for when we want to return an image to its original pixel value range</span>
  <span class="c1">#(for plotting purposes)</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">image</span><span class="o">*</span><span class="n">std_</span><span class="p">)</span><span class="o">+</span><span class="n">mean</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">unnormalise</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">data_mean</span><span class="p">,</span> <span class="n">std_</span><span class="o">=</span><span class="n">data_std</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Unnormalises an image by reversing the normalisation process.</span>

<span class="sd">    Args:</span>
<span class="sd">        image (numpy.ndarray or torch.Tensor): The normalised image with shape (H, W, C).</span>
<span class="sd">        mean (numpy.ndarray or torch.Tensor): The mean used for normalisation, shape (C,).</span>
<span class="sd">        std_ (numpy.ndarray or torch.Tensor): The standard deviation used for normalisation, shape (C,).</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray or torch.Tensor: The unnormalised image.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Reshape mean and std_ to (1, 1, C) for broadcasting</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">mean</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">std_</span> <span class="o">=</span> <span class="n">std_</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Reverse the normalisation</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">image</span> <span class="o">*</span> <span class="n">std_</span><span class="p">)</span> <span class="o">+</span> <span class="n">mean</span>
</pre></div>
</div>
</div>
</div>
<p><a name="autoencoder"></a></p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="training-the-autoencoder">
<h1>Training the autoencoder<a class="headerlink" href="#training-the-autoencoder" title="Link to this heading">#</a></h1>
<p>Since our inputs are images, we use convolutional neural networks as encoders and decoders. Autoencoders applied to images are very often convolutional autoencoders - they perform much better than simpler artificial neural networks.</p>
<p><strong>Encoder:</strong></p>
<ul class="simple">
<li><p>The “encoder” takes an input image (in this case, 64x64 pixels with 3 color channels for RGB) and tries to compress it into a smaller, simpler representation.</p></li>
<li><p>It starts with the original image input.</p></li>
<li><p>Then it passes the image through a series of convolutional layers (Conv2D), each followed by an activation function called ELU and a dropout layer (which helps prevent overfitting).</p></li>
<li><p>These layers gradually reduce the size of the image (downsampling) while learning important features.</p></li>
<li><p>The final output of the encoder is a “latent space” representation, which is a compact version of the input image but with fewer dimensions (in this case, 64 dimensions).</p></li>
</ul>
<p><strong>Decoder:</strong></p>
<ul class="simple">
<li><p>The “decoder” takes this compact representation (the latent space) and tries to reconstruct the original image from it.</p></li>
<li><p>It starts with the compact representation.</p></li>
<li><p>Then it passes it through a series of layers that do the opposite of the encoder: upsampling the image.</p></li>
<li><p>The layers gradually increase the size of the image (Conv2DTranspose layers), with each followed by an ELU activation and a dropout.</p></li>
<li><p>The final output of the decoder is an image that should ideally look like the original input.</p></li>
</ul>
<p><strong>Putting it Together:</strong>
*The “autoencoder” is created by connecting the encoder’s input to the decoder’s output.</p>
<ul class="simple">
<li><p>This creates a full model that takes an image, compresses it into a smaller representation, then tries to reconstruct the original image.</p></li>
<li><p>When training this autoencoder, it tries to minimize the difference between the input image and the reconstructed image. In this case, it’s using the Mean Squared Error (MSE) as the measure of this difference.</p></li>
</ul>
<p><strong>Summary:</strong></p>
<ul class="simple">
<li><p>So, in simple terms, this code creates a model that can compress images into a simpler form (encoder), then expand them back to their original form (decoder).</p></li>
<li><p>This can be useful for tasks like reducing the size of images for storage, removing noise from images, or even generating new images.</p></li>
</ul>
<p>The compile function at the end is just setting up the model for training, using the Adam optimizer and Mean Squared Error (MSE) as the loss function. This means when you train the model on a dataset, it will try to adjust its internal parameters (weights) to minimize the difference between the original and reconstructed images.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>

<span class="k">class</span><span class="w"> </span><span class="nc">Autoencoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A convolutional autoencoder model for encoding and decoding images.</span>

<span class="sd">    Args:</span>
<span class="sd">        input_shape (tuple): Shape of the input image (height, width, channels). Default is (64, 64, 3).</span>
<span class="sd">        dropout (float): Dropout rate for regularization. Default is 0.3.</span>
<span class="sd">        latent_dim (int): Dimensionality of the latent space. Default is 64.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        encoder (nn.Sequential): The encoder network.</span>
<span class="sd">        decoder (nn.Sequential): The decoder network.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Autoencoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>  <span class="c1"># (64, 64, 3) -&gt; (64, 64, 16)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>  <span class="c1"># (64, 64, 16) -&gt; (32, 32, 32)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>  <span class="c1"># (32, 32, 32) -&gt; (16, 16, 64)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>  <span class="c1"># (16, 16, 64) -&gt; (8, 8, 128)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>  <span class="c1"># (8, 8, 128) -&gt; (8*8*128)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">8</span> <span class="o">*</span> <span class="mi">8</span> <span class="o">*</span> <span class="mi">128</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">),</span>  <span class="c1"># Latent space</span>
        <span class="p">)</span>

        <span class="c1"># Decoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="mi">8</span> <span class="o">*</span> <span class="mi">8</span> <span class="o">*</span> <span class="mi">128</span><span class="p">),</span>  <span class="c1"># Latent space -&gt; (8, 8, 128)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Unflatten</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">)),</span>  <span class="c1"># (8*8*128) -&gt; (8, 8, 128)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>  <span class="c1"># (8, 8, 128) -&gt; (16, 16, 64)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>  <span class="c1"># (16, 16, 64) -&gt; (32, 32, 32)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>  <span class="c1"># (32, 32, 32) -&gt; (64, 64, 16)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>  <span class="c1"># (64, 64, 16) -&gt; (64, 64, 3)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass of the autoencoder.</span>

<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): Input tensor of shape (batch_size, channels, height, width).</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Reconstructed output tensor of the same shape as the input.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">latent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">decoded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">latent</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">decoded</span>


<span class="c1"># Instantiate the model</span>
<span class="n">autoencoder</span> <span class="o">=</span> <span class="n">Autoencoder</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>

<span class="c1"># Define the encoder and decoder as separate models</span>
<span class="n">ae_encoder</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="o">.</span><span class="n">encoder</span>
<span class="n">ae_decoder</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="o">.</span><span class="n">decoder</span>

<span class="c1"># Define the optimizer and loss function</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">autoencoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>

<span class="c1"># Print the model architecture</span>
<span class="nb">print</span><span class="p">(</span><span class="n">autoencoder</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Autoencoder(
  (encoder): Sequential(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ELU(alpha=1.0)
    (2): Dropout(p=0.3, inplace=False)
    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (4): ELU(alpha=1.0)
    (5): Dropout(p=0.3, inplace=False)
    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (7): ELU(alpha=1.0)
    (8): Dropout(p=0.3, inplace=False)
    (9): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (10): ELU(alpha=1.0)
    (11): Dropout(p=0.3, inplace=False)
    (12): Flatten(start_dim=1, end_dim=-1)
    (13): Linear(in_features=8192, out_features=256, bias=True)
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=8192, bias=True)
    (1): Unflatten(dim=1, unflattened_size=(128, 8, 8))
    (2): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (3): ELU(alpha=1.0)
    (4): Dropout(p=0.3, inplace=False)
    (5): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (6): ELU(alpha=1.0)
    (7): Dropout(p=0.3, inplace=False)
    (8): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (9): ELU(alpha=1.0)
    (10): Dropout(p=0.3, inplace=False)
    (11): ConvTranspose2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="mf">0.8</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:</span><span class="mi">5500</span><span class="p">]</span>
<span class="n">val_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">5500</span><span class="p">:]</span>

<span class="c1">#x (features) and y (labels) are the same for an autoencoder.</span>
<span class="c1">#It is trained so that the mean squared error (mse) of the training data is minimised.</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">val_data</span><span class="p">,</span> <span class="n">val_data</span><span class="p">),</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5562.400000000001
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>

<span class="c1"># Assuming `data` is a NumPy array or PyTorch tensor</span>
<span class="nb">print</span><span class="p">(</span><span class="mf">0.8</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>

<span class="c1"># Split the data into training and validation sets</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:</span><span class="mi">5500</span><span class="p">]</span>
<span class="n">val_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">5500</span><span class="p">:]</span>

<span class="c1"># Convert data to PyTorch tensors</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">val_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">val_data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Permute the dimensions to match PyTorch&#39;s format: (batch_size, channels, height, width)</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># From (batch_size, height, width, channels) to (batch_size, channels, height, width)</span>
<span class="n">val_data</span> <span class="o">=</span> <span class="n">val_data</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1"># train_data = train_data.to(device)  # Move data to GPU</span>
<span class="c1"># val_data = val_data.to(device)</span>

<span class="c1"># Create DataLoader for training and validation</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_data</span><span class="p">)</span>  <span class="c1"># x and y are the same for autoencoder</span>
<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">val_data</span><span class="p">,</span> <span class="n">val_data</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="c1"># Define the optimizer and loss function</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">autoencoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>

<span class="c1"># Training loop</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">25</span>
<span class="n">history</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="p">[]}</span>  <span class="c1"># To store loss values</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">autoencoder</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>  <span class="c1"># Set model to training mode</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="c1"># Training phase</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>  <span class="c1"># x and y are the same for autoencoder</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>  <span class="c1"># Clear gradients</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Forward pass</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>  <span class="c1"># Compute loss</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># Backward pass</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>  <span class="c1"># Update weights</span>
        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Accumulate loss</span>

    <span class="c1"># Calculate average training loss for the epoch</span>
    <span class="n">train_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>

    <span class="c1"># Validation phase</span>
    <span class="n">autoencoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># Set model to evaluation mode</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>  <span class="c1"># Disable gradient computation</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Calculate average validation loss for the epoch</span>
    <span class="n">val_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>

    <span class="c1"># Print progress</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">, Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Val Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># `history` now contains the training and validation loss for each epoch</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5562.400000000001
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/25, Train Loss: 5121.2574, Val Loss: 3796.7811
Epoch 2/25, Train Loss: 3459.8605, Val Loss: 3257.5244
Epoch 3/25, Train Loss: 3097.1694, Val Loss: 3254.2362
Epoch 4/25, Train Loss: 2884.1536, Val Loss: 3021.7556
Epoch 5/25, Train Loss: 2772.1141, Val Loss: 2990.4764
Epoch 6/25, Train Loss: 2690.1976, Val Loss: 2570.8325
Epoch 7/25, Train Loss: 2479.0168, Val Loss: 2673.3227
Epoch 8/25, Train Loss: 2385.8806, Val Loss: 2432.3891
Epoch 9/25, Train Loss: 2383.9542, Val Loss: 2606.3565
Epoch 10/25, Train Loss: 2254.7624, Val Loss: 2645.0025
Epoch 11/25, Train Loss: 2144.6723, Val Loss: 2276.6262
Epoch 12/25, Train Loss: 2118.7628, Val Loss: 2330.0598
Epoch 13/25, Train Loss: 2159.9579, Val Loss: 2211.1209
Epoch 14/25, Train Loss: 2119.0711, Val Loss: 2525.5415
Epoch 15/25, Train Loss: 2036.3004, Val Loss: 2350.5271
Epoch 16/25, Train Loss: 1992.7909, Val Loss: 2298.0104
Epoch 17/25, Train Loss: 1951.8699, Val Loss: 2426.1814
Epoch 18/25, Train Loss: 2050.9888, Val Loss: 2410.0354
Epoch 19/25, Train Loss: 1956.4651, Val Loss: 2721.4636
Epoch 20/25, Train Loss: 1958.1818, Val Loss: 2224.8980
Epoch 21/25, Train Loss: 1878.6190, Val Loss: 2351.7587
Epoch 22/25, Train Loss: 1875.6083, Val Loss: 2243.1631
Epoch 23/25, Train Loss: 1844.7961, Val Loss: 2181.9269
Epoch 24/25, Train Loss: 1835.7595, Val Loss: 2135.5280
Epoch 25/25, Train Loss: 1771.9960, Val Loss: 1985.9189
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">GradScaler</span><span class="p">,</span> <span class="n">autocast</span>

<span class="c1"># Enable CuDNN benchmark</span>
<span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># Move model and data to GPU</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">autoencoder</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">val_data</span> <span class="o">=</span> <span class="n">val_data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Mixed precision training</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">GradScaler</span><span class="p">()</span>

<span class="c1"># Training loop</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">25</span>
<span class="n">history</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="p">[]}</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">autoencoder</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="c1"># Training phase with tqdm</span>
    <span class="n">train_loader_tqdm</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2"> [Training]&quot;</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">train_loader_tqdm</span><span class="p">:</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="k">with</span> <span class="n">autocast</span><span class="p">():</span>  <span class="c1"># Mixed precision</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="n">scaler</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># Scale loss for mixed precision</span>
        <span class="n">scaler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
        <span class="n">scaler</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>

        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">train_loader_tqdm</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s2">&quot;Training Loss&quot;</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()})</span>

    <span class="c1"># Calculate average training loss</span>
    <span class="n">train_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>

    <span class="c1"># Validation phase</span>
    <span class="n">autoencoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="n">val_loader_tqdm</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">val_loader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2"> [Validation]&quot;</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">val_loader_tqdm</span><span class="p">:</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">outputs</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

            <span class="n">val_loader_tqdm</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s2">&quot;Validation Loss&quot;</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()})</span>

    <span class="c1"># Calculate average validation loss</span>
    <span class="n">val_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>

    <span class="c1"># Print epoch summary</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">, Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Val Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">autocast</span><span class="p">,</span> <span class="n">GradScaler</span>

<span class="c1"># Assuming `data` is a NumPy array or PyTorch tensor</span>
<span class="nb">print</span><span class="p">(</span><span class="mf">0.8</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>

<span class="c1"># Split the data into training and validation sets</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:</span><span class="mi">5500</span><span class="p">]</span>
<span class="n">val_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">5500</span><span class="p">:]</span>

<span class="c1"># Convert data to PyTorch tensors</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">val_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">val_data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Permute the dimensions to match PyTorch&#39;s format: (batch_size, channels, height, width)</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># From (batch_size, height, width, channels) to (batch_size, channels, height, width)</span>
<span class="n">val_data</span> <span class="o">=</span> <span class="n">val_data</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1"># Move data to GPU if available</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">val_data</span> <span class="o">=</span> <span class="n">val_data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Create DataLoader for training and validation</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_data</span><span class="p">)</span>  <span class="c1"># x and y are the same for autoencoder</span>
<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">val_data</span><span class="p">,</span> <span class="n">val_data</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Define the optimizer and loss function</span>
<span class="n">autoencoder</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">autoencoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>

<span class="c1"># Mixed precision training setup</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">GradScaler</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

<span class="c1"># Training loop</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">25</span>
<span class="n">history</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="p">[]}</span>  <span class="c1"># To store loss values</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">autoencoder</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>  <span class="c1"># Set model to training mode</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="c1"># Training phase</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>  <span class="c1"># x and y are the same for autoencoder</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>  <span class="c1"># Clear gradients</span>

        <span class="k">with</span> <span class="n">autocast</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">):</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Forward pass</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>  <span class="c1"># Compute loss</span>

        <span class="n">scaler</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># Backward pass</span>
        <span class="n">scaler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>  <span class="c1"># Update weights</span>
        <span class="n">scaler</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>

        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Accumulate loss</span>

    <span class="c1"># Calculate average training loss for the epoch</span>
    <span class="n">train_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>

    <span class="c1"># Validation phase</span>
    <span class="n">autoencoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># Set model to evaluation mode</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>  <span class="c1"># Disable gradient computation</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Calculate average validation loss for the epoch</span>
    <span class="n">val_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>

    <span class="c1"># Print progress</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">, Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Val Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># `history` now contains the training and validation loss for each epoch</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/f438aa92a90a78c5e2154a5003676666ff4e9bad31b94abccdb0bc8c88eca21b.png" src="../../../_images/f438aa92a90a78c5e2154a5003676666ff4e9bad31b94abccdb0bc8c88eca21b.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">val_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(3, 64, 64)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">unnormalise</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">data_mean</span><span class="p">,</span> <span class="n">std_</span><span class="o">=</span><span class="n">data_std</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Unnormalises an image by reversing the normalisation process.</span>

<span class="sd">    Args:</span>
<span class="sd">        image (numpy.ndarray or torch.Tensor): The normalised image with shape (H, W, C).</span>
<span class="sd">        mean (numpy.ndarray or torch.Tensor): The mean used for normalisation, shape (C,).</span>
<span class="sd">        std_ (numpy.ndarray or torch.Tensor): The standard deviation used for normalisation, shape (C,).</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray or torch.Tensor: The unnormalised image.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Reshape mean and std_ to (1, 1, C) for broadcasting</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">mean</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">std_</span> <span class="o">=</span> <span class="n">std_</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Reverse the normalisation</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">image</span> <span class="o">*</span> <span class="n">std_</span><span class="p">)</span> <span class="o">+</span> <span class="n">mean</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">autoencoder</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Ensure the model is on the correct device</span>

<span class="n">brightness</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># Build two rows of 10 images: top row is original, bottom row is reconstructed</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="c1"># Plot original image</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">original_img</span> <span class="o">=</span> <span class="n">val_data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>  <span class="c1"># Transfer to CPU and convert to NumPy for plotting</span>
    <span class="n">original_img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">original_img</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>  <span class="c1"># Change from (C, H, W) to (H, W, C)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">unnormalise</span><span class="p">(</span><span class="n">original_img</span><span class="p">)</span> <span class="o">*</span> <span class="n">brightness</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Original&#39;</span><span class="p">)</span>

    <span class="c1"># Plot reconstructed image</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">11</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>  <span class="c1"># Disable gradient computation for inference</span>
        <span class="c1"># Add extra dimension as the model expects a batch dimension and ensure tensor is on the device</span>
        <span class="n">predicted_img</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="p">(</span><span class="n">val_data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
    <span class="c1"># Move to CPU, detach, convert to NumPy, and squeeze away the batch dimension</span>
    <span class="n">predicted_img</span> <span class="o">=</span> <span class="n">predicted_img</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
    <span class="n">predicted_img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">predicted_img</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>  <span class="c1"># Change from (C, H, W) to (H, W, C)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">unnormalise</span><span class="p">(</span><span class="n">predicted_img</span><span class="p">)</span> <span class="o">*</span> <span class="n">brightness</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Reconstructed&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

<span class="c1"># Reduce spacing between images</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=-</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.07249999018515273..2.4240000832094815].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.12892187812292982..1.0867794617983368].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.19549999972972681..1.1599999718028595].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.07449999766531529..0.5609999961475319].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.08249999879319009..2.24600000442237].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.12460758208436148..1.0961927308988095].
</pre></div>
</div>
<img alt="../../../_images/3097a6d3798621f32f1b4be8411e730e4663c7ab3b6c5b676382cb409815b379.png" src="../../../_images/3097a6d3798621f32f1b4be8411e730e4663c7ab3b6c5b676382cb409815b379.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.decomposition</span><span class="w"> </span><span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">plot_latent_space_2d</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">filepaths</span><span class="p">,</span> <span class="n">brightness</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
    <span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">encoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># Set the model to evaluation mode</span>

    <span class="n">colours</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;red&#39;</span> <span class="k">if</span> <span class="s1">&#39;leeds&#39;</span> <span class="ow">in</span> <span class="n">filepath</span> <span class="k">else</span> <span class="s1">&#39;blue&#39;</span> <span class="k">for</span> <span class="n">filepath</span> <span class="ow">in</span> <span class="n">filepaths</span><span class="p">]</span>

    <span class="c1"># Convert input data to PyTorch tensor and move to device</span>
    <span class="n">data_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Predict the latent space representations with the encoder</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">x_encoded</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">data_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>  <span class="c1"># Predict and move data back to CPU/numpy</span>

    <span class="c1"># Flatten the outputs if necessary (depends on the output shape of the encoder)</span>
    <span class="n">x_encoded</span> <span class="o">=</span> <span class="n">x_encoded</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x_encoded</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Reduce to 2D using PCA</span>
    <span class="n">x_encoded</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_encoded</span><span class="p">)</span>

    <span class="c1"># Plot the embeddings (that are in 2D) on a scatter plot</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_encoded</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x_encoded</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">colours</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>

    <span class="c1"># Plot the idx of images furthest from the origin</span>
    <span class="n">dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x_encoded</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">furthest</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">dist</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="n">labels</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">furthest</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x_encoded</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x_encoded</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="c1"># Show the images furthest from the origin in a row</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Top images furthest from origin:&#39;</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">labels</span><span class="p">):</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">unnormalise</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">furthest</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span> <span class="o">*</span> <span class="n">brightness</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">furthest</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.decomposition</span><span class="w"> </span><span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">plot_latent_space_2d</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">filepaths</span><span class="p">,</span> <span class="n">brightness</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
    <span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">encoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># Set the model to evaluation mode</span>

    <span class="n">colours</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;red&#39;</span> <span class="k">if</span> <span class="s1">&#39;leeds&#39;</span> <span class="ow">in</span> <span class="n">filepath</span> <span class="k">else</span> <span class="s1">&#39;blue&#39;</span> <span class="k">for</span> <span class="n">filepath</span> <span class="ow">in</span> <span class="n">filepaths</span><span class="p">]</span>

    <span class="c1"># Convert input data to PyTorch tensor, permute it to match (N, C, H, W), and move to device</span>
    <span class="n">data_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Predict the latent space representations with the encoder</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">x_encoded</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">data_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>  <span class="c1"># Predict and move data back to CPU/numpy</span>

    <span class="c1"># Flatten the outputs if necessary (depends on the output shape of the encoder)</span>
    <span class="n">x_encoded</span> <span class="o">=</span> <span class="n">x_encoded</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x_encoded</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Reduce to 2D using PCA</span>
    <span class="n">x_encoded</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_encoded</span><span class="p">)</span>

    <span class="c1"># Plot the embeddings (that are in 2D) on a scatter plot</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_encoded</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x_encoded</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">colours</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>

    <span class="c1"># Plot the idx of images furthest from the origin</span>
    <span class="n">dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x_encoded</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">furthest</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">dist</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="n">labels</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">furthest</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x_encoded</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x_encoded</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="c1"># Show the images furthest from the origin in a row</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Top images furthest from origin:&#39;</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">labels</span><span class="p">):</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">unnormalise</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">furthest</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span> <span class="o">*</span> <span class="n">brightness</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">furthest</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_latent_space_2d</span><span class="p">(</span><span class="n">ae_encoder</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">filepaths</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/e3a104456e598d5247c59411cf9a2a5ae79c84233e51c17e55e7d1c9d7918eaa.png" src="../../../_images/e3a104456e598d5247c59411cf9a2a5ae79c84233e51c17e55e7d1c9d7918eaa.png" />
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.10530000000000002..1.11].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.11055000000000001..0.7074].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.04897500000000002..0.7014].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.09300000000000001..0.5184].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.07485000000000001..2.5164].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.13785000000000003..0.37260000000000004].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.05985..0.9783000000000002].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.05084999999999999..0.54195].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.058125000000000024..0.573].
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Top images furthest from origin:
</pre></div>
</div>
<img alt="../../../_images/247ea930f444571b71de3cdd760302ede87c670fd4dc80a37f194b1f25fdd062.png" src="../../../_images/247ea930f444571b71de3cdd760302ede87c670fd4dc80a37f194b1f25fdd062.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([4369, 6863, 6713, 1123,  246, 4716, 2224, 6719, 3343, 6421])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Setup</span>
<span class="n">brightness</span> <span class="o">=</span> <span class="mf">6.5</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">5</span>  <span class="c1"># number of steps in interpolation</span>

<span class="c1"># Assuming ae_encoder and ae_decoder are already defined and moved to the right device</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">ae_encoder</span> <span class="o">=</span> <span class="n">ae_encoder</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">ae_decoder</span> <span class="o">=</span> <span class="n">ae_decoder</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Ensure the model is in evaluation mode</span>
<span class="n">ae_encoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">ae_decoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1"># Data handling: assuming &#39;data&#39; is a numpy array and needs proper conversion and device handling</span>
<span class="n">data_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Adjusting from NHWC to NCHW</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">x_encoded</span> <span class="o">=</span> <span class="n">ae_encoder</span><span class="p">(</span><span class="n">data_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>  <span class="c1"># Encode the data</span>

<span class="c1"># Randomly choose start and end indices</span>
<span class="n">start_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
<span class="n">end_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>

<span class="c1"># Plotting setup</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="c1"># Interpolate between the encodings</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">i</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">z_sample</span> <span class="o">=</span> <span class="n">x_encoded</span><span class="p">[</span><span class="n">start_idx</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">+</span> <span class="n">x_encoded</span><span class="p">[</span><span class="n">end_idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">alpha</span>

    <span class="c1"># Decode the interpolated sample</span>
    <span class="n">z_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">z_sample</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Adjust dimensions and type</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">x_decoded</span> <span class="o">=</span> <span class="n">ae_decoder</span><span class="p">(</span><span class="n">z_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

    <span class="c1"># Prepare the image for display</span>
    <span class="n">patch</span> <span class="o">=</span> <span class="n">x_decoded</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># Assuming output is CxHxW, converting to HxWxC</span>

    <span class="c1"># Displaying the interpolated images</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">unnormalise</span><span class="p">(</span><span class="n">patch</span><span class="p">)</span> <span class="o">*</span> <span class="n">brightness</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.1815849231261767..1.2084719799324073].
</pre></div>
</div>
<img alt="../../../_images/77b3ad0fbbca9a5391066e6fe6c47ad6fbdf3b5332b0f4f4b615d86b373547d2.png" src="../../../_images/77b3ad0fbbca9a5391066e6fe6c47ad6fbdf3b5332b0f4f4b615d86b373547d2.png" />
</div>
</div>
<p>Anomaly detection is one application of autoencoders.</p>
<p>In this dataset, most of the clouds have been removed on purpose. The vast majority of images are therefore cloud-free… But there are some images that have been left in.</p>
<p>Here is how an autoencoder help us automatically find these kinds of images:</p>
<p>We train the autoencoder with the entire dataset. Since most satellite images look cloud-free, the model will learn to discard any uncommon characteristics.</p>
<p>The compressed representation will contain common features representative of most images in the data.</p>
<p>What happens if we try autoencoding a cloudy image?</p>
<p>The result of the decoder will be very different from the original picture.</p>
<p>Our model can’t reproduce this image as easily from the compressed representation, so we know this is an anomaly!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">autoencoder</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">autoencoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1"># Assuming &#39;data&#39; is already loaded as a numpy array</span>
<span class="n">data_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># NHWC to NCHW</span>

<span class="c1"># Get predictions from the autoencoder</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">preds_tensor</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="p">(</span><span class="n">data_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>  <span class="c1"># Run model and move output to CPU</span>

<span class="c1"># Convert predictions back to NHWC for error calculation</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">preds_tensor</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="c1"># Calculate squared reconstruction error</span>
<span class="n">recon_err</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">data</span> <span class="o">-</span> <span class="n">preds</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="c1"># Determine the top N anomalies</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">anomalies</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">recon_err</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="n">N</span><span class="p">]</span>

<span class="c1"># Print reconstruction errors</span>
<span class="nb">print</span><span class="p">(</span><span class="n">recon_err</span><span class="p">)</span>

<span class="c1"># Visualization</span>
<span class="n">brightness</span> <span class="o">=</span> <span class="mf">6.5</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>  <span class="c1"># Adjusted subplot dimensions for clarity</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="n">anomaly_image</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">anomalies</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
    <span class="k">if</span> <span class="n">anomaly_image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># If grayscale, repeat dimensions to avoid matplotlib error</span>
        <span class="n">anomaly_image</span> <span class="o">=</span> <span class="n">anomaly_image</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">unnormalise</span><span class="p">(</span><span class="n">anomaly_image</span><span class="p">)</span> <span class="o">*</span> <span class="n">brightness</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.5473..2.5506].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.129025..10.8576].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.5187..2.4284000000000003].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.19174999999999998..4.331600000000001].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.5414499999999999..6.580600000000001].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.13487500000000002..6.351800000000001].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.20800000000000002..11.434800000000001].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.19824999999999998..2.6962].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.23920000000000005..2.6741].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.13487500000000002..6.4792000000000005].
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[ 711.70941389 1193.20850723 2868.24557985 ... 5294.77212823 1204.91680558
 9160.20714555]
</pre></div>
</div>
<img alt="../../../_images/364363b5f36447aa67de14cee371b3a05964e0f7738f94c97673258f299b5bf6.png" src="../../../_images/364363b5f36447aa67de14cee371b3a05964e0f7738f94c97673258f299b5bf6.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">preds</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
<span class="n">recon_err</span> <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">data</span><span class="o">-</span><span class="n">preds</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">anomalies</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">recon_err</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="n">N</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">recon_err</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span> <span class="n">unnormalise</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">anomalies</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span><span class="o">*</span><span class="n">brightness</span> <span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold">218/218</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">2s</span> 7ms/step
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.4563000000000001..4.810000000000001].
WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.32435..10.904399999999999].
WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.5648500000000001..4.945200000000001].
WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.129025..10.8576].
WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.5414500000000001..6.580600000000001].
WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.5472999999999998..2.5506000000000006].
WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.1677..3.4567000000000005].
WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.48229999999999995..3.205800000000001].
WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0006500000000000186..4.188600000000001].
WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.34060000000000007..5.7096].
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[5135.99007721 1113.65308266 1603.63958333 ... 1593.71768148 2597.81203751
 2037.48341618]
</pre></div>
</div>
<img alt="../../../_images/65bbda3d59a65ced4b9f4793157d8fb6be2ed18d2daccf2815c2c3677409d8a0.png" src="../../../_images/65bbda3d59a65ced4b9f4793157d8fb6be2ed18d2daccf2815c2c3677409d8a0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">brightness</span> <span class="o">=</span> <span class="mf">5.5</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">131</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">unnormalise</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">start_idx</span><span class="p">])</span><span class="o">*</span><span class="n">brightness</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">132</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">unnormalise</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">end_idx</span><span class="p">])</span><span class="o">*</span><span class="n">brightness</span><span class="p">)</span>

<span class="c1">#combine the two images using autoencoder</span>
<span class="c1">#get encoding of both images</span>
<span class="n">enc_a</span> <span class="o">=</span> <span class="n">ae_encoder</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">start_idx</span><span class="p">],</span><span class="mi">0</span><span class="p">)</span> <span class="p">)</span>
<span class="n">enc_b</span> <span class="o">=</span> <span class="n">ae_encoder</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">end_idx</span><span class="p">],</span><span class="mi">0</span><span class="p">)</span> <span class="p">)</span>
<span class="c1">#combine the encodings</span>
<span class="n">enc_combined</span> <span class="o">=</span> <span class="p">(</span><span class="n">enc_a</span><span class="o">+</span><span class="n">enc_b</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
<span class="c1">#decode the combined encoding</span>
<span class="n">dec_combined</span> <span class="o">=</span> <span class="n">ae_decoder</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">enc_combined</span><span class="p">)</span>
<span class="c1">#show the combined image</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">133</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span> <span class="n">unnormalise</span><span class="p">(</span><span class="n">dec_combined</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span><span class="o">*</span><span class="n">brightness</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.19002500000000003..1.8815500000000003].
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 480ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 29ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 37ms/step
</pre></div>
</div>
<img alt="../../../_images/0fd3760e8620247caacd06042d381e4172502c74537d134021878224c56a7e43.png" src="../../../_images/0fd3760e8620247caacd06042d381e4172502c74537d134021878224c56a7e43.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Setup device</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">ae_encoder</span> <span class="o">=</span> <span class="n">ae_encoder</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">ae_decoder</span> <span class="o">=</span> <span class="n">ae_decoder</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">brightness</span> <span class="o">=</span> <span class="mf">5.5</span>

<span class="c1"># Assuming &#39;data&#39; is a numpy array and already loaded</span>
<span class="n">data_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># NHWC to NCHW conversion for PyTorch</span>

<span class="c1"># Preparing plots</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="c1"># Original Image at &#39;start_idx&#39;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">131</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">unnormalise</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">start_idx</span><span class="p">])</span><span class="o">*</span><span class="n">brightness</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>  <span class="c1"># Hide axes for clarity</span>

<span class="c1"># Original Image at &#39;end_idx&#39;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">132</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">unnormalise</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">end_idx</span><span class="p">])</span><span class="o">*</span><span class="n">brightness</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

<span class="c1"># Combine the two images using autoencoder</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="c1"># Get encoding of both images</span>
    <span class="n">enc_a</span> <span class="o">=</span> <span class="n">ae_encoder</span><span class="p">(</span><span class="n">data_tensor</span><span class="p">[</span><span class="n">start_idx</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>  <span class="c1"># Add batch dimension</span>
    <span class="n">enc_b</span> <span class="o">=</span> <span class="n">ae_encoder</span><span class="p">(</span><span class="n">data_tensor</span><span class="p">[</span><span class="n">end_idx</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

    <span class="c1"># Combine the encodings</span>
    <span class="n">enc_combined</span> <span class="o">=</span> <span class="p">(</span><span class="n">enc_a</span> <span class="o">+</span> <span class="n">enc_b</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>

    <span class="c1"># Decode the combined encoding</span>
    <span class="n">dec_combined</span> <span class="o">=</span> <span class="n">ae_decoder</span><span class="p">(</span><span class="n">enc_combined</span><span class="p">)</span>
    <span class="n">dec_combined_np</span> <span class="o">=</span> <span class="n">dec_combined</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>  <span class="c1"># Convert to NHWC for display and numpy</span>

<span class="c1"># Show the combined image</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">133</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">unnormalise</span><span class="p">(</span><span class="n">dec_combined_np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span> <span class="o">*</span> <span class="n">brightness</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.13640000000000002..1.3826999999999998].
</pre></div>
</div>
<img alt="../../../_images/42c57568d9b0bc28346758a6806d9eb6acf5b2dc5f8f064f13ff9fd91208e1ec.png" src="../../../_images/42c57568d9b0bc28346758a6806d9eb6acf5b2dc5f8f064f13ff9fd91208e1ec.png" />
</div>
</div>
<p><a name="variationalautoencoder"></a></p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="variational-autoencoder">
<h1>Variational Autoencoder<a class="headerlink" href="#variational-autoencoder" title="Link to this heading">#</a></h1>
<p>Variational Autoencoders were introduced by <a class="reference external" href="https://arxiv.org/abs/1312.6114">Kingma and Welling (2013)</a>.</p>
<p>A variational autoencoder is a type of autoencoder with added constraints on the encoded representations being learned. Instead of letting your neural network learn an arbitrary function like with the simple autoencoder, you are learning the parameters of a probability distribution modelling your data. If you sample points from this distribution, you can generate new input data samples: a VAE is a “generative model”.</p>
<p>We aim to construct a generative model rather than a basic data structure that merely “memorises” images. At present, we cannot produce any output since we lack the knowledge to generate latent vectors apart from encoding them from images.</p>
<p>By imposing a constraint on the encoder network, we ensure it generates latent vectors that approximately adhere to a unit Gaussian distribution. This constraint is what distinguishes a variational autoencoder from a conventional one.</p>
<p><img alt="image.png" src="data:image/png;base64,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" /></p>
<p><strong>Encoder:</strong></p>
<ul class="simple">
<li><p>The “encoder” part of the VAE compresses an input image into a lower-dimensional latent space.</p></li>
<li><p>It starts with the original image input.</p></li>
<li><p>Then, similar to the previous autoencoder, it passes the image through a series of convolutional layers, followed by ELU activation and dropout layers.</p></li>
<li><p>However, instead of directly outputting the latent representation, it outputs the mean and variance parameters of a Gaussian distribution that represents the latent space.</p></li>
</ul>
<p><strong>Variational Trick:</strong></p>
<ul class="simple">
<li><p>The “Lambda” layer functions to implement a customized lambda function. In this instance, it is utilized to convert the mean and variance into a representation within a latent space.</p></li>
<li><p>This method enables the model to draw samples from this distribution during training, aiding the Variational Autoencoder (VAE) in acquiring knowledge of a smooth and continuous latent space.</p></li>
<li><p>For a Gaussian distribution, we consider our noise as a standard normal distribution, meaning a Gaussian with a mean of 0 and a variance of 1. This noise element is now separate from and not influenced by our model’s parameters.</p></li>
<li><p>A beneficial characteristic of the Gaussian distribution is that to adjust the mean and variance of a sample, we can directly add the mean and then multiply by the variance. This process effectively scales a sample from our noise distribution. The advantage here is that the prediction of mean and variance is no longer dependent on the stochastic sampling operation (the process of generating random samples from the probability distribution).</p></li>
</ul>
<p><strong>Generator (Decoder):</strong></p>
<ul class="simple">
<li><p>The “generator” part of the VAE takes a latent space representation and tries to reconstruct the original image.</p></li>
<li><p>It starts with the latent space representation.</p></li>
<li><p>Then, it goes through a series of layers that gradually upsample the image to the original size.</p></li>
<li><p>Like before, these layers include convolutional transpose layers (Conv2DTranspose), ELU activation, and dropout.</p></li>
</ul>
<p><strong>Noise Layer:</strong></p>
<ul class="simple">
<li><p>This VAE also includes a “noise” layer, which is used during training to make the encoder “variational.”</p></li>
<li><p>The noise layer adds randomness to the latent space, which can help improve the model’s ability to generate diverse outputs.</p></li>
<li><p>During training, a random noise vector is added to the mean and variance before sampling from the latent space.</p></li>
</ul>
<p><strong>Model Assembly:</strong></p>
<ul class="simple">
<li><p>The “var_encoder” is the model for the encoder part of the VAE.</p></li>
<li><p>The “var_generator” is the model for the generator part of the VAE.</p></li>
<li><p>The “var_autoencoder” combines the encoder, noise layer, and generator to create the full VAE model.</p></li>
<li><p>The “var_autoencoder” is what you train to learn the compressed latent space and the reconstruction process.</p></li>
</ul>
<p><strong>Summary:</strong></p>
<ul class="simple">
<li><p>So, in simple terms, this code creates a Variational Autoencoder, which is an advanced type of autoencoder.</p></li>
<li><p>It uses a more complex encoder that outputs the mean and variance of a Gaussian distribution.</p></li>
<li><p>The decoder then takes samples from this distribution to reconstruct the image.</p></li>
<li><p>The noise layer adds randomness during training to improve the model’s ability to generate diverse outputs.</p></li>
<li><p>The model is then compiled for training using the Adam optimizer and Mean Squared Error loss.</p></li>
</ul>
<p><strong>Key Differences from a Simple Autoencoder:</strong></p>
<ul class="simple">
<li><p>The key difference from a simple autoencoder is the variational aspect, which allows for smoother and more structured latent spaces.</p></li>
<li><p>This can be useful for tasks like generating new images, interpolating between images, or exploring the latent space of a dataset.</p></li>
</ul>
<p><strong>How to Use:</strong></p>
<ul class="simple">
<li><p>To use this VAE, you would train it on a dataset of images.</p></li>
<li><p>During training, it tries to reconstruct the original images while also learning a structured and continuous latent space.</p></li>
<li><p>After training, you can generate new images by sampling from the learned latent space.</p></li>
</ul>
<p>This kind of VAE architecture is particularly useful for generating new images that retain characteristics of the original dataset while being completely new and unique.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">VariationalAutoencoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">VariationalAutoencoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
        <span class="p">)</span>

        <span class="c1"># Latent space</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_mu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">8</span> <span class="o">*</span> <span class="mi">8</span> <span class="o">*</span> <span class="mi">128</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc_var</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">8</span> <span class="o">*</span> <span class="mi">8</span> <span class="o">*</span> <span class="mi">128</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>

        <span class="c1"># Decoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="mi">8</span> <span class="o">*</span> <span class="mi">8</span> <span class="o">*</span> <span class="mi">128</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Unflatten</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">)),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">reparameterize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">):</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">log_var</span><span class="p">)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">std</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">eps</span> <span class="o">*</span> <span class="n">std</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">encoded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_mu</span><span class="p">(</span><span class="n">encoded</span><span class="p">)</span>
        <span class="n">log_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc_var</span><span class="p">(</span><span class="n">encoded</span><span class="p">)</span>
        <span class="c1"># Clamping the log variance</span>
        <span class="n">log_var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">log_var</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">10</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reparameterize</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">)</span>
        <span class="n">decoded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">decoded</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span>

<span class="k">def</span><span class="w"> </span><span class="nf">vae_loss</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">):</span>
    <span class="c1"># Reconstruction loss</span>
    <span class="n">BCE</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>
    <span class="c1"># KL divergence</span>
    <span class="n">KLD</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">log_var</span> <span class="o">-</span> <span class="n">mu</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">log_var</span><span class="o">.</span><span class="n">exp</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">BCE</span> <span class="o">+</span> <span class="n">KLD</span>

<span class="c1"># Create the VAE</span>
<span class="n">vae</span> <span class="o">=</span> <span class="n">VariationalAutoencoder</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">vae</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.0005</span><span class="p">)</span>

<span class="c1"># Example forward pass (add a DataLoader in practice)</span>
<span class="c1"># loss = vae_loss(*vae(batch_images), batch_images)</span>
<span class="c1"># optimizer.zero_grad()</span>
<span class="c1"># loss.backward()</span>
<span class="c1"># optimizer.step()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="mf">0.8</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:</span><span class="mi">5500</span><span class="p">]</span>
<span class="n">val_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">5500</span><span class="p">:]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5562.400000000001
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_dataset</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">13</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">shape</span>

<span class="ne">NameError</span>: name &#39;train_dataset&#39; is not defined
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">val_data</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1453, 64, 64, 3)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>

<span class="c1"># Setup device</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>

<span class="c1"># DataLoader setup</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">train_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="c1">#.to(device)</span>
<span class="n">val_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">val_data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="c1">#.to(device)</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">train_tensor</span><span class="p">,</span> <span class="n">train_tensor</span><span class="p">)</span>  <span class="c1"># Assuming train_data is prepared and on the correct device</span>
<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">val_tensor</span><span class="p">,</span> <span class="n">val_tensor</span><span class="p">)</span>  <span class="c1"># Assuming val_data is prepared and on the correct device</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># VAE model, optimizer setup</span>
<span class="n">vae</span> <span class="o">=</span> <span class="n">VariationalAutoencoder</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">vae</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>

<span class="c1"># Define VAE specific loss function</span>
<span class="k">def</span><span class="w"> </span><span class="nf">vae_loss</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">):</span>
    <span class="c1"># Reconstruction loss</span>
    <span class="n">recon_loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>
    <span class="c1"># KL divergence</span>
    <span class="n">kl_div</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">log_var</span> <span class="o">-</span> <span class="n">mu</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">log_var</span><span class="o">.</span><span class="n">exp</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">recon_loss</span> <span class="o">+</span> <span class="n">kl_div</span>

<span class="c1"># Training loop</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">25</span>
<span class="n">history</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="p">[]}</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">vae</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2"> - Train&quot;</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&quot;batch&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">train_bar</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">train_bar</span><span class="p">:</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            
            <span class="c1"># Forward pass</span>
            <span class="n">recon_x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span> <span class="o">=</span> <span class="n">vae</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">vae_loss</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">)</span>

            <span class="c1"># Backward pass and optimize</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            
            <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">train_bar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">train_loss</span> <span class="o">/</span> <span class="p">((</span><span class="n">train_bar</span><span class="o">.</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">))</span>

    <span class="c1"># Calculate average training loss</span>
    <span class="n">train_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>

    <span class="c1"># Validation phase</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">vae</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">val_loader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Validating&quot;</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&quot;batch&quot;</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">val_bar</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">val_bar</span><span class="p">:</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">recon_x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span> <span class="o">=</span> <span class="n">vae</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">vae_loss</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">)</span>

            <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Calculate average validation loss</span>
    <span class="n">val_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>

    <span class="c1"># Print progress</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">, Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Val Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Now `history` contains the training and validation loss for each epoch</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/25 - Train:   0%|          | 0/172 [00:00&lt;?, ?batch/s, loss=4.89e+10]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/25 - Train: 100%|██████████| 172/172 [00:00&lt;00:00, 179.43batch/s, loss=2.08e+9]
                                                     
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/25, Train Loss: 2023857217.4429, Val Loss: 1485144734.8548
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2/25 - Train: 100%|██████████| 172/172 [00:00&lt;00:00, 187.74batch/s, loss=1.55e+9]
                                                     
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2/25, Train Loss: 1386934417.4545, Val Loss: 1402130792.6772
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3/25 - Train: 100%|██████████| 172/172 [00:00&lt;00:00, 185.36batch/s, loss=1.24e+9]
                                                     
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3/25, Train Loss: 1236479025.0589, Val Loss: 1244643092.7681
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4/25 - Train: 100%|██████████| 172/172 [00:00&lt;00:00, 181.76batch/s, loss=1.18e+9]
                                                     
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4/25, Train Loss: 1175290585.8327, Val Loss: 1293409371.3531
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5/25 - Train: 100%|██████████| 172/172 [00:00&lt;00:00, 190.04batch/s, loss=1.21e+9]
                                                     
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5/25, Train Loss: 1123159409.7571, Val Loss: 1139805309.5554
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 6/25 - Train: 100%|██████████| 172/172 [00:00&lt;00:00, 173.42batch/s, loss=1.13e+9]
                                                     
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 6/25, Train Loss: 1072410219.7062, Val Loss: 1058292727.0805
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 7/25 - Train: 100%|██████████| 172/172 [00:00&lt;00:00, 172.66batch/s, loss=1.08e+9]
                                                     
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 7/25, Train Loss: 1013629189.9113, Val Loss: 993276514.3125
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/25 - Train: 100%|██████████| 172/172 [00:00&lt;00:00, 184.01batch/s, loss=9.63e+8]
                                                     
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/25, Train Loss: 958300416.4189, Val Loss: 1008967646.8988
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 9/25 - Train: 100%|██████████| 172/172 [00:00&lt;00:00, 186.82batch/s, loss=9.31e+8]
                                                     
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 9/25, Train Loss: 931885799.4240, Val Loss: 974765622.4418
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 10/25 - Train: 100%|██████████| 172/172 [00:00&lt;00:00, 187.54batch/s, loss=9.36e+8]
                                                     
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 10/25, Train Loss: 937078202.2749, Val Loss: 949435465.0296
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 11/25 - Train: 100%|██████████| 172/172 [00:00&lt;00:00, 176.60batch/s, loss=9.24e+8]
                                                     
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 11/25, Train Loss: 903651526.8887, Val Loss: 902481073.3985
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 12/25 - Train: 100%|██████████| 172/172 [00:00&lt;00:00, 177.42batch/s, loss=8.95e+8]
                                                     
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 12/25, Train Loss: 859039007.4182, Val Loss: 893068041.8004
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 13/25 - Train: 100%|██████████| 172/172 [00:00&lt;00:00, 181.89batch/s, loss=8.4e+8] 
                                                     
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 13/25, Train Loss: 840586700.5673, Val Loss: 908792702.7006
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 14/25 - Train: 100%|██████████| 172/172 [00:00&lt;00:00, 180.62batch/s, loss=8.55e+8]
                                                     
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 14/25, Train Loss: 831076606.9527, Val Loss: 885099115.3861
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/25 - Train: 100%|██████████| 172/172 [00:00&lt;00:00, 182.86batch/s, loss=8.15e+8]
                                                     
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/25, Train Loss: 815803922.0596, Val Loss: 887674797.8527
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 16/25 - Train: 100%|██████████| 172/172 [00:00&lt;00:00, 184.00batch/s, loss=8.77e+8]
                                                     
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 16/25, Train Loss: 806587093.0385, Val Loss: 794224355.5678
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 17/25 - Train: 100%|██████████| 172/172 [00:00&lt;00:00, 185.26batch/s, loss=8.86e+8]
                                                     
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 17/25, Train Loss: 799108041.1695, Val Loss: 832369999.6586
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 18/25 - Train: 100%|██████████| 172/172 [00:00&lt;00:00, 179.51batch/s, loss=8.2e+8] 
                                                     
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 18/25, Train Loss: 806175985.1985, Val Loss: 852431669.2526
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 19/25 - Train: 100%|██████████| 172/172 [00:00&lt;00:00, 180.84batch/s, loss=7.95e+8]
                                                     
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 19/25, Train Loss: 785884630.9469, Val Loss: 875309399.1246
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 20/25 - Train: 100%|██████████| 172/172 [00:00&lt;00:00, 178.83batch/s, loss=8.07e+8]
                                                     
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 20/25, Train Loss: 779687553.9084, Val Loss: 977748457.3379
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 21/25 - Train: 100%|██████████| 172/172 [00:00&lt;00:00, 183.80batch/s, loss=7.81e+8]
                                                     
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 21/25, Train Loss: 776774693.2364, Val Loss: 827402585.3710
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 22/25 - Train: 100%|██████████| 172/172 [00:00&lt;00:00, 181.32batch/s, loss=8.49e+8]
                                                     
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 22/25, Train Loss: 756077286.4000, Val Loss: 854562156.1349
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 23/25 - Train: 100%|██████████| 172/172 [00:00&lt;00:00, 188.52batch/s, loss=8.24e+8]
                                                     
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 23/25, Train Loss: 748060077.2422, Val Loss: 795497700.4047
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 24/25 - Train: 100%|██████████| 172/172 [00:00&lt;00:00, 185.94batch/s, loss=8.44e+8]
                                                     
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 24/25, Train Loss: 756023313.8735, Val Loss: 789119154.8851
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 25/25 - Train: 100%|██████████| 172/172 [00:00&lt;00:00, 180.31batch/s, loss=7.44e+8]
                                                     
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 25/25, Train Loss: 731357260.9396, Val Loss: 742976977.0351
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation loss&#39;</span><span class="p">)</span>
<span class="c1"># plt.ylim(0, 1e10)  # Adjust y-axis limits for better visualization</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/d20c2153a2337ec094f3050eddb17aeeef00124cfe20a2578ea17413ea7f59da.png" src="../../../_images/d20c2153a2337ec094f3050eddb17aeeef00124cfe20a2578ea17413ea7f59da.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">val_dataset</span><span class="o">.</span><span class="n">tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([1453, 3, 64, 64])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">tensors</span><span class="p">)</span><span class="c1">#.shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">val_tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([1, 3, 64, 64])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">vae</span> <span class="o">=</span> <span class="n">vae</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Ensure the model is on the correct device</span>

<span class="n">brightness</span> <span class="o">=</span> <span class="mi">5</span>


<span class="c1"># Build two rows of 10 images: top row is original, bottom row is reconstructed</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="c1"># Plot original image</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">original_img</span> <span class="o">=</span> <span class="n">val_data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="c1">#.cpu().numpy()  # Transfer to CPU and convert to NumPy for plotting</span>
    <span class="c1"># original_img = np.transpose(original_img, (1, 2, 0))  # Change from (C, H, W) to (H, W, C)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">unnormalise</span><span class="p">(</span><span class="n">original_img</span><span class="p">)</span> <span class="o">*</span> <span class="n">brightness</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Original&#39;</span><span class="p">)</span>

    <span class="c1"># Plot reconstructed image</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">11</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>  <span class="c1"># Disable gradient computation for inference</span>
        <span class="c1"># Add extra dimension as the model expects a batch dimension and ensure tensor is on the device</span>
        <span class="n">predicted_img</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">vae</span><span class="p">(</span><span class="n">val_tensor</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
    <span class="c1"># Move reconstruction to CPU, detach, convert to NumPy, and squeeze away the batch dimension</span>
    <span class="n">predicted_img</span> <span class="o">=</span> <span class="n">predicted_img</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
    <span class="n">predicted_img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">predicted_img</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>  <span class="c1"># Change from (C, H, W) to (H, W, C)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">unnormalise</span><span class="p">(</span><span class="n">predicted_img</span><span class="p">)</span> <span class="o">*</span> <span class="n">brightness</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Reconstructed&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

<span class="c1"># Reduce spacing between images</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=-</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.10499999999999998..1.061].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.07149999999999998..1.1425].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.024249999999999966..1.6720000000000002].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.06970498039909041..1.2506686419847268].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.036500000000000005..1.113].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.1175..1.2990000000000002].
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.073..2.882].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.10540136106810491..1.4970297449161643].
</pre></div>
</div>
<img alt="../../../_images/81e7b691a1ac4458ab96f496ceed666b9bfab6418c31b6be6c7fa1e83c9a54e4.png" src="../../../_images/81e7b691a1ac4458ab96f496ceed666b9bfab6418c31b6be6c7fa1e83c9a54e4.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_latent_space_2d</span><span class="p">(</span><span class="n">vae</span><span class="o">.</span><span class="n">encoder</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">filepaths</span><span class="p">,</span> <span class="n">brightness</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/74a1d8927e30fb3a762253e421a8e81b8082b626192ca8e5bb0872fa48fea79d.png" src="../../../_images/74a1d8927e30fb3a762253e421a8e81b8082b626192ca8e5bb0872fa48fea79d.png" />
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.03875000000000001..0.1844].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.0456..0.1602].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.037849999999999995..0.1904].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.04345..0.3804].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.03685..0.2358].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.024950000000000003..0.8387999999999999].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.0421..0.1962].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.019299999999999994..0.23220000000000002].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.039200000000000006..0.08090000000000001].
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.049949999999999994..0.08209999999999999].
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Top images furthest from origin:
</pre></div>
</div>
<img alt="../../../_images/61589c209dac08140ba5a006ff8a6600351e369d74c31102e2f661109a160611.png" src="../../../_images/61589c209dac08140ba5a006ff8a6600351e369d74c31102e2f661109a160611.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([6329, 1160,  570, 5234, 3744, 3539,  594, 2807, 5379, 4129])
</pre></div>
</div>
</div>
</div>
<p><a name="ssl"></a></p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="semi-supervised-learning">
<h1>Semi-supervised learning<a class="headerlink" href="#semi-supervised-learning" title="Link to this heading">#</a></h1>
<p>A pre-trained model such as a VAE can be fine-tuned for a classification task, particularly when labeled data is limited. We will compare the performance of a model that uses a pre-trained autoencoder’s learned features against a model that starts with randomly initialised weights.</p>
<p>The combination of unsupervised learning as a ‘pretext’ task, followed by some supervised learning, is a form of semi-supervised learning.</p>
<p><strong>Feature Transfer</strong>: The encoder part of an autoencoder has learned to extract essential features from the data during its reconstruction process. We will see how these features, even though initially trained for a different purpose, can be extremely useful for classification.</p>
<ol class="arabic simple">
<li><p>Load a pre-trained autoencoder.</p></li>
<li><p>Modify the model to be a classifier.</p></li>
<li><p>Train the model on a semi-supervised dataset.</p></li>
<li><p>Now remake the autoencoder with random initial weights. Compare the accuracy of the pretrained autoencoder to the untrained one, when finetuned to a classification task.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(6953, 64, 64, 3)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#make a classification task to predict whether the location is in Scotland or England. Ensure that the classes are balanced (see sense_ae_metadata.csv)</span>
<span class="n">location</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span> <span class="k">if</span> <span class="s1">&#39;leeds&#39;</span> <span class="ow">in</span> <span class="n">i</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">filepaths</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span><span class="o">=</span><span class="mi">1000</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>

<span class="c1"># Prepare data for classification</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:</span><span class="n">n</span><span class="p">]</span>
<span class="n">val_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">n</span><span class="p">:]</span>
<span class="n">train_labels</span><span class="o">=</span> <span class="n">location</span><span class="p">[:</span><span class="n">n</span><span class="p">]</span>
<span class="n">val_labels</span> <span class="o">=</span> <span class="n">location</span><span class="p">[</span><span class="n">n</span><span class="p">:]</span>

<span class="c1"># Prepare the dataset with labels</span>
<span class="n">train_data_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">train_labels_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">train_labels</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>  <span class="c1"># Assuming location is your label array</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">train_data_tensor</span><span class="p">,</span> <span class="n">train_labels_tensor</span><span class="p">)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">val_data_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">val_data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">val_labels_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">val_labels</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>  <span class="c1"># Assuming location is your label array</span>

<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">val_data_tensor</span><span class="p">,</span> <span class="n">val_labels_tensor</span><span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">SimpleClassifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SimpleClassifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">32</span> <span class="o">*</span> <span class="mi">16</span> <span class="o">*</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>  <span class="c1"># Adjust based on input shape</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">))</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># Train the simple classifier</span>
<span class="n">simple_classifier</span> <span class="o">=</span> <span class="n">SimpleClassifier</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">simple_classifier</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># Use the same training loop as before</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vae</span><span class="o">.</span><span class="n">forward</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;bound method VariationalAutoencoder.forward of VariationalAutoencoder(
  (encoder): Sequential(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ELU(alpha=1.0)
    (2): Dropout(p=0.3, inplace=False)
    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (4): ELU(alpha=1.0)
    (5): Dropout(p=0.3, inplace=False)
    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (7): ELU(alpha=1.0)
    (8): Dropout(p=0.3, inplace=False)
    (9): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (10): ELU(alpha=1.0)
    (11): Dropout(p=0.3, inplace=False)
    (12): Flatten(start_dim=1, end_dim=-1)
  )
  (fc_mu): Linear(in_features=8192, out_features=256, bias=True)
  (fc_var): Linear(in_features=8192, out_features=256, bias=True)
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=8192, bias=True)
    (1): Unflatten(dim=1, unflattened_size=(128, 8, 8))
    (2): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (3): ELU(alpha=1.0)
    (4): Dropout(p=0.3, inplace=False)
    (5): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (6): ELU(alpha=1.0)
    (7): Dropout(p=0.3, inplace=False)
    (8): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (9): ELU(alpha=1.0)
    (10): Dropout(p=0.3, inplace=False)
    (11): ConvTranspose2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
)&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Check for NaNs or Infs in the training data</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;NaNs in train_data:&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Infs in train_data:&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>

<span class="c1"># Check for NaNs or Infs in the validation data</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;NaNs in val_data:&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">val_data</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Infs in val_data:&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">val_data</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>NaNs in train_data: 0
Infs in train_data: 0
NaNs in val_data: 0
Infs in val_data: 0
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">SimpleClassifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SimpleClassifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">32</span> <span class="o">*</span> <span class="mi">16</span> <span class="o">*</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>  <span class="c1"># Adjust based on input shape</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">))</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># Train the simple classifier</span>
<span class="n">simple_classifier</span> <span class="o">=</span> <span class="n">SimpleClassifier</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">simple_classifier</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># Use the same training loop as before</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Training loop</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">history</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;train_accuracy&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;val_accuracy&#39;</span><span class="p">:</span> <span class="p">[]}</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">simple_classifier</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2"> - Train&quot;</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&quot;batch&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">train_bar</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">train_bar</span><span class="p">:</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            
            <span class="c1"># Forward pass</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">simple_classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            
            <span class="c1"># Backward pass and optimize</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            
            <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="n">predicted</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            
            <span class="n">train_bar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">train_loss</span> <span class="o">/</span> <span class="p">((</span><span class="n">train_bar</span><span class="o">.</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">),</span> 
                                 <span class="n">accuracy</span><span class="o">=</span><span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span>
    
    <span class="c1"># Calculate average training loss and accuracy</span>
    <span class="n">train_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">train_accuracy</span> <span class="o">=</span> <span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_accuracy</span><span class="p">)</span>
    
    <span class="c1"># Validation phase</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">simple_classifier</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">val_loader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Validating&quot;</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&quot;batch&quot;</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">val_bar</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">val_bar</span><span class="p">:</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">logits</span> <span class="o">=</span> <span class="n">simple_classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            
            <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="n">predicted</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    
    <span class="c1"># Calculate average validation loss and accuracy</span>
    <span class="n">val_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">val_accuracy</span> <span class="o">=</span> <span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_accuracy</span><span class="p">)</span>
    
    <span class="c1"># Print progress</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">, Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Train Accuracy: </span><span class="si">{</span><span class="n">train_accuracy</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%, &quot;</span>
          <span class="sa">f</span><span class="s2">&quot;Val Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Val Accuracy: </span><span class="si">{</span><span class="n">val_accuracy</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 71.51batch/s, accuracy=59.5, loss=29.5] 
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20, Train Loss: 1.8903, Train Accuracy: 59.50%, Val Loss: 0.7996, Val Accuracy: 62.96%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 98.96batch/s, accuracy=68.3, loss=9.66]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2/20, Train Loss: 0.6180, Train Accuracy: 68.30%, Val Loss: 0.6456, Val Accuracy: 66.84%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 89.30batch/s, accuracy=71.5, loss=8.43]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3/20, Train Loss: 0.5396, Train Accuracy: 71.50%, Val Loss: 0.6184, Val Accuracy: 68.96%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 103.07batch/s, accuracy=74.8, loss=7.68]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4/20, Train Loss: 0.4917, Train Accuracy: 74.80%, Val Loss: 0.6308, Val Accuracy: 69.60%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 98.32batch/s, accuracy=79.1, loss=6.81]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5/20, Train Loss: 0.4359, Train Accuracy: 79.10%, Val Loss: 0.6103, Val Accuracy: 69.73%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 6/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 90.50batch/s, accuracy=80.2, loss=6.3] 
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 6/20, Train Loss: 0.4035, Train Accuracy: 80.20%, Val Loss: 0.6660, Val Accuracy: 69.06%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 7/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 93.39batch/s, accuracy=83.2, loss=0.358] 
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 7/20, Train Loss: 0.3668, Train Accuracy: 83.20%, Val Loss: 0.6486, Val Accuracy: 71.26%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 91.87batch/s, accuracy=86.3, loss=4.96]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20, Train Loss: 0.3177, Train Accuracy: 86.30%, Val Loss: 0.7070, Val Accuracy: 70.79%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 9/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 95.71batch/s, accuracy=83.9, loss=5.3] 
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 9/20, Train Loss: 0.3393, Train Accuracy: 83.90%, Val Loss: 0.6627, Val Accuracy: 72.45%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 10/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 92.75batch/s, accuracy=88.1, loss=4.48]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 10/20, Train Loss: 0.2865, Train Accuracy: 88.10%, Val Loss: 0.7342, Val Accuracy: 71.61%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 11/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 89.46batch/s, accuracy=89.9, loss=3.9] 
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 11/20, Train Loss: 0.2493, Train Accuracy: 89.90%, Val Loss: 0.7047, Val Accuracy: 71.51%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 12/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 98.17batch/s, accuracy=91.6, loss=3.2] 
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 12/20, Train Loss: 0.2048, Train Accuracy: 91.60%, Val Loss: 0.8117, Val Accuracy: 72.69%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 13/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 94.66batch/s, accuracy=91.6, loss=3.34]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 13/20, Train Loss: 0.2135, Train Accuracy: 91.60%, Val Loss: 0.7628, Val Accuracy: 73.36%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 14/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 92.25batch/s, accuracy=93.8, loss=2.79]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 14/20, Train Loss: 0.1785, Train Accuracy: 93.80%, Val Loss: 0.8473, Val Accuracy: 72.60%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 90.84batch/s, accuracy=94, loss=2.5]   
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20, Train Loss: 0.1602, Train Accuracy: 94.00%, Val Loss: 0.8016, Val Accuracy: 71.58%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 16/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 99.64batch/s, accuracy=95.8, loss=2.14]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 16/20, Train Loss: 0.1369, Train Accuracy: 95.80%, Val Loss: 0.7985, Val Accuracy: 72.80%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 17/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 90.87batch/s, accuracy=95.2, loss=2.18]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 17/20, Train Loss: 0.1396, Train Accuracy: 95.20%, Val Loss: 0.9118, Val Accuracy: 73.04%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 18/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 93.32batch/s, accuracy=97.1, loss=1.64]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 18/20, Train Loss: 0.1050, Train Accuracy: 97.10%, Val Loss: 0.9418, Val Accuracy: 72.90%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 19/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 103.79batch/s, accuracy=96.5, loss=1.72]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 19/20, Train Loss: 0.1102, Train Accuracy: 96.50%, Val Loss: 1.0653, Val Accuracy: 73.11%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 20/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 86.80batch/s, accuracy=97.3, loss=1.65]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 20/20, Train Loss: 0.1058, Train Accuracy: 97.30%, Val Loss: 1.0212, Val Accuracy: 72.72%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Plot training &amp; validation loss values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Model Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Plot training &amp; validation accuracy values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Model Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/b8a43c73908ad74ae35e86a5ddd783e6ae24eea7d5cacaf34612373f2586d838.png" src="../../../_images/b8a43c73908ad74ae35e86a5ddd783e6ae24eea7d5cacaf34612373f2586d838.png" />
<img alt="../../../_images/2d6b1130f8337673d986b796ef442a5894684e636e8b30103bd59cddbfc2f650.png" src="../../../_images/2d6b1130f8337673d986b796ef442a5894684e636e8b30103bd59cddbfc2f650.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vae</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1"># Test the VAE on a batch of data</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">test_batch</span> <span class="o">=</span> <span class="n">train_data_tensor</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">recon_batch</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span> <span class="o">=</span> <span class="n">vae</span><span class="p">(</span><span class="n">test_batch</span><span class="p">)</span>
    
    <span class="c1"># Check reconstruction</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reconstruction - mean:&quot;</span><span class="p">,</span> <span class="n">recon_batch</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="s2">&quot;std:&quot;</span><span class="p">,</span> <span class="n">recon_batch</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
    <span class="c1"># Check latent space</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Latent vector - mean:&quot;</span><span class="p">,</span> <span class="n">mu</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="s2">&quot;std:&quot;</span><span class="p">,</span> <span class="n">mu</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Log variance - mean:&quot;</span><span class="p">,</span> <span class="n">log_var</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="s2">&quot;std:&quot;</span><span class="p">,</span> <span class="n">log_var</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Reconstruction - mean: 1.922062635421753 std: 82.76224517822266
Latent vector - mean: -0.4058205783367157 std: 38.14091873168945
Log variance - mean: -9.945394515991211 std: 0.6593005061149597
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">reparameterize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">):</span>
    <span class="n">log_var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">log_var</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">10</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>  <span class="c1"># Clamp log_var</span>
    <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">log_var</span><span class="p">)</span>
    <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">std</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">eps</span> <span class="o">*</span> <span class="n">std</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">VAEClassifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vae</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">VAEClassifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vae</span> <span class="o">=</span> <span class="n">vae</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">vae</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>  <span class="c1"># Assuming latent_dim is 256</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">))</span>
        
    <span class="k">def</span><span class="w"> </span><span class="nf">reparameterize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">):</span>
        <span class="n">log_var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">log_var</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">10</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>  <span class="c1"># Clamp log_var</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">log_var</span><span class="p">)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">std</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">eps</span> <span class="o">*</span> <span class="n">std</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">encoded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vae</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vae</span><span class="o">.</span><span class="n">fc_mu</span><span class="p">(</span><span class="n">encoded</span><span class="p">)</span>
            <span class="n">log_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vae</span><span class="o">.</span><span class="n">fc_var</span><span class="p">(</span><span class="n">encoded</span><span class="p">)</span>
            <span class="n">log_var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">log_var</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">10</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>  <span class="c1"># Clamp log_var</span>
            <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reparameterize</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span><span class="p">)</span>
            
            <span class="c1"># Debug: Print latent vector statistics</span>
            <span class="c1"># print(&quot;Latent vector - mean:&quot;, z.mean().item(), &quot;std:&quot;, z.std().item())</span>
        
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        
        <span class="c1"># Debug: Print logits</span>
        <span class="c1"># print(&quot;Logits - mean:&quot;, logits.mean().item(), &quot;std:&quot;, logits.std().item())</span>
        
        <span class="k">return</span> <span class="n">logits</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialize the VAEClassifier</span>
<span class="n">vae_classifier</span> <span class="o">=</span> <span class="n">VAEClassifier</span><span class="p">(</span><span class="n">vae</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Define the loss function and optimizer</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">vae_classifier</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>

<span class="c1"># Training loop</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">history</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;train_accuracy&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;val_accuracy&#39;</span><span class="p">:</span> <span class="p">[]}</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">vae_classifier</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2"> - Train&quot;</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&quot;batch&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">train_bar</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">train_bar</span><span class="p">:</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            
            <span class="c1"># Forward pass</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">vae_classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            
            <span class="c1"># Backward pass and optimize</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            
            <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="n">predicted</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            
            <span class="n">train_bar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">train_loss</span> <span class="o">/</span> <span class="p">((</span><span class="n">train_bar</span><span class="o">.</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">),</span> 
                                 <span class="n">accuracy</span><span class="o">=</span><span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span>
    
    <span class="c1"># Calculate average training loss and accuracy</span>
    <span class="n">train_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">train_accuracy</span> <span class="o">=</span> <span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_accuracy</span><span class="p">)</span>
    
    <span class="c1"># Validation phase</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">vae_classifier</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">val_loader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Validating&quot;</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&quot;batch&quot;</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">val_bar</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">val_bar</span><span class="p">:</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">logits</span> <span class="o">=</span> <span class="n">vae_classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            
            <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="n">predicted</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    
    <span class="c1"># Calculate average validation loss and accuracy</span>
    <span class="n">val_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">val_accuracy</span> <span class="o">=</span> <span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_accuracy</span><span class="p">)</span>
    
    <span class="c1"># Print progress</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">, Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Train Accuracy: </span><span class="si">{</span><span class="n">train_accuracy</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%, &quot;</span>
          <span class="sa">f</span><span class="s2">&quot;Val Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Val Accuracy: </span><span class="si">{</span><span class="n">val_accuracy</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 87.45batch/s, accuracy=54.6, loss=72.2]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20, Train Loss: 4.6237, Train Accuracy: 54.60%, Val Loss: 2.3837, Val Accuracy: 61.77%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 95.52batch/s, accuracy=59.8, loss=55.8]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2/20, Train Loss: 3.5692, Train Accuracy: 59.80%, Val Loss: 2.1855, Val Accuracy: 62.47%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 95.31batch/s, accuracy=60.6, loss=49.7]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3/20, Train Loss: 3.1834, Train Accuracy: 60.60%, Val Loss: 2.0590, Val Accuracy: 62.24%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 100.20batch/s, accuracy=63.2, loss=41.2]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4/20, Train Loss: 2.6359, Train Accuracy: 63.20%, Val Loss: 2.0413, Val Accuracy: 63.45%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 89.87batch/s, accuracy=64.3, loss=40.5]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5/20, Train Loss: 2.5905, Train Accuracy: 64.30%, Val Loss: 2.0094, Val Accuracy: 63.50%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 6/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 93.11batch/s, accuracy=67.4, loss=36.2]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 6/20, Train Loss: 2.3197, Train Accuracy: 67.40%, Val Loss: 1.9156, Val Accuracy: 62.96%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 7/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 98.70batch/s, accuracy=66.2, loss=31] 
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 7/20, Train Loss: 1.9857, Train Accuracy: 66.20%, Val Loss: 1.9089, Val Accuracy: 62.98%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 92.90batch/s, accuracy=65.9, loss=32] 
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/20, Train Loss: 2.0493, Train Accuracy: 65.90%, Val Loss: 1.8513, Val Accuracy: 62.98%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 9/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 102.15batch/s, accuracy=68.6, loss=27.9]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 9/20, Train Loss: 1.7878, Train Accuracy: 68.60%, Val Loss: 1.7843, Val Accuracy: 63.38%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 10/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 95.26batch/s, accuracy=69.1, loss=29.2]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 10/20, Train Loss: 1.8660, Train Accuracy: 69.10%, Val Loss: 1.7607, Val Accuracy: 63.01%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 11/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 92.31batch/s, accuracy=66.4, loss=31.7]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 11/20, Train Loss: 2.0271, Train Accuracy: 66.40%, Val Loss: 1.6664, Val Accuracy: 62.22%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 12/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 88.48batch/s, accuracy=67.8, loss=25.5]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 12/20, Train Loss: 1.6323, Train Accuracy: 67.80%, Val Loss: 1.7134, Val Accuracy: 63.16%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 13/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 100.77batch/s, accuracy=69.5, loss=23.1]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 13/20, Train Loss: 1.4756, Train Accuracy: 69.50%, Val Loss: 1.6365, Val Accuracy: 62.22%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 14/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 96.44batch/s, accuracy=69.2, loss=24.9]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 14/20, Train Loss: 1.5967, Train Accuracy: 69.20%, Val Loss: 1.5799, Val Accuracy: 62.30%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 92.39batch/s, accuracy=71.3, loss=21.5]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 15/20, Train Loss: 1.3738, Train Accuracy: 71.30%, Val Loss: 1.5875, Val Accuracy: 62.67%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 16/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 92.54batch/s, accuracy=70.8, loss=22.9]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 16/20, Train Loss: 1.4664, Train Accuracy: 70.80%, Val Loss: 1.5462, Val Accuracy: 62.09%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 17/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 96.53batch/s, accuracy=70.6, loss=20.8]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 17/20, Train Loss: 1.3295, Train Accuracy: 70.60%, Val Loss: 1.5357, Val Accuracy: 62.51%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 18/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 100.19batch/s, accuracy=72.2, loss=18.6]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 18/20, Train Loss: 1.1928, Train Accuracy: 72.20%, Val Loss: 1.5170, Val Accuracy: 63.06%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 19/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 101.17batch/s, accuracy=74.4, loss=17.4]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 19/20, Train Loss: 1.1162, Train Accuracy: 74.40%, Val Loss: 1.4685, Val Accuracy: 61.23%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 20/20 - Train: 100%|██████████| 32/32 [00:00&lt;00:00, 87.59batch/s, accuracy=72.4, loss=17.6]
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 20/20, Train Loss: 1.1295, Train Accuracy: 72.40%, Val Loss: 1.4660, Val Accuracy: 62.36%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Plot training &amp; validation loss values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Model Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Plot training &amp; validation accuracy values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Model Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/99963d9001b16ea71d5a707bb1cbb495da195946ab4012ae5609828b4ec9af97.png" src="../../../_images/99963d9001b16ea71d5a707bb1cbb495da195946ab4012ae5609828b4ec9af97.png" />
<img alt="../../../_images/0cad388fa476911ec575ebb7edae1230adad5209fd5bb746d1ec18ff3742a6a4.png" src="../../../_images/0cad388fa476911ec575ebb7edae1230adad5209fd5bb746d1ec18ff3742a6a4.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load the pre-trained VAE model</span>
<span class="c1"># vae = VariationalAutoencoder(input_shape=(64, 64, 3), dropout=0.3, latent_dim=256).to(device)</span>
<span class="c1"># vae.load_state_dict(torch.load(&#39;path_to_pretrained_vae_weights.pth&#39;))</span>
<span class="c1"># vae.eval()  # Set the VAE to evaluation mode</span>

<span class="c1"># Initialize the VAEClassifier</span>
<span class="n">vae_classifier</span> <span class="o">=</span> <span class="n">VAEClassifier</span><span class="p">(</span><span class="n">vae</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Define the loss function and optimizer for classification</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">vae_classifier</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>

<span class="c1"># Training loop for classification</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">history</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;train_accuracy&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;val_accuracy&#39;</span><span class="p">:</span> <span class="p">[]}</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">vae_classifier</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2"> - Train&quot;</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&quot;batch&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">train_bar</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">train_bar</span><span class="p">:</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            
            <span class="c1"># Forward pass</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">vae_classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            
            <span class="c1"># Backward pass and optimize</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            
            <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="n">predicted</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            
            <span class="n">train_bar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">train_loss</span> <span class="o">/</span> <span class="p">((</span><span class="n">train_bar</span><span class="o">.</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">),</span> 
                                 <span class="n">accuracy</span><span class="o">=</span><span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span>
    
    <span class="c1"># Calculate average training loss and accuracy</span>
    <span class="n">train_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">train_accuracy</span> <span class="o">=</span> <span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_accuracy</span><span class="p">)</span>
    
    <span class="c1"># Validation phase</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">vae_classifier</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">val_loader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Validating&quot;</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&quot;batch&quot;</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">val_bar</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">val_bar</span><span class="p">:</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">logits</span> <span class="o">=</span> <span class="n">vae_classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            
            <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="n">predicted</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    
    <span class="c1"># Calculate average validation loss and accuracy</span>
    <span class="n">val_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">val_accuracy</span> <span class="o">=</span> <span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_accuracy</span><span class="p">)</span>
    
    <span class="c1"># Print progress</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">, Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Train Accuracy: </span><span class="si">{</span><span class="n">train_accuracy</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%, &quot;</span>
          <span class="sa">f</span><span class="s2">&quot;Val Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Val Accuracy: </span><span class="si">{</span><span class="n">val_accuracy</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/10 - Train: 100%|██████████| 4/4 [00:00&lt;00:00, 10.43batch/s, accuracy=59, loss=nan]   
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/10, Train Loss: nan, Train Accuracy: 59.00%, Val Loss: nan, Val Accuracy: 38.04%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2/10 - Train: 100%|██████████| 4/4 [00:00&lt;00:00, 14.85batch/s, accuracy=41, loss=nan]  
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2/10, Train Loss: nan, Train Accuracy: 41.00%, Val Loss: nan, Val Accuracy: 38.04%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3/10 - Train: 100%|██████████| 4/4 [00:00&lt;00:00, 14.38batch/s, accuracy=41, loss=nan]  
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3/10, Train Loss: nan, Train Accuracy: 41.00%, Val Loss: nan, Val Accuracy: 38.04%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4/10 - Train: 100%|██████████| 4/4 [00:00&lt;00:00, 14.77batch/s, accuracy=41, loss=nan]  
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4/10, Train Loss: nan, Train Accuracy: 41.00%, Val Loss: nan, Val Accuracy: 38.04%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5/10 - Train: 100%|██████████| 4/4 [00:00&lt;00:00, 16.08batch/s, accuracy=41, loss=nan]  
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5/10, Train Loss: nan, Train Accuracy: 41.00%, Val Loss: nan, Val Accuracy: 38.04%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 6/10 - Train: 100%|██████████| 4/4 [00:00&lt;00:00, 14.49batch/s, accuracy=41, loss=nan]  
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 6/10, Train Loss: nan, Train Accuracy: 41.00%, Val Loss: nan, Val Accuracy: 38.04%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 7/10 - Train: 100%|██████████| 4/4 [00:00&lt;00:00, 13.98batch/s, accuracy=41, loss=nan]  
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 7/10, Train Loss: nan, Train Accuracy: 41.00%, Val Loss: nan, Val Accuracy: 38.04%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/10 - Train: 100%|██████████| 4/4 [00:00&lt;00:00, 13.27batch/s, accuracy=41, loss=nan]  
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/10, Train Loss: nan, Train Accuracy: 41.00%, Val Loss: nan, Val Accuracy: 38.04%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 9/10 - Train: 100%|██████████| 4/4 [00:00&lt;00:00, 14.06batch/s, accuracy=41, loss=nan]  
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 9/10, Train Loss: nan, Train Accuracy: 41.00%, Val Loss: nan, Val Accuracy: 38.04%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 10/10 - Train: 100%|██████████| 4/4 [00:00&lt;00:00, 16.87batch/s, accuracy=41, loss=nan]  
                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 10/10, Train Loss: nan, Train Accuracy: 41.00%, Val Loss: nan, Val Accuracy: 38.04%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>

<span class="c1"># Initialize the VAEClassifier</span>
<span class="n">vae_classifier</span> <span class="o">=</span> <span class="n">VAEClassifier</span><span class="p">(</span><span class="n">vae</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Define the loss function and optimizer for classification</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">vae_classifier</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>

<span class="c1"># Training loop for classification</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">history</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;train_accuracy&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;val_accuracy&#39;</span><span class="p">:</span> <span class="p">[]}</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">vae_classifier</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2"> - Train&quot;</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&quot;batch&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">train_bar</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">train_bar</span><span class="p">:</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            
            <span class="c1"># Forward pass</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">vae_classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            
            <span class="c1"># Backward pass and optimize</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            
            <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="n">predicted</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            
            <span class="n">train_bar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">train_loss</span> <span class="o">/</span> <span class="p">((</span><span class="n">train_bar</span><span class="o">.</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">),</span> 
                                 <span class="n">accuracy</span><span class="o">=</span><span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span>
    
    <span class="c1"># Calculate average training loss and accuracy</span>
    <span class="n">train_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">train_accuracy</span> <span class="o">=</span> <span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_accuracy</span><span class="p">)</span>
    
    <span class="c1"># Validation phase</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">vae_classifier</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">val_loader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Validating&quot;</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&quot;batch&quot;</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">val_bar</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">val_bar</span><span class="p">:</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">logits</span> <span class="o">=</span> <span class="n">vae_classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            
            <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="n">predicted</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    
    <span class="c1"># Calculate average validation loss and accuracy</span>
    <span class="n">val_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">val_accuracy</span> <span class="o">=</span> <span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_accuracy</span><span class="p">)</span>
    
    <span class="c1"># Print progress</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">, Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Train Accuracy: </span><span class="si">{</span><span class="n">train_accuracy</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%, &quot;</span>
          <span class="sa">f</span><span class="s2">&quot;Val Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Val Accuracy: </span><span class="si">{</span><span class="n">val_accuracy</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/10 - Train: 100%|██████████| 4/4 [00:00&lt;00:00, 10.32batch/s, accuracy=51, loss=nan]  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: -455.64898681640625 std: 41202.12109375
Logits - mean: -71.93480682373047 std: 890.7963256835938
Latent vector - mean: 1.3288325071334839 std: 142.2589111328125
Logits - mean: 0.7981832027435303 std: 24.277402877807617
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: 1.5028856992721558 std: 31.783966064453125
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Validating:  28%|██▊       | 61/215 [00:00&lt;00:00, 270.75batch/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: -0.29726263880729675 std: 36.13966751098633
Logits - mean: nan std: nan
Latent vector - mean: 8934149.0 std: 808253696.0
Logits - mean: nan std: nan
Latent vector - mean: -0.6251255869865417 std: 35.167049407958984
Logits - mean: nan std: nan
Latent vector - mean: -0.32717809081077576 std: 32.95549011230469
Logits - mean: nan std: nan
Latent vector - mean: -0.24035556614398956 std: 30.433412551879883
Logits - mean: nan std: nan
Latent vector - mean: -0.539783239364624 std: 32.54273223876953
Logits - mean: nan std: nan
Latent vector - mean: 7457053696.0 std: 582442352640.0
Logits - mean: nan std: nan
Latent vector - mean: -0.4343886077404022 std: 33.73320007324219
Logits - mean: nan std: nan
Latent vector - mean: 12.696303367614746 std: 1190.7291259765625
Logits - mean: nan std: nan
Latent vector - mean: -0.4819388687610626 std: 32.07368850708008
Logits - mean: nan std: nan
Latent vector - mean: -0.04834383726119995 std: 30.546998977661133
Logits - mean: nan std: nan
Latent vector - mean: nan std: nan
Logits - mean: nan std: nan
Latent vector - mean: 0.03130368888378143 std: 31.829631805419922
Logits - mean: nan std: nan
Latent vector - mean: -0.5916541218757629 std: 34.65316390991211
Logits - mean: nan std: nan
Latent vector - mean: -639041.4375 std: 57839308.0
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.9194978475570679 std: 34.78175735473633
Logits - mean: nan std: nan
Latent vector - mean: 5583341.0 std: 505346400.0
Logits - mean: nan std: nan
Latent vector - mean: -0.4163048565387726 std: 33.58918380737305
Logits - mean: nan std: nan
Latent vector - mean: -35963363328.0 std: 3255032086528.0
Logits - mean: nan std: nan
Latent vector - mean: 8.81222915649414 std: 905.6707763671875
Logits - mean: nan std: nan
Latent vector - mean: -0.2999662756919861 std: 30.845842361450195
Logits - mean: nan std: nan
Latent vector - mean: -0.6611657738685608 std: 32.11457061767578
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.42385420203208923 std: 31.97293472290039
Logits - mean: nan std: nan
Latent vector - mean: -0.20990028977394104 std: 36.4200325012207
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.22214572131633759 std: 32.536685943603516
Logits - mean: nan std: nan
Latent vector - mean: -0.7347534894943237 std: 31.383005142211914
Logits - mean: nan std: nan
Latent vector - mean: -0.4482705295085907 std: 34.560794830322266
Logits - mean: nan std: nan
Latent vector - mean: -2.7533440869072888e+23 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 0.21745823323726654 std: 35.98490524291992
Logits - mean: nan std: nan
Latent vector - mean: -301.894287109375 std: 27486.91796875
Logits - mean: nan std: nan
Latent vector - mean: 143342567424.0 std: 12880899473408.0
Logits - mean: nan std: nan
Latent vector - mean: -0.2724247872829437 std: 34.10768127441406
Logits - mean: nan std: nan
Latent vector - mean: -0.8437350988388062 std: 30.394001007080078
Logits - mean: nan std: nan
Latent vector - mean: 0.2064301073551178 std: 31.152803421020508
Logits - mean: nan std: nan
Latent vector - mean: 5.683356912276472e+18 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -0.5835289359092712 std: 35.21723937988281
Logits - mean: nan std: nan
Latent vector - mean: -0.4343823790550232 std: 30.325742721557617
Logits - mean: nan std: nan
Latent vector - mean: -0.28015977144241333 std: 32.9652214050293
Logits - mean: nan std: nan
Latent vector - mean: -0.15125328302383423 std: 33.1912841796875
Logits - mean: nan std: nan
Latent vector - mean: 42.33208084106445 std: 3796.9638671875
Logits - mean: nan std: nan
Latent vector - mean: 951.4109497070312 std: 86161.046875
Logits - mean: nan std: nan
Latent vector - mean: -0.2905867099761963 std: 32.49253463745117
Logits - mean: nan std: nan
Latent vector - mean: -1.9192919912617323e+30 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 47996888.0 std: 4344215552.0
Logits - mean: nan std: nan
Latent vector - mean: -0.5027913451194763 std: 34.46860885620117
Logits - mean: nan std: nan
Latent vector - mean: -0.5615289211273193 std: 29.70557403564453
Logits - mean: nan std: nan
Latent vector - mean: -0.4638482928276062 std: 30.77645492553711
Logits - mean: nan std: nan
Latent vector - mean: 0.06322871893644333 std: 31.110034942626953
Logits - mean: nan std: nan
Latent vector - mean: -0.5602445602416992 std: 31.70345115661621
Logits - mean: nan std: nan
Latent vector - mean: -0.7185062170028687 std: 35.337364196777344
Logits - mean: nan std: nan
Latent vector - mean: -0.5977287292480469 std: 35.42842483520508
Logits - mean: nan std: nan
Latent vector - mean: -11537484800.0 std: 1034858528768.0
Logits - mean: nan std: nan
Latent vector - mean: 25919.541015625 std: 2345966.0
Logits - mean: nan std: nan
Latent vector - mean: -0.4653334617614746 std: 33.57425308227539
Logits - mean: nan std: nan
Latent vector - mean: 0.04308649152517319 std: 29.641881942749023
Logits - mean: nan std: nan
Latent vector - mean: -0.6615467071533203 std: 35.5986328125
Logits - mean: nan std: nan
Latent vector - mean: 0.005970016121864319 std: 31.91424560546875
Logits - mean: nan std: nan
Latent vector - mean: -0.2527671456336975 std: 29.224973678588867
Logits - mean: nan std: nan
Latent vector - mean: -0.528841495513916 std: 28.009267807006836
Logits - mean: nan std: nan
Latent vector - mean: -1.178120732307434 std: 78.33353424072266
Logits - mean: nan std: nan
Latent vector - mean: -0.9019489288330078 std: 31.32176399230957
Logits - mean: nan std: nan
Latent vector - mean: -0.5840262174606323 std: 32.267826080322266
Logits - mean: nan std: nan
Latent vector - mean: -0.5510515570640564 std: 32.439693450927734
Logits - mean: nan std: nan
Latent vector - mean: 0.14164221286773682 std: 30.44652557373047
Logits - mean: nan std: nan
Latent vector - mean: 0.07051058858633041 std: 31.675676345825195
Logits - mean: nan std: nan
Latent vector - mean: -10864.2724609375 std: 983285.6875
Logits - mean: nan std: nan
Latent vector - mean: -0.20993119478225708 std: 33.46569061279297
Logits - mean: nan std: nan
Latent vector - mean: -6.155991554260254 std: 378.96759033203125
Logits - mean: nan std: nan
Latent vector - mean: 0.03744497895240784 std: 30.467453002929688
Logits - mean: nan std: nan
Latent vector - mean: 1.5977934558355268e+28 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 299833.78125 std: 27137916.0
Logits - mean: nan std: nan
Latent vector - mean: -0.7681465744972229 std: 35.35074996948242
Logits - mean: nan std: nan
Latent vector - mean: -0.31314489245414734 std: 34.67757797241211
Logits - mean: nan std: nan
Latent vector - mean: -0.041858501732349396 std: 32.1795539855957
Logits - mean: nan std: nan
Latent vector - mean: -0.41956162452697754 std: 31.179513931274414
Logits - mean: nan std: nan
Latent vector - mean: -0.25282716751098633 std: 33.60586929321289
Logits - mean: nan std: nan
Latent vector - mean: 12.476058959960938 std: 1128.9652099609375
Logits - mean: nan std: nan
Latent vector - mean: -0.4727325439453125 std: 29.70396614074707
Logits - mean: nan std: nan
Latent vector - mean: -0.13103298842906952 std: 34.1411018371582
Logits - mean: nan std: nan
Latent vector - mean: 19778659942400.0 std: 1790159951495168.0
Logits - mean: nan std: nan
Latent vector - mean: -0.5250349044799805 std: 32.25698471069336
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: 47700.75 std: 4317457.5
Logits - mean: nan std: nan
Latent vector - mean: -0.16716474294662476 std: 30.62948989868164
Logits - mean: nan std: nan
Latent vector - mean: -0.45345520973205566 std: 33.426002502441406
Logits - mean: nan std: nan
Latent vector - mean: -0.3884473741054535 std: 32.7457275390625
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: 4265008.5 std: 386024576.0
Logits - mean: nan std: nan
Latent vector - mean: -1126.49462890625 std: 101904.28125
Logits - mean: nan std: nan
Latent vector - mean: -0.1601243019104004 std: 32.13703536987305
Logits - mean: nan std: nan
Latent vector - mean: 284.3376159667969 std: 25766.1328125
Logits - mean: nan std: nan
Latent vector - mean: -0.548251748085022 std: 31.55762481689453
Logits - mean: nan std: nan
Latent vector - mean: -24614694.0 std: 2227867904.0
Logits - mean: nan std: nan
Latent vector - mean: -0.42138218879699707 std: 33.62551498413086
Logits - mean: nan std: nan
Latent vector - mean: -79.30298614501953 std: 7114.66259765625
Logits - mean: nan std: nan
Latent vector - mean: -0.13221979141235352 std: 32.251041412353516
Logits - mean: nan std: nan
Latent vector - mean: -103216201728.0 std: 9342063476736.0
Logits - mean: nan std: nan
Latent vector - mean: -0.03374581038951874 std: 32.28512191772461
Logits - mean: nan std: nan
Latent vector - mean: -0.7056042551994324 std: 36.01926803588867
Logits - mean: nan std: nan
Latent vector - mean: -0.33508390188217163 std: 31.419748306274414
Logits - mean: nan std: nan
Latent vector - mean: 0.04151630401611328 std: 31.216020584106445
Logits - mean: nan std: nan
Latent vector - mean: -0.654149055480957 std: 36.31159591674805
Logits - mean: nan std: nan
Latent vector - mean: -0.4810450077056885 std: 32.083255767822266
Logits - mean: nan std: nan
Latent vector - mean: -0.2780715823173523 std: 31.3658504486084
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.5450882315635681 std: 36.03191375732422
Logits - mean: nan std: nan
Latent vector - mean: -0.3814672827720642 std: 30.073028564453125
Logits - mean: nan std: nan
Latent vector - mean: 8.298879261238886e+16 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 22449.064453125 std: 2030746.375
Logits - mean: nan std: nan
Latent vector - mean: 6073259313332224.0 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 214639161901056.0 std: 1.942677273496781e+16
Logits - mean: nan std: nan
Latent vector - mean: 22064247341056.0 std: 1997022622121984.0
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Validating:  80%|████████  | 173/215 [00:00&lt;00:00, 445.94batch/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: -9142675.0 std: 827500992.0
Logits - mean: nan std: nan
Latent vector - mean: -0.7261975407600403 std: 32.28953170776367
Logits - mean: nan std: nan
Latent vector - mean: -0.19152691960334778 std: 31.684368133544922
Logits - mean: nan std: nan
Latent vector - mean: -185289.625 std: 16770479.0
Logits - mean: nan std: nan
Latent vector - mean: 1.4436457105693082e+18 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -13865.154296875 std: 1251384.875
Logits - mean: nan std: nan
Latent vector - mean: -0.5948426723480225 std: 31.74551010131836
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.07146304100751877 std: 30.56592559814453
Logits - mean: nan std: nan
Latent vector - mean: 0.0851929634809494 std: 31.88134002685547
Logits - mean: nan std: nan
Latent vector - mean: -1.049172463583232e+16 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -0.32016441226005554 std: 31.117176055908203
Logits - mean: nan std: nan
Latent vector - mean: 0.009370088577270508 std: 31.300708770751953
Logits - mean: nan std: nan
Latent vector - mean: -0.4919354319572449 std: 33.533084869384766
Logits - mean: nan std: nan
Latent vector - mean: -0.2186657041311264 std: 28.963848114013672
Logits - mean: nan std: nan
Latent vector - mean: -0.08758949488401413 std: 30.33533477783203
Logits - mean: nan std: nan
Latent vector - mean: -0.4053898751735687 std: 35.385765075683594
Logits - mean: nan std: nan
Latent vector - mean: -0.49600157141685486 std: 32.79496383666992
Logits - mean: nan std: nan
Latent vector - mean: -0.7012682557106018 std: 31.09520721435547
Logits - mean: nan std: nan
Latent vector - mean: -1913401.75 std: 173181344.0
Logits - mean: nan std: nan
Latent vector - mean: -0.10511179268360138 std: 31.546361923217773
Logits - mean: nan std: nan
Latent vector - mean: 0.8508506417274475 std: 74.53196716308594
Logits - mean: nan std: nan
Latent vector - mean: -0.5165845155715942 std: 36.31776428222656
Logits - mean: nan std: nan
Latent vector - mean: -0.8497594594955444 std: 36.56142807006836
Logits - mean: nan std: nan
Latent vector - mean: -0.32111021876335144 std: 34.97942352294922
Logits - mean: nan std: nan
Latent vector - mean: -0.33180904388427734 std: 31.379600524902344
Logits - mean: nan std: nan
Latent vector - mean: 0.1529616117477417 std: 30.612295150756836
Logits - mean: nan std: nan
Latent vector - mean: 286300448.0 std: 27044157440.0
Logits - mean: nan std: nan
Latent vector - mean: 1287606272.0 std: 116540817408.0
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: 6.504116535186768 std: 605.8251953125
Logits - mean: nan std: nan
Latent vector - mean: -5.331387042999268 std: 453.063232421875
Logits - mean: nan std: nan
Latent vector - mean: 309.23223876953125 std: 28026.890625
Logits - mean: nan std: nan
Latent vector - mean: -0.3621249198913574 std: 32.4920539855957
Logits - mean: nan std: nan
Latent vector - mean: -0.6768391728401184 std: 32.277130126953125
Logits - mean: nan std: nan
Latent vector - mean: 169.86013793945312 std: 15454.3369140625
Logits - mean: nan std: nan
Latent vector - mean: 1.464841365814209 std: 149.00721740722656
Logits - mean: nan std: nan
Latent vector - mean: -0.02238285541534424 std: 30.989286422729492
Logits - mean: nan std: nan
Latent vector - mean: -0.3340895175933838 std: 30.95747184753418
Logits - mean: nan std: nan
Latent vector - mean: -0.3717148005962372 std: 33.1754150390625
Logits - mean: nan std: nan
Latent vector - mean: -0.27551645040512085 std: 30.678836822509766
Logits - mean: nan std: nan
Latent vector - mean: -26182.80078125 std: 3265257.75
Logits - mean: nan std: nan
Latent vector - mean: -0.29778873920440674 std: 34.54830551147461
Logits - mean: nan std: nan
Latent vector - mean: -0.8313560485839844 std: 33.12623596191406
Logits - mean: nan std: nan
Latent vector - mean: -0.1928386390209198 std: 32.29191207885742
Logits - mean: nan std: nan
Latent vector - mean: -154413133987840.0 std: 1.3015633176297472e+16
Logits - mean: nan std: nan
Latent vector - mean: -0.5236333012580872 std: 28.76555061340332
Logits - mean: nan std: nan
Latent vector - mean: 180075597135872.0 std: 1.6298581623308288e+16
Logits - mean: nan std: nan
Latent vector - mean: -0.271395742893219 std: 27.79340362548828
Logits - mean: nan std: nan
Latent vector - mean: -0.8062512874603271 std: 36.461395263671875
Logits - mean: nan std: nan
Latent vector - mean: 422340.75 std: 38225932.0
Logits - mean: nan std: nan
Latent vector - mean: 1008.4754638671875 std: 109288.8125
Logits - mean: nan std: nan
Latent vector - mean: -103939751936.0 std: 9407552290816.0
Logits - mean: nan std: nan
Latent vector - mean: -16390.6015625 std: 1483521.375
Logits - mean: nan std: nan
Latent vector - mean: -2775.186279296875 std: 251151.5
Logits - mean: nan std: nan
Latent vector - mean: -0.44940876960754395 std: 29.832157135009766
Logits - mean: nan std: nan
Latent vector - mean: -0.13370239734649658 std: 31.137527465820312
Logits - mean: nan std: nan
Latent vector - mean: -0.32361042499542236 std: 29.566675186157227
Logits - mean: nan std: nan
Latent vector - mean: -469.4918212890625 std: 42486.375
Logits - mean: nan std: nan
Latent vector - mean: 2341038.0 std: 211886640.0
Logits - mean: nan std: nan
Latent vector - mean: -0.1978786587715149 std: 32.405555725097656
Logits - mean: nan std: nan
Latent vector - mean: 0.04361444711685181 std: 29.207571029663086
Logits - mean: nan std: nan
Latent vector - mean: -0.3660058081150055 std: 33.29943084716797
Logits - mean: nan std: nan
Latent vector - mean: -0.5580640435218811 std: 28.69451332092285
Logits - mean: nan std: nan
Latent vector - mean: -0.7499367594718933 std: 32.91950988769531
Logits - mean: nan std: nan
Latent vector - mean: 982685.75 std: 88942592.0
Logits - mean: nan std: nan
Latent vector - mean: -0.654057502746582 std: 30.09581184387207
Logits - mean: nan std: nan
Latent vector - mean: -0.5943909883499146 std: 28.44582176208496
Logits - mean: nan std: nan
Latent vector - mean: -0.04025191068649292 std: 32.78450012207031
Logits - mean: nan std: nan
Latent vector - mean: 36852092.0 std: 3335470592.0
Logits - mean: nan std: nan
Latent vector - mean: -48792.828125 std: 4416172.5
Logits - mean: nan std: nan
Latent vector - mean: 0.1638304889202118 std: 36.489742279052734
Logits - mean: nan std: nan
Latent vector - mean: -0.8130069375038147 std: 30.85956573486328
Logits - mean: nan std: nan
Latent vector - mean: -0.5450226068496704 std: 29.48528480529785
Logits - mean: nan std: nan
Latent vector - mean: -0.290513277053833 std: 34.5176887512207
Logits - mean: nan std: nan
Latent vector - mean: 322989632.0 std: 27002320896.0
Logits - mean: nan std: nan
Latent vector - mean: -0.48903346061706543 std: 34.12816619873047
Logits - mean: nan std: nan
Latent vector - mean: 0.10132499039173126 std: 29.352371215820312
Logits - mean: nan std: nan
Latent vector - mean: -0.6830929517745972 std: 33.061180114746094
Logits - mean: nan std: nan
Latent vector - mean: 1.2600402400427186e+34 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -47.087677001953125 std: 4186.7333984375
Logits - mean: nan std: nan
Latent vector - mean: -0.20292958617210388 std: 32.79780197143555
Logits - mean: nan std: nan
Latent vector - mean: -0.18642663955688477 std: 32.29594802856445
Logits - mean: nan std: nan
Latent vector - mean: 0.039826616644859314 std: 28.838056564331055
Logits - mean: nan std: nan
Latent vector - mean: -0.4868956208229065 std: 31.62369155883789
Logits - mean: nan std: nan
Latent vector - mean: -51.36248016357422 std: 4588.36181640625
Logits - mean: nan std: nan
Latent vector - mean: -0.03244275599718094 std: 27.346187591552734
Logits - mean: nan std: nan
Latent vector - mean: 0.02534627914428711 std: 31.686050415039062
Logits - mean: nan std: nan
Latent vector - mean: -0.6222102046012878 std: 32.73847198486328
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.12459617853164673 std: 29.06024169921875
Logits - mean: nan std: nan
Latent vector - mean: -0.394945353269577 std: 32.97136306762695
Logits - mean: nan std: nan
Latent vector - mean: 0.19324323534965515 std: 31.141387939453125
Logits - mean: nan std: nan
Latent vector - mean: -0.036476291716098785 std: 33.07645034790039
Logits - mean: nan std: nan
Latent vector - mean: -0.41444700956344604 std: 32.25383758544922
Logits - mean: nan std: nan
Latent vector - mean: -0.20887990295886993 std: 29.667770385742188
Logits - mean: nan std: nan
Latent vector - mean: 33.35896682739258 std: 3042.188720703125
Logits - mean: nan std: nan
Latent vector - mean: -0.2353598028421402 std: 34.436622619628906
Logits - mean: nan std: nan
Latent vector - mean: -0.11554780602455139 std: 30.542783737182617
Logits - mean: nan std: nan
Latent vector - mean: -0.24061523377895355 std: 31.268232345581055
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/10, Train Loss: nan, Train Accuracy: 51.00%, Val Loss: nan, Val Accuracy: 38.04%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2/10 - Train:  25%|██▌       | 1/4 [00:00&lt;00:00,  6.76batch/s, accuracy=41, loss=nan]  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: 6.13676157752207e+22 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -1.008472204208374 std: 37.267826080322266
Logits - mean: nan std: nan
Latent vector - mean: -0.32870233058929443 std: 48.74657440185547
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2/10 - Train: 100%|██████████| 4/4 [00:00&lt;00:00, 15.44batch/s, accuracy=41, loss=nan]
Validating:  28%|██▊       | 60/215 [00:00&lt;00:00, 267.36batch/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: -0.29712361097335815 std: 36.13969802856445
Logits - mean: nan std: nan
Latent vector - mean: 8725700.0 std: 786293760.0
Logits - mean: nan std: nan
Latent vector - mean: -0.6220335960388184 std: 35.1479606628418
Logits - mean: nan std: nan
Latent vector - mean: -0.3270849287509918 std: 32.955528259277344
Logits - mean: nan std: nan
Latent vector - mean: -0.2401798963546753 std: 30.433393478393555
Logits - mean: nan std: nan
Latent vector - mean: -0.5395113825798035 std: 32.54268264770508
Logits - mean: nan std: nan
Latent vector - mean: -40101048320.0 std: 3553909014528.0
Logits - mean: nan std: nan
Latent vector - mean: -0.43418389558792114 std: 33.73350143432617
Logits - mean: nan std: nan
Latent vector - mean: -36.88805389404297 std: 3297.778076171875
Logits - mean: nan std: nan
Latent vector - mean: -0.4820844531059265 std: 32.07366180419922
Logits - mean: nan std: nan
Latent vector - mean: -0.04831057786941528 std: 30.547229766845703
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: 0.004652425646781921 std: 31.71080207824707
Logits - mean: nan std: nan
Latent vector - mean: -0.5914571285247803 std: 34.65302276611328
Logits - mean: nan std: nan
Latent vector - mean: 16008933.0 std: 1448963328.0
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.9201793670654297 std: 34.781429290771484
Logits - mean: nan std: nan
Latent vector - mean: 9789527.0 std: 886046848.0
Logits - mean: nan std: nan
Latent vector - mean: -0.4166938364505768 std: 33.58888244628906
Logits - mean: nan std: nan
Latent vector - mean: 5101369856.0 std: 461723303936.0
Logits - mean: nan std: nan
Latent vector - mean: 101.11393737792969 std: 9196.306640625
Logits - mean: nan std: nan
Latent vector - mean: -0.3000847101211548 std: 30.845779418945312
Logits - mean: nan std: nan
Latent vector - mean: -0.6609758734703064 std: 32.114501953125
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.4236113429069519 std: 31.97294044494629
Logits - mean: nan std: nan
Latent vector - mean: -0.2095387876033783 std: 36.41940689086914
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: 0.045902639627456665 std: 35.75566482543945
Logits - mean: nan std: nan
Latent vector - mean: -0.7347191572189331 std: 31.383047103881836
Logits - mean: nan std: nan
Latent vector - mean: -0.44884732365608215 std: 34.560733795166016
Logits - mean: nan std: nan
Latent vector - mean: -1.0806774615443459e+23 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 0.08032065629959106 std: 37.247894287109375
Logits - mean: nan std: nan
Latent vector - mean: 458.63885498046875 std: 41567.4453125
Logits - mean: nan std: nan
Latent vector - mean: 3082614528.0 std: 296486338560.0
Logits - mean: nan std: nan
Latent vector - mean: -0.2724074721336365 std: 34.10773849487305
Logits - mean: nan std: nan
Latent vector - mean: -0.8448923230171204 std: 30.393033981323242
Logits - mean: nan std: nan
Latent vector - mean: 0.20654994249343872 std: 31.152908325195312
Logits - mean: nan std: nan
Latent vector - mean: 5.747814681943212e+18 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -0.5836099982261658 std: 35.21725845336914
Logits - mean: nan std: nan
Latent vector - mean: -0.4362003207206726 std: 30.326139450073242
Logits - mean: nan std: nan
Latent vector - mean: -0.25373315811157227 std: 33.13388442993164
Logits - mean: nan std: nan
Latent vector - mean: -0.1514989733695984 std: 33.19112014770508
Logits - mean: nan std: nan
Latent vector - mean: 23.67801284790039 std: 2108.711669921875
Logits - mean: nan std: nan
Latent vector - mean: -143.1310577392578 std: 12913.1318359375
Logits - mean: nan std: nan
Latent vector - mean: -0.29044878482818604 std: 32.49258804321289
Logits - mean: nan std: nan
Latent vector - mean: 8.457675257169436e+29 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 41751920.0 std: 3779111168.0
Logits - mean: nan std: nan
Latent vector - mean: -0.5027305483818054 std: 34.46832275390625
Logits - mean: nan std: nan
Latent vector - mean: -0.5616328120231628 std: 29.705549240112305
Logits - mean: nan std: nan
Latent vector - mean: -0.4638890027999878 std: 30.776493072509766
Logits - mean: nan std: nan
Latent vector - mean: 0.06339000165462494 std: 31.1102294921875
Logits - mean: nan std: nan
Latent vector - mean: -0.5602630972862244 std: 31.70342445373535
Logits - mean: nan std: nan
Latent vector - mean: -0.995922327041626 std: 39.777854919433594
Logits - mean: nan std: nan
Latent vector - mean: -0.5972230434417725 std: 35.42878341674805
Logits - mean: nan std: nan
Latent vector - mean: 30539304960.0 std: 2739746635776.0
Logits - mean: nan std: nan
Latent vector - mean: -8223.51171875 std: 744310.8125
Logits - mean: nan std: nan
Latent vector - mean: -0.46497154235839844 std: 33.574527740478516
Logits - mean: nan std: nan
Latent vector - mean: 0.04313687980175018 std: 29.642024993896484
Logits - mean: nan std: nan
Latent vector - mean: -0.6616348028182983 std: 35.59857940673828
Logits - mean: nan std: nan
Latent vector - mean: 0.005930185317993164 std: 31.913976669311523
Logits - mean: nan std: nan
Latent vector - mean: -0.25265786051750183 std: 29.225069046020508
Logits - mean: nan std: nan
Latent vector - mean: -0.5289749503135681 std: 28.00940704345703
Logits - mean: nan std: nan
Latent vector - mean: 0.4634997844696045 std: 84.66957092285156
Logits - mean: nan std: nan
Latent vector - mean: -0.9015518426895142 std: 31.321792602539062
Logits - mean: nan std: nan
Latent vector - mean: -0.5841265320777893 std: 32.26774597167969
Logits - mean: nan std: nan
Latent vector - mean: -0.5512493848800659 std: 32.43989562988281
Logits - mean: nan std: nan
Latent vector - mean: 0.14143362641334534 std: 30.446548461914062
Logits - mean: nan std: nan
Latent vector - mean: 0.07061532884836197 std: 31.675695419311523
Logits - mean: nan std: nan
Latent vector - mean: 3742.237060546875 std: 338744.6875
Logits - mean: nan std: nan
Latent vector - mean: -0.2098139375448227 std: 33.46571731567383
Logits - mean: nan std: nan
Latent vector - mean: -2.6860241889953613 std: 339.7791442871094
Logits - mean: nan std: nan
Latent vector - mean: 0.03910605609416962 std: 30.46922492980957
Logits - mean: nan std: nan
Latent vector - mean: -2.9569711640131057e+28 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -319995.125 std: 28962596.0
Logits - mean: nan std: nan
Latent vector - mean: -0.7600123882293701 std: 35.35476303100586
Logits - mean: nan std: nan
Latent vector - mean: -0.3131495416164398 std: 34.67753601074219
Logits - mean: nan std: nan
Latent vector - mean: -0.04178275913000107 std: 32.179630279541016
Logits - mean: nan std: nan
Latent vector - mean: -0.41967612504959106 std: 31.17931365966797
Logits - mean: nan std: nan
Latent vector - mean: -0.252596378326416 std: 33.60639190673828
Logits - mean: nan std: nan
Latent vector - mean: -29.706960678100586 std: 2689.7646484375
Logits - mean: nan std: nan
Latent vector - mean: -0.4726766347885132 std: 29.703933715820312
Logits - mean: nan std: nan
Latent vector - mean: -0.1312544047832489 std: 34.141090393066406
Logits - mean: nan std: nan
Latent vector - mean: -8290505326592.0 std: 750370850603008.0
Logits - mean: nan std: nan
Latent vector - mean: -0.5247617959976196 std: 32.257110595703125
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: 183233.515625 std: 16584483.0
Logits - mean: nan std: nan
Latent vector - mean: -0.16717733442783356 std: 30.629682540893555
Logits - mean: nan std: nan
Latent vector - mean: -0.45320048928260803 std: 33.426265716552734
Logits - mean: nan std: nan
Latent vector - mean: -0.38785141706466675 std: 32.743064880371094
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -3314304.25 std: 299976576.0
Logits - mean: nan std: nan
Latent vector - mean: 943.2447509765625 std: 85411.078125
Logits - mean: nan std: nan
Latent vector - mean: -0.1601371318101883 std: 32.136905670166016
Logits - mean: nan std: nan
Latent vector - mean: -716.4669799804688 std: 64816.36328125
Logits - mean: nan std: nan
Latent vector - mean: -0.5468839406967163 std: 31.556556701660156
Logits - mean: nan std: nan
Latent vector - mean: -23083376.0 std: 2089268608.0
Logits - mean: nan std: nan
Latent vector - mean: -0.4217362105846405 std: 33.62547302246094
Logits - mean: nan std: nan
Latent vector - mean: 62.380821228027344 std: 5709.27783203125
Logits - mean: nan std: nan
Latent vector - mean: -0.1322004348039627 std: 32.25104522705078
Logits - mean: nan std: nan
Latent vector - mean: -78038237184.0 std: 7063215276032.0
Logits - mean: nan std: nan
Latent vector - mean: -0.03362149000167847 std: 32.28514099121094
Logits - mean: nan std: nan
Latent vector - mean: -0.7050025463104248 std: 36.01951217651367
Logits - mean: nan std: nan
Latent vector - mean: -0.3351745903491974 std: 31.419618606567383
Logits - mean: nan std: nan
Latent vector - mean: 0.04140409827232361 std: 31.216083526611328
Logits - mean: nan std: nan
Latent vector - mean: -0.6544492244720459 std: 36.31132888793945
Logits - mean: nan std: nan
Latent vector - mean: -0.48121291399002075 std: 32.08355712890625
Logits - mean: nan std: nan
Latent vector - mean: -0.2780011296272278 std: 31.365779876708984
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.5109071135520935 std: 36.116188049316406
Logits - mean: nan std: nan
Latent vector - mean: -0.3817458748817444 std: 30.072704315185547
Logits - mean: nan std: nan
Latent vector - mean: -2.5132727841010483e+17 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -349701.90625 std: 31650936.0
Logits - mean: nan std: nan
Latent vector - mean: 2976904915189760.0 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 74166854221824.0 std: 6712664516460544.0
Logits - mean: nan std: nan
Latent vector - mean: -53464403017728.0 std: 4839061269250048.0
Logits - mean: nan std: nan
Latent vector - mean: -2020549.0 std: 182878224.0
Logits - mean: nan std: nan
Latent vector - mean: -0.7226181030273438 std: 32.282981872558594
Logits - mean: nan std: nan
Latent vector - mean: -0.19150465726852417 std: 31.684602737426758
Logits - mean: nan std: nan
Latent vector - mean: -234556.0625 std: 21229568.0
Logits - mean: nan std: nan
Latent vector - mean: 2.438717992998011e+17 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -18061.84765625 std: 1656962.75
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Validating:  87%|████████▋ | 186/215 [00:00&lt;00:00, 485.26batch/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: -0.5910451412200928 std: 31.74087905883789
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.07136820256710052 std: 30.566043853759766
Logits - mean: nan std: nan
Latent vector - mean: 0.08603353053331375 std: 31.881860733032227
Logits - mean: nan std: nan
Latent vector - mean: -1.4994226899058688e+16 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -0.3206612765789032 std: 31.116994857788086
Logits - mean: nan std: nan
Latent vector - mean: 0.009184390306472778 std: 31.30071258544922
Logits - mean: nan std: nan
Latent vector - mean: -0.49193716049194336 std: 33.53310775756836
Logits - mean: nan std: nan
Latent vector - mean: -0.21851488947868347 std: 28.96411895751953
Logits - mean: nan std: nan
Latent vector - mean: -0.08772231638431549 std: 30.33531379699707
Logits - mean: nan std: nan
Latent vector - mean: -0.4052702486515045 std: 35.38591384887695
Logits - mean: nan std: nan
Latent vector - mean: -0.4960172474384308 std: 32.79518127441406
Logits - mean: nan std: nan
Latent vector - mean: -0.7012200951576233 std: 31.095256805419922
Logits - mean: nan std: nan
Latent vector - mean: -407317.9375 std: 36866220.0
Logits - mean: nan std: nan
Latent vector - mean: -0.10499556362628937 std: 31.546424865722656
Logits - mean: nan std: nan
Latent vector - mean: -2.2881288528442383 std: 220.09657287597656
Logits - mean: nan std: nan
Latent vector - mean: -0.5165767669677734 std: 36.317665100097656
Logits - mean: nan std: nan
Latent vector - mean: -0.8499956727027893 std: 36.561309814453125
Logits - mean: nan std: nan
Latent vector - mean: -0.2726621627807617 std: 35.25297927856445
Logits - mean: nan std: nan
Latent vector - mean: -0.3319239616394043 std: 31.379688262939453
Logits - mean: nan std: nan
Latent vector - mean: 0.15300199389457703 std: 30.6121883392334
Logits - mean: nan std: nan
Latent vector - mean: -1204011392.0 std: 110786633728.0
Logits - mean: nan std: nan
Latent vector - mean: 2044731776.0 std: 185067978752.0
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: 8.933606147766113 std: 825.4760131835938
Logits - mean: nan std: nan
Latent vector - mean: 2.239665985107422 std: 236.32762145996094
Logits - mean: nan std: nan
Latent vector - mean: -613.2976684570312 std: 55471.03125
Logits - mean: nan std: nan
Latent vector - mean: -0.36252617835998535 std: 32.49173355102539
Logits - mean: nan std: nan
Latent vector - mean: -0.6770974397659302 std: 32.277408599853516
Logits - mean: nan std: nan
Latent vector - mean: 86.11629486083984 std: 7874.39501953125
Logits - mean: nan std: nan
Latent vector - mean: -3.719574213027954 std: 325.7117614746094
Logits - mean: nan std: nan
Latent vector - mean: 0.0067013949155807495 std: 31.01557159423828
Logits - mean: nan std: nan
Latent vector - mean: -0.3338787257671356 std: 30.957374572753906
Logits - mean: nan std: nan
Latent vector - mean: -0.35096806287765503 std: 33.18951416015625
Logits - mean: nan std: nan
Latent vector - mean: -0.2755920886993408 std: 30.678808212280273
Logits - mean: nan std: nan
Latent vector - mean: 82061.0234375 std: 8468017.0
Logits - mean: nan std: nan
Latent vector - mean: -0.2974991798400879 std: 34.548492431640625
Logits - mean: nan std: nan
Latent vector - mean: -0.8313180208206177 std: 33.126251220703125
Logits - mean: nan std: nan
Latent vector - mean: -0.19302690029144287 std: 32.29182434082031
Logits - mean: nan std: nan
Latent vector - mean: 323253029568512.0 std: 2.884203897998541e+16
Logits - mean: nan std: nan
Latent vector - mean: -0.5237551927566528 std: 28.765430450439453
Logits - mean: nan std: nan
Latent vector - mean: -177570876227584.0 std: 1.6071881438265344e+16
Logits - mean: nan std: nan
Latent vector - mean: -0.2711092233657837 std: 27.793663024902344
Logits - mean: nan std: nan
Latent vector - mean: -0.8051960468292236 std: 36.45555114746094
Logits - mean: nan std: nan
Latent vector - mean: 238171.671875 std: 21556856.0
Logits - mean: nan std: nan
Latent vector - mean: -659.2889404296875 std: 59645.71875
Logits - mean: nan std: nan
Latent vector - mean: 411067416576.0 std: 37205573632000.0
Logits - mean: nan std: nan
Latent vector - mean: -11489.9345703125 std: 1039979.4375
Logits - mean: nan std: nan
Latent vector - mean: -1812.1099853515625 std: 163983.78125
Logits - mean: nan std: nan
Latent vector - mean: -0.4491540789604187 std: 29.8319091796875
Logits - mean: nan std: nan
Latent vector - mean: -0.1348603218793869 std: 31.13661766052246
Logits - mean: nan std: nan
Latent vector - mean: -0.32499265670776367 std: 29.56736183166504
Logits - mean: nan std: nan
Latent vector - mean: 27.46224021911621 std: 2493.02734375
Logits - mean: nan std: nan
Latent vector - mean: 1772836.125 std: 160458864.0
Logits - mean: nan std: nan
Latent vector - mean: -0.19794410467147827 std: 32.40542984008789
Logits - mean: nan std: nan
Latent vector - mean: 0.042887017130851746 std: 29.207624435424805
Logits - mean: nan std: nan
Latent vector - mean: -0.3657703101634979 std: 33.299503326416016
Logits - mean: nan std: nan
Latent vector - mean: -0.5581614971160889 std: 28.694351196289062
Logits - mean: nan std: nan
Latent vector - mean: -0.7154926061630249 std: 32.990970611572266
Logits - mean: nan std: nan
Latent vector - mean: 1148623.5 std: 103961528.0
Logits - mean: nan std: nan
Latent vector - mean: -0.6544521450996399 std: 30.095870971679688
Logits - mean: nan std: nan
Latent vector - mean: -0.5930624604225159 std: 28.447078704833984
Logits - mean: nan std: nan
Latent vector - mean: -0.03999823331832886 std: 32.78462600708008
Logits - mean: nan std: nan
Latent vector - mean: 9609595.0 std: 869761280.0
Logits - mean: nan std: nan
Latent vector - mean: -82261.9765625 std: 7445453.5
Logits - mean: nan std: nan
Latent vector - mean: -0.11681732535362244 std: 35.005680084228516
Logits - mean: nan std: nan
Latent vector - mean: -0.8129435777664185 std: 30.859682083129883
Logits - mean: nan std: nan
Latent vector - mean: -0.5448577404022217 std: 29.485177993774414
Logits - mean: nan std: nan
Latent vector - mean: -0.2907055616378784 std: 34.517547607421875
Logits - mean: nan std: nan
Latent vector - mean: 407172128.0 std: 30984531968.0
Logits - mean: nan std: nan
Latent vector - mean: -0.4891503155231476 std: 34.12822723388672
Logits - mean: nan std: nan
Latent vector - mean: 0.10166263580322266 std: 29.352285385131836
Logits - mean: nan std: nan
Latent vector - mean: -0.6836393475532532 std: 33.06104278564453
Logits - mean: nan std: nan
Latent vector - mean: 1.4890437968540268e+34 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -61.55684280395508 std: 5496.3056640625
Logits - mean: nan std: nan
Latent vector - mean: -0.2026686817407608 std: 32.79753112792969
Logits - mean: nan std: nan
Latent vector - mean: -0.1865750104188919 std: 32.295772552490234
Logits - mean: nan std: nan
Latent vector - mean: 0.03943578898906708 std: 28.837852478027344
Logits - mean: nan std: nan
Latent vector - mean: -0.48678579926490784 std: 31.62375259399414
Logits - mean: nan std: nan
Latent vector - mean: -99.93058013916016 std: 8984.1962890625
Logits - mean: nan std: nan
Latent vector - mean: -0.032674640417099 std: 27.34624671936035
Logits - mean: nan std: nan
Latent vector - mean: 0.025752559304237366 std: 31.686246871948242
Logits - mean: nan std: nan
Latent vector - mean: -0.6220455765724182 std: 32.73843765258789
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.12423096597194672 std: 29.060688018798828
Logits - mean: nan std: nan
Latent vector - mean: -0.39486241340637207 std: 32.971466064453125
Logits - mean: nan std: nan
Latent vector - mean: 0.19328159093856812 std: 31.14138412475586
Logits - mean: nan std: nan
Latent vector - mean: -0.03627559542655945 std: 33.076416015625
Logits - mean: nan std: nan
Latent vector - mean: -0.41539013385772705 std: 32.253868103027344
Logits - mean: nan std: nan
Latent vector - mean: -0.208708256483078 std: 29.66766929626465
Logits - mean: nan std: nan
Latent vector - mean: -1.220570683479309 std: 94.60833740234375
Logits - mean: nan std: nan
Latent vector - mean: -0.23524941504001617 std: 34.436614990234375
Logits - mean: nan std: nan
Latent vector - mean: -0.11534911394119263 std: 30.542978286743164
Logits - mean: nan std: nan
Latent vector - mean: -0.24127164483070374 std: 31.267972946166992
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2/10, Train Loss: nan, Train Accuracy: 41.00%, Val Loss: nan, Val Accuracy: 38.04%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3/10 - Train:  25%|██▌       | 1/4 [00:00&lt;00:00,  6.66batch/s, accuracy=41, loss=nan]  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: -0.7067179083824158 std: 36.66712951660156
Logits - mean: nan std: nan
Latent vector - mean: nan std: nan
Logits - mean: nan std: nan
Latent vector - mean: -7.0236287117004395 std: 622.9676513671875
Logits - mean: nan std: nan
Latent vector - mean: -0.03587925434112549 std: 37.0204963684082
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3/10 - Train: 100%|██████████| 4/4 [00:00&lt;00:00, 14.69batch/s, accuracy=41, loss=nan]
Validating:  26%|██▌       | 55/215 [00:00&lt;00:00, 264.88batch/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: -0.296888530254364 std: 36.139766693115234
Logits - mean: nan std: nan
Latent vector - mean: -10724863.0 std: 972637568.0
Logits - mean: nan std: nan
Latent vector - mean: -0.6273201704025269 std: 35.18098068237305
Logits - mean: nan std: nan
Latent vector - mean: -0.3271602690219879 std: 32.95555877685547
Logits - mean: nan std: nan
Latent vector - mean: -0.23994362354278564 std: 30.433441162109375
Logits - mean: nan std: nan
Latent vector - mean: -0.5394212007522583 std: 32.542884826660156
Logits - mean: nan std: nan
Latent vector - mean: -3240695040.0 std: 253685727232.0
Logits - mean: nan std: nan
Latent vector - mean: -0.4341224431991577 std: 33.73369216918945
Logits - mean: nan std: nan
Latent vector - mean: 19.839330673217773 std: 1837.0927734375
Logits - mean: nan std: nan
Latent vector - mean: -0.482054740190506 std: 32.07363510131836
Logits - mean: nan std: nan
Latent vector - mean: -0.0483250617980957 std: 30.546993255615234
Logits - mean: nan std: nan
Latent vector - mean: nan std: nan
Logits - mean: nan std: nan
Latent vector - mean: 0.036754511296749115 std: 31.877084732055664
Logits - mean: nan std: nan
Latent vector - mean: -0.5916982889175415 std: 34.65288162231445
Logits - mean: nan std: nan
Latent vector - mean: -4891337.5 std: 442713312.0
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.9187052249908447 std: 34.78199768066406
Logits - mean: nan std: nan
Latent vector - mean: -20768580.0 std: 1879757312.0
Logits - mean: nan std: nan
Latent vector - mean: -0.4165678024291992 std: 33.589176177978516
Logits - mean: nan std: nan
Latent vector - mean: -29779093504.0 std: 2695295926272.0
Logits - mean: nan std: nan
Latent vector - mean: 84.69760131835938 std: 7515.19775390625
Logits - mean: nan std: nan
Latent vector - mean: -0.2999876141548157 std: 30.845888137817383
Logits - mean: nan std: nan
Latent vector - mean: -0.6609073281288147 std: 32.11458206176758
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.4231716990470886 std: 31.97325325012207
Logits - mean: nan std: nan
Latent vector - mean: -0.21000364422798157 std: 36.4201774597168
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.21714554727077484 std: 32.43364715576172
Logits - mean: nan std: nan
Latent vector - mean: -0.7343382835388184 std: 31.383153915405273
Logits - mean: nan std: nan
Latent vector - mean: -0.4487723112106323 std: 34.560462951660156
Logits - mean: nan std: nan
Latent vector - mean: -4.5097065084652104e+23 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 0.3333609104156494 std: 38.16008377075195
Logits - mean: nan std: nan
Latent vector - mean: -261.40130615234375 std: 23542.416015625
Logits - mean: nan std: nan
Latent vector - mean: 69055807488.0 std: 6150690963456.0
Logits - mean: nan std: nan
Latent vector - mean: -0.272274911403656 std: 34.10749435424805
Logits - mean: nan std: nan
Latent vector - mean: -0.844691276550293 std: 30.393173217773438
Logits - mean: nan std: nan
Latent vector - mean: 0.2064547836780548 std: 31.152877807617188
Logits - mean: nan std: nan
Latent vector - mean: 3.5666321020635054e+18 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -0.5831001996994019 std: 35.217281341552734
Logits - mean: nan std: nan
Latent vector - mean: -0.43460386991500854 std: 30.325820922851562
Logits - mean: nan std: nan
Latent vector - mean: -0.3377726674079895 std: 33.18916320800781
Logits - mean: nan std: nan
Latent vector - mean: -0.15133625268936157 std: 33.19112014770508
Logits - mean: nan std: nan
Latent vector - mean: 12.158428192138672 std: 1066.373291015625
Logits - mean: nan std: nan
Latent vector - mean: 456.71112060546875 std: 41376.078125
Logits - mean: nan std: nan
Latent vector - mean: -0.29071298241615295 std: 32.492393493652344
Logits - mean: nan std: nan
Latent vector - mean: 6.003250967371605e+29 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 10880958.0 std: 985022912.0
Logits - mean: nan std: nan
Latent vector - mean: -0.5028995275497437 std: 34.46833801269531
Logits - mean: nan std: nan
Latent vector - mean: -0.5615184307098389 std: 29.705659866333008
Logits - mean: nan std: nan
Latent vector - mean: -0.46390455961227417 std: 30.776477813720703
Logits - mean: nan std: nan
Latent vector - mean: 0.06339217722415924 std: 31.110034942626953
Logits - mean: nan std: nan
Latent vector - mean: -0.5605096817016602 std: 31.703813552856445
Logits - mean: nan std: nan
Latent vector - mean: -0.5475995540618896 std: 40.88791275024414
Logits - mean: nan std: nan
Latent vector - mean: -0.5975902080535889 std: 35.42850112915039
Logits - mean: nan std: nan
Latent vector - mean: -16716253184.0 std: 1472977567744.0
Logits - mean: nan std: nan
Latent vector - mean: -1042.1241455078125 std: 94325.7109375
Logits - mean: nan std: nan
Latent vector - mean: -0.4655698537826538 std: 33.574344635009766
Logits - mean: nan std: nan
Latent vector - mean: 0.043688222765922546 std: 29.642148971557617
Logits - mean: nan std: nan
Latent vector - mean: -0.6615296602249146 std: 35.59878158569336
Logits - mean: nan std: nan
Latent vector - mean: 0.005892306566238403 std: 31.914508819580078
Logits - mean: nan std: nan
Latent vector - mean: -0.25238344073295593 std: 29.22529411315918
Logits - mean: nan std: nan
Latent vector - mean: -0.528472900390625 std: 28.00954246520996
Logits - mean: nan std: nan
Latent vector - mean: 0.11117375642061234 std: 56.793949127197266
Logits - mean: nan std: nan
Latent vector - mean: -0.9020127654075623 std: 31.321792602539062
Logits - mean: nan std: nan
Latent vector - mean: -0.5836885571479797 std: 32.26776123046875
Logits - mean: nan std: nan
Latent vector - mean: -0.5506382584571838 std: 32.439674377441406
Logits - mean: nan std: nan
Latent vector - mean: 0.14162501692771912 std: 30.446510314941406
Logits - mean: nan std: nan
Latent vector - mean: 0.0705818384885788 std: 31.67571258544922
Logits - mean: nan std: nan
Latent vector - mean: 13621.9580078125 std: 1232954.875
Logits - mean: nan std: nan
Latent vector - mean: -0.2098146677017212 std: 33.4656982421875
Logits - mean: nan std: nan
Latent vector - mean: -80.45478820800781 std: 7358.89453125
Logits - mean: nan std: nan
Latent vector - mean: 0.03854326903820038 std: 30.46868133544922
Logits - mean: nan std: nan
Latent vector - mean: -1.1871776219090806e+29 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -48114.01171875 std: 4354728.5
Logits - mean: nan std: nan
Latent vector - mean: -0.7669816613197327 std: 35.35034942626953
Logits - mean: nan std: nan
Latent vector - mean: -0.3133007884025574 std: 34.677459716796875
Logits - mean: nan std: nan
Latent vector - mean: -0.042128533124923706 std: 32.179508209228516
Logits - mean: nan std: nan
Latent vector - mean: -0.41932642459869385 std: 31.179502487182617
Logits - mean: nan std: nan
Latent vector - mean: -0.2525130808353424 std: 33.60594177246094
Logits - mean: nan std: nan
Latent vector - mean: 13.921481132507324 std: 1259.7005615234375
Logits - mean: nan std: nan
Latent vector - mean: -0.4724960923194885 std: 29.704036712646484
Logits - mean: nan std: nan
Latent vector - mean: -0.1308160126209259 std: 34.1412353515625
Logits - mean: nan std: nan
Latent vector - mean: 11089915936768.0 std: 1003744661602304.0
Logits - mean: nan std: nan
Latent vector - mean: -0.5254148840904236 std: 32.256752014160156
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -173037.953125 std: 15661530.0
Logits - mean: nan std: nan
Latent vector - mean: -0.1670011430978775 std: 30.62938690185547
Logits - mean: nan std: nan
Latent vector - mean: -0.4532982110977173 std: 33.4260368347168
Logits - mean: nan std: nan
Latent vector - mean: -0.3905356526374817 std: 32.75510025024414
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: 4667786.0 std: 422479808.0
Logits - mean: nan std: nan
Latent vector - mean: -1534.9002685546875 std: 138888.765625
Logits - mean: nan std: nan
Latent vector - mean: -0.16007138788700104 std: 32.13697814941406
Logits - mean: nan std: nan
Latent vector - mean: -338.9034423828125 std: 30643.2109375
Logits - mean: nan std: nan
Latent vector - mean: -0.5480587482452393 std: 31.557266235351562
Logits - mean: nan std: nan
Latent vector - mean: 2811750.0 std: 254490560.0
Logits - mean: nan std: nan
Latent vector - mean: -0.4217725098133087 std: 33.625587463378906
Logits - mean: nan std: nan
Latent vector - mean: -38.9004020690918 std: 3457.91650390625
Logits - mean: nan std: nan
Latent vector - mean: -0.1318230777978897 std: 32.2508430480957
Logits - mean: nan std: nan
Latent vector - mean: 15065306112.0 std: 1363555909632.0
Logits - mean: nan std: nan
Latent vector - mean: -0.03359989821910858 std: 32.285037994384766
Logits - mean: nan std: nan
Latent vector - mean: -0.7050042748451233 std: 36.01948928833008
Logits - mean: nan std: nan
Latent vector - mean: -0.335125595331192 std: 31.41960334777832
Logits - mean: nan std: nan
Latent vector - mean: 0.04151672124862671 std: 31.21596908569336
Logits - mean: nan std: nan
Latent vector - mean: -0.6540395617485046 std: 36.31198501586914
Logits - mean: nan std: nan
Latent vector - mean: -0.48108088970184326 std: 32.083736419677734
Logits - mean: nan std: nan
Latent vector - mean: -0.2780369818210602 std: 31.36591911315918
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.5480958223342896 std: 36.036014556884766
Logits - mean: nan std: nan
Latent vector - mean: -0.381458044052124 std: 30.072856903076172
Logits - mean: nan std: nan
Latent vector - mean: 3.464061892123689e+17 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -27736.09375 std: 2509103.5
Logits - mean: nan std: nan
Latent vector - mean: 5964964397318144.0 std: inf
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Validating:  81%|████████  | 174/215 [00:00&lt;00:00, 468.80batch/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: 865630324523008.0 std: 7.834820929807974e+16
Logits - mean: nan std: nan
Latent vector - mean: 41894293798912.0 std: 3791864222187520.0
Logits - mean: nan std: nan
Latent vector - mean: -4154873.75 std: 376054592.0
Logits - mean: nan std: nan
Latent vector - mean: -0.7277852296829224 std: 32.29248809814453
Logits - mean: nan std: nan
Latent vector - mean: -0.19134604930877686 std: 31.684465408325195
Logits - mean: nan std: nan
Latent vector - mean: 156578.125 std: 14171853.0
Logits - mean: nan std: nan
Latent vector - mean: -2.4436470005461156e+18 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 62139.15625 std: 5620837.5
Logits - mean: nan std: nan
Latent vector - mean: -0.595639705657959 std: 31.746313095092773
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.07096116244792938 std: 30.565893173217773
Logits - mean: nan std: nan
Latent vector - mean: 0.08429761230945587 std: 31.881195068359375
Logits - mean: nan std: nan
Latent vector - mean: -2607980109365248.0 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -0.3202917277812958 std: 31.11725425720215
Logits - mean: nan std: nan
Latent vector - mean: 0.00917080044746399 std: 31.30068016052246
Logits - mean: nan std: nan
Latent vector - mean: -0.49232804775238037 std: 33.53407669067383
Logits - mean: nan std: nan
Latent vector - mean: -0.21852272748947144 std: 28.964275360107422
Logits - mean: nan std: nan
Latent vector - mean: -0.08737565577030182 std: 30.33548355102539
Logits - mean: nan std: nan
Latent vector - mean: -0.4056131839752197 std: 35.3856315612793
Logits - mean: nan std: nan
Latent vector - mean: -0.49588730931282043 std: 32.7951545715332
Logits - mean: nan std: nan
Latent vector - mean: -0.7012705206871033 std: 31.095144271850586
Logits - mean: nan std: nan
Latent vector - mean: -271288.21875 std: 24554214.0
Logits - mean: nan std: nan
Latent vector - mean: -0.1049535870552063 std: 31.54643440246582
Logits - mean: nan std: nan
Latent vector - mean: -3.577280044555664 std: 335.85943603515625
Logits - mean: nan std: nan
Latent vector - mean: -0.5166319608688354 std: 36.317710876464844
Logits - mean: nan std: nan
Latent vector - mean: -0.8497999906539917 std: 36.5615119934082
Logits - mean: nan std: nan
Latent vector - mean: -0.3779315948486328 std: 35.35493087768555
Logits - mean: nan std: nan
Latent vector - mean: -0.3318307399749756 std: 31.379638671875
Logits - mean: nan std: nan
Latent vector - mean: 0.15273186564445496 std: 30.612354278564453
Logits - mean: nan std: nan
Latent vector - mean: 1170881152.0 std: 104618606592.0
Logits - mean: nan std: nan
Latent vector - mean: 560163776.0 std: 50700238848.0
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -9.46867847442627 std: 841.7190551757812
Logits - mean: nan std: nan
Latent vector - mean: 6.679557800292969 std: 636.4637451171875
Logits - mean: nan std: nan
Latent vector - mean: 340.4300231933594 std: 30850.5546875
Logits - mean: nan std: nan
Latent vector - mean: -0.362568736076355 std: 32.492000579833984
Logits - mean: nan std: nan
Latent vector - mean: -0.6774052381515503 std: 32.27694320678711
Logits - mean: nan std: nan
Latent vector - mean: 92.41631317138672 std: 8445.0244140625
Logits - mean: nan std: nan
Latent vector - mean: -1.7645798921585083 std: 150.8224334716797
Logits - mean: nan std: nan
Latent vector - mean: 0.02759253978729248 std: 31.684358596801758
Logits - mean: nan std: nan
Latent vector - mean: -0.33404698967933655 std: 30.9573974609375
Logits - mean: nan std: nan
Latent vector - mean: -0.3448624610900879 std: 33.463478088378906
Logits - mean: nan std: nan
Latent vector - mean: -0.2757032513618469 std: 30.67877960205078
Logits - mean: nan std: nan
Latent vector - mean: -189807.109375 std: 17018698.0
Logits - mean: nan std: nan
Latent vector - mean: -0.29773861169815063 std: 34.54834747314453
Logits - mean: nan std: nan
Latent vector - mean: -0.8313973546028137 std: 33.12614822387695
Logits - mean: nan std: nan
Latent vector - mean: -0.1937391757965088 std: 32.291873931884766
Logits - mean: nan std: nan
Latent vector - mean: 351970086879232.0 std: 3.065981946350797e+16
Logits - mean: nan std: nan
Latent vector - mean: -0.5235984325408936 std: 28.765316009521484
Logits - mean: nan std: nan
Latent vector - mean: -8389229805568.0 std: 759306395844608.0
Logits - mean: nan std: nan
Latent vector - mean: -0.2717125713825226 std: 27.79340171813965
Logits - mean: nan std: nan
Latent vector - mean: -0.8060907125473022 std: 36.46027374267578
Logits - mean: nan std: nan
Latent vector - mean: -732195.8125 std: 66270796.0
Logits - mean: nan std: nan
Latent vector - mean: -165.6530303955078 std: 10540.302734375
Logits - mean: nan std: nan
Latent vector - mean: -644502323200.0 std: 58333692166144.0
Logits - mean: nan std: nan
Latent vector - mean: 4747.91796875 std: 429705.84375
Logits - mean: nan std: nan
Latent vector - mean: -490.5875244140625 std: 44373.21484375
Logits - mean: nan std: nan
Latent vector - mean: -0.4498118460178375 std: 29.831989288330078
Logits - mean: nan std: nan
Latent vector - mean: -0.13406848907470703 std: 31.1370849609375
Logits - mean: nan std: nan
Latent vector - mean: -0.3250678777694702 std: 29.567516326904297
Logits - mean: nan std: nan
Latent vector - mean: -967.546630859375 std: 87565.125
Logits - mean: nan std: nan
Latent vector - mean: -964131.75 std: 87263184.0
Logits - mean: nan std: nan
Latent vector - mean: -0.19743508100509644 std: 32.40563201904297
Logits - mean: nan std: nan
Latent vector - mean: 0.04337969422340393 std: 29.20772361755371
Logits - mean: nan std: nan
Latent vector - mean: -0.36605697870254517 std: 33.299503326416016
Logits - mean: nan std: nan
Latent vector - mean: -0.5580765604972839 std: 28.694448471069336
Logits - mean: nan std: nan
Latent vector - mean: -0.7142980098724365 std: 32.99846649169922
Logits - mean: nan std: nan
Latent vector - mean: 128297.625 std: 11612205.0
Logits - mean: nan std: nan
Latent vector - mean: -0.6542007923126221 std: 30.096040725708008
Logits - mean: nan std: nan
Latent vector - mean: -0.5934620499610901 std: 28.44643211364746
Logits - mean: nan std: nan
Latent vector - mean: -0.04002416133880615 std: 32.78437042236328
Logits - mean: nan std: nan
Latent vector - mean: -14919680.0 std: 1350375296.0
Logits - mean: nan std: nan
Latent vector - mean: 149049.4375 std: 13490465.0
Logits - mean: nan std: nan
Latent vector - mean: 0.1898949146270752 std: 37.51063537597656
Logits - mean: nan std: nan
Latent vector - mean: -0.8129245042800903 std: 30.859529495239258
Logits - mean: nan std: nan
Latent vector - mean: -0.5451139807701111 std: 29.48539161682129
Logits - mean: nan std: nan
Latent vector - mean: -0.2904481887817383 std: 34.51759719848633
Logits - mean: nan std: nan
Latent vector - mean: 324053024.0 std: 33380087808.0
Logits - mean: nan std: nan
Latent vector - mean: -0.48903247714042664 std: 34.128265380859375
Logits - mean: nan std: nan
Latent vector - mean: 0.10179522633552551 std: 29.35253143310547
Logits - mean: nan std: nan
Latent vector - mean: -0.6834069490432739 std: 33.06107711791992
Logits - mean: nan std: nan
Latent vector - mean: 1.8724330842566855e+34 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -47.04927444458008 std: 4183.25927734375
Logits - mean: nan std: nan
Latent vector - mean: -0.20278432965278625 std: 32.797786712646484
Logits - mean: nan std: nan
Latent vector - mean: -0.18664807081222534 std: 32.29609680175781
Logits - mean: nan std: nan
Latent vector - mean: 0.03942035138607025 std: 28.837446212768555
Logits - mean: nan std: nan
Latent vector - mean: -0.486836701631546 std: 31.62373924255371
Logits - mean: nan std: nan
Latent vector - mean: -41.416194915771484 std: 3688.162353515625
Logits - mean: nan std: nan
Latent vector - mean: -0.03240847587585449 std: 27.34623908996582
Logits - mean: nan std: nan
Latent vector - mean: 0.025464937090873718 std: 31.686134338378906
Logits - mean: nan std: nan
Latent vector - mean: -0.6220176815986633 std: 32.73845672607422
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.12421290576457977 std: 29.060420989990234
Logits - mean: nan std: nan
Latent vector - mean: -0.39463645219802856 std: 32.97126770019531
Logits - mean: nan std: nan
Latent vector - mean: 0.19310563802719116 std: 31.141443252563477
Logits - mean: nan std: nan
Latent vector - mean: -0.035960689187049866 std: 33.076576232910156
Logits - mean: nan std: nan
Latent vector - mean: -0.41468125581741333 std: 32.253910064697266
Logits - mean: nan std: nan
Latent vector - mean: -0.20893804728984833 std: 29.667680740356445
Logits - mean: nan std: nan
Latent vector - mean: -13.576967239379883 std: 1206.6875
Logits - mean: nan std: nan
Latent vector - mean: -0.23514162003993988 std: 34.436431884765625
Logits - mean: nan std: nan
Latent vector - mean: -0.11533629894256592 std: 30.54273223876953
Logits - mean: nan std: nan
Latent vector - mean: -0.24151156842708588 std: 31.268129348754883
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3/10, Train Loss: nan, Train Accuracy: 41.00%, Val Loss: nan, Val Accuracy: 38.04%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4/10 - Train:  25%|██▌       | 1/4 [00:00&lt;00:00,  6.28batch/s, accuracy=41, loss=nan]  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: 4.0036351490137186e+29 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -0.3224312961101532 std: 35.07735061645508
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.23376011848449707 std: 44.73095703125
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4/10 - Train: 100%|██████████| 4/4 [00:00&lt;00:00, 14.69batch/s, accuracy=41, loss=nan]
Validating:  27%|██▋       | 58/215 [00:00&lt;00:00, 284.32batch/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: -0.29731759428977966 std: 36.13969421386719
Logits - mean: nan std: nan
Latent vector - mean: 831898.4375 std: 78381584.0
Logits - mean: nan std: nan
Latent vector - mean: -0.626007080078125 std: 35.171630859375
Logits - mean: nan std: nan
Latent vector - mean: -0.32722145318984985 std: 32.95552444458008
Logits - mean: nan std: nan
Latent vector - mean: -0.24020256102085114 std: 30.433435440063477
Logits - mean: nan std: nan
Latent vector - mean: -0.5395529270172119 std: 32.542930603027344
Logits - mean: nan std: nan
Latent vector - mean: -26984933376.0 std: 2366943789056.0
Logits - mean: nan std: nan
Latent vector - mean: -0.4339239299297333 std: 33.734214782714844
Logits - mean: nan std: nan
Latent vector - mean: -17.559322357177734 std: 1548.48828125
Logits - mean: nan std: nan
Latent vector - mean: -0.482112318277359 std: 32.073673248291016
Logits - mean: nan std: nan
Latent vector - mean: -0.04822944104671478 std: 30.547029495239258
Logits - mean: nan std: nan
Latent vector - mean: nan std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.02244921773672104 std: 31.777095794677734
Logits - mean: nan std: nan
Latent vector - mean: -0.5918995141983032 std: 34.65327453613281
Logits - mean: nan std: nan
Latent vector - mean: 7797550.5 std: 705753792.0
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.9197496175765991 std: 34.7816162109375
Logits - mean: nan std: nan
Latent vector - mean: 70236280.0 std: 6357062656.0
Logits - mean: nan std: nan
Latent vector - mean: -0.4164987802505493 std: 33.58905029296875
Logits - mean: nan std: nan
Latent vector - mean: 17346410496.0 std: 1570017902592.0
Logits - mean: nan std: nan
Latent vector - mean: 86.01908874511719 std: 7841.16455078125
Logits - mean: nan std: nan
Latent vector - mean: -0.3000844120979309 std: 30.845956802368164
Logits - mean: nan std: nan
Latent vector - mean: -0.6612571477890015 std: 32.11452865600586
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.42348527908325195 std: 31.973159790039062
Logits - mean: nan std: nan
Latent vector - mean: -0.20989687740802765 std: 36.420387268066406
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.08122935891151428 std: 32.056339263916016
Logits - mean: nan std: nan
Latent vector - mean: -0.7342040538787842 std: 31.3829288482666
Logits - mean: nan std: nan
Latent vector - mean: -0.44883617758750916 std: 34.560707092285156
Logits - mean: nan std: nan
Latent vector - mean: 2.1348793417432912e+23 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 0.19462084770202637 std: 35.90142822265625
Logits - mean: nan std: nan
Latent vector - mean: -61.51959991455078 std: 5827.45654296875
Logits - mean: nan std: nan
Latent vector - mean: 109548675072.0 std: 9938624577536.0
Logits - mean: nan std: nan
Latent vector - mean: -0.2725003957748413 std: 34.10752487182617
Logits - mean: nan std: nan
Latent vector - mean: -0.8441677689552307 std: 30.39349937438965
Logits - mean: nan std: nan
Latent vector - mean: 0.2066294103860855 std: 31.15292739868164
Logits - mean: nan std: nan
Latent vector - mean: -5.846924110315127e+18 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -0.5835916996002197 std: 35.2171745300293
Logits - mean: nan std: nan
Latent vector - mean: -0.4360020160675049 std: 30.326242446899414
Logits - mean: nan std: nan
Latent vector - mean: -0.2548750638961792 std: 33.11790466308594
Logits - mean: nan std: nan
Latent vector - mean: -0.1515694111585617 std: 33.19123840332031
Logits - mean: nan std: nan
Latent vector - mean: -43.28057861328125 std: 3952.080322265625
Logits - mean: nan std: nan
Latent vector - mean: -514.0445556640625 std: 46481.62890625
Logits - mean: nan std: nan
Latent vector - mean: -0.29060426354408264 std: 32.49253845214844
Logits - mean: nan std: nan
Latent vector - mean: -2.1278671695622752e+29 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 2012738.5 std: 182265648.0
Logits - mean: nan std: nan
Latent vector - mean: -0.5030120611190796 std: 34.46824264526367
Logits - mean: nan std: nan
Latent vector - mean: -0.5617841482162476 std: 29.705549240112305
Logits - mean: nan std: nan
Latent vector - mean: -0.46397608518600464 std: 30.776552200317383
Logits - mean: nan std: nan
Latent vector - mean: 0.06330432742834091 std: 31.110042572021484
Logits - mean: nan std: nan
Latent vector - mean: -0.5602477192878723 std: 31.703426361083984
Logits - mean: nan std: nan
Latent vector - mean: -0.7759977579116821 std: 34.84567642211914
Logits - mean: nan std: nan
Latent vector - mean: -0.5977637767791748 std: 35.42885208129883
Logits - mean: nan std: nan
Latent vector - mean: -11204892672.0 std: 863877136384.0
Logits - mean: nan std: nan
Latent vector - mean: 15151.4599609375 std: 1371350.125
Logits - mean: nan std: nan
Latent vector - mean: -0.4650259017944336 std: 33.57435607910156
Logits - mean: nan std: nan
Latent vector - mean: 0.043555907905101776 std: 29.642019271850586
Logits - mean: nan std: nan
Latent vector - mean: -0.6615079045295715 std: 35.59865951538086
Logits - mean: nan std: nan
Latent vector - mean: 0.0058447569608688354 std: 31.91435432434082
Logits - mean: nan std: nan
Latent vector - mean: -0.2524496018886566 std: 29.225072860717773
Logits - mean: nan std: nan
Latent vector - mean: -0.5289132595062256 std: 28.00965118408203
Logits - mean: nan std: nan
Latent vector - mean: -2.0618793964385986 std: 154.48252868652344
Logits - mean: nan std: nan
Latent vector - mean: -0.9023460149765015 std: 31.32171058654785
Logits - mean: nan std: nan
Latent vector - mean: -0.5840334892272949 std: 32.26777648925781
Logits - mean: nan std: nan
Latent vector - mean: -0.5510419011116028 std: 32.439735412597656
Logits - mean: nan std: nan
Latent vector - mean: 0.1415431797504425 std: 30.446487426757812
Logits - mean: nan std: nan
Latent vector - mean: 0.0703970268368721 std: 31.675823211669922
Logits - mean: nan std: nan
Latent vector - mean: 10125.3095703125 std: 916474.5
Logits - mean: nan std: nan
Latent vector - mean: -0.20968565344810486 std: 33.465736389160156
Logits - mean: nan std: nan
Latent vector - mean: -26.76827621459961 std: 2642.5830078125
Logits - mean: nan std: nan
Latent vector - mean: 0.03822658956050873 std: 30.468191146850586
Logits - mean: nan std: nan
Latent vector - mean: 2.3236217273247368e+29 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -70330.25 std: 6365513.0
Logits - mean: nan std: nan
Latent vector - mean: -0.76670902967453 std: 35.350406646728516
Logits - mean: nan std: nan
Latent vector - mean: -0.31316113471984863 std: 34.677589416503906
Logits - mean: nan std: nan
Latent vector - mean: -0.042005062103271484 std: 32.17942810058594
Logits - mean: nan std: nan
Latent vector - mean: -0.41986575722694397 std: 31.179262161254883
Logits - mean: nan std: nan
Latent vector - mean: -0.25327715277671814 std: 33.60607147216797
Logits - mean: nan std: nan
Latent vector - mean: 23.230175018310547 std: 2102.057861328125
Logits - mean: nan std: nan
Latent vector - mean: -0.47247645258903503 std: 29.70407485961914
Logits - mean: nan std: nan
Latent vector - mean: -0.13167333602905273 std: 34.14109420776367
Logits - mean: nan std: nan
Latent vector - mean: 28866942861312.0 std: 2612737590951936.0
Logits - mean: nan std: nan
Latent vector - mean: -0.5246652364730835 std: 32.25716018676758
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: 119861.09375 std: 10848668.0
Logits - mean: nan std: nan
Latent vector - mean: -0.16702072322368622 std: 30.62954330444336
Logits - mean: nan std: nan
Latent vector - mean: -0.4532535672187805 std: 33.42610168457031
Logits - mean: nan std: nan
Latent vector - mean: -0.38863396644592285 std: 32.74654769897461
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -1242741.875 std: 112480104.0
Logits - mean: nan std: nan
Latent vector - mean: 1386.6868896484375 std: 125459.5
Logits - mean: nan std: nan
Latent vector - mean: -0.15992623567581177 std: 32.13698959350586
Logits - mean: nan std: nan
Latent vector - mean: 197.04013061523438 std: 17864.94921875
Logits - mean: nan std: nan
Latent vector - mean: -0.5487771034240723 std: 31.557979583740234
Logits - mean: nan std: nan
Latent vector - mean: -19248812.0 std: 1742203520.0
Logits - mean: nan std: nan
Latent vector - mean: -0.4209020435810089 std: 33.62563705444336
Logits - mean: nan std: nan
Latent vector - mean: 105.90289306640625 std: 9648.392578125
Logits - mean: nan std: nan
Latent vector - mean: -0.13195180892944336 std: 32.251129150390625
Logits - mean: nan std: nan
Latent vector - mean: -87074373632.0 std: 7881072574464.0
Logits - mean: nan std: nan
Latent vector - mean: -0.033335015177726746 std: 32.285133361816406
Logits - mean: nan std: nan
Latent vector - mean: -0.7053115963935852 std: 36.019371032714844
Logits - mean: nan std: nan
Latent vector - mean: -0.33501553535461426 std: 31.41974639892578
Logits - mean: nan std: nan
Latent vector - mean: 0.041565656661987305 std: 31.216167449951172
Logits - mean: nan std: nan
Latent vector - mean: -0.6552714109420776 std: 36.30930709838867
Logits - mean: nan std: nan
Latent vector - mean: -0.4807129204273224 std: 32.083553314208984
Logits - mean: nan std: nan
Latent vector - mean: -0.2780376672744751 std: 31.3658447265625
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.5302271842956543 std: 36.036346435546875
Logits - mean: nan std: nan
Latent vector - mean: -0.381458044052124 std: 30.072954177856445
Logits - mean: nan std: nan
Latent vector - mean: 1.0113862003064832e+17 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 75138.09375 std: 6798738.0
Logits - mean: nan std: nan
Latent vector - mean: -3757313894645760.0 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -537038247952384.0 std: 4.860702535712768e+16
Logits - mean: nan std: nan
Latent vector - mean: 9730215903232.0 std: 880667609006080.0
Logits - mean: nan std: nan
Latent vector - mean: 9796282.0 std: 886661120.0
Logits - mean: nan std: nan
Latent vector - mean: -0.7249151468276978 std: 32.285736083984375
Logits - mean: nan std: nan
Latent vector - mean: -0.19141322374343872 std: 31.684505462646484
Logits - mean: nan std: nan
Latent vector - mean: -297695.0625 std: 26944258.0
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Validating:  85%|████████▌ | 183/215 [00:00&lt;00:00, 496.39batch/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: -1.1067005783957832e+18 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 19478.5625 std: 1756688.875
Logits - mean: nan std: nan
Latent vector - mean: -0.594484806060791 std: 31.744470596313477
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.07102129608392715 std: 30.566024780273438
Logits - mean: nan std: nan
Latent vector - mean: 0.0855458527803421 std: 31.88176727294922
Logits - mean: nan std: nan
Latent vector - mean: 5468990700781568.0 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -0.32021987438201904 std: 31.116788864135742
Logits - mean: nan std: nan
Latent vector - mean: 0.009252786636352539 std: 31.30084228515625
Logits - mean: nan std: nan
Latent vector - mean: -0.49193283915519714 std: 33.53365707397461
Logits - mean: nan std: nan
Latent vector - mean: -0.2184629738330841 std: 28.96406364440918
Logits - mean: nan std: nan
Latent vector - mean: -0.08760756254196167 std: 30.33539390563965
Logits - mean: nan std: nan
Latent vector - mean: -0.405692458152771 std: 35.3856315612793
Logits - mean: nan std: nan
Latent vector - mean: -0.4957381784915924 std: 32.795318603515625
Logits - mean: nan std: nan
Latent vector - mean: -0.7011603713035583 std: 31.095258712768555
Logits - mean: nan std: nan
Latent vector - mean: -3518019.25 std: 318414720.0
Logits - mean: nan std: nan
Latent vector - mean: -0.10496707260608673 std: 31.54643440246582
Logits - mean: nan std: nan
Latent vector - mean: -0.3792724609375 std: 55.891780853271484
Logits - mean: nan std: nan
Latent vector - mean: -0.5166386961936951 std: 36.31768798828125
Logits - mean: nan std: nan
Latent vector - mean: -0.8498896360397339 std: 36.5614013671875
Logits - mean: nan std: nan
Latent vector - mean: -0.20184141397476196 std: 36.60763168334961
Logits - mean: nan std: nan
Latent vector - mean: -0.33176761865615845 std: 31.379718780517578
Logits - mean: nan std: nan
Latent vector - mean: 0.15296173095703125 std: 30.61237335205078
Logits - mean: nan std: nan
Latent vector - mean: -885003200.0 std: 80519053312.0
Logits - mean: nan std: nan
Latent vector - mean: 1147352320.0 std: 103846469632.0
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -4.281705856323242 std: 373.364990234375
Logits - mean: nan std: nan
Latent vector - mean: -7.706277370452881 std: 667.5501708984375
Logits - mean: nan std: nan
Latent vector - mean: -250.2622833251953 std: 22612.857421875
Logits - mean: nan std: nan
Latent vector - mean: -0.3625807762145996 std: 32.49189758300781
Logits - mean: nan std: nan
Latent vector - mean: -0.6768876314163208 std: 32.276737213134766
Logits - mean: nan std: nan
Latent vector - mean: -23.107112884521484 std: 2011.7220458984375
Logits - mean: nan std: nan
Latent vector - mean: -2.9031107425689697 std: 252.3551788330078
Logits - mean: nan std: nan
Latent vector - mean: -0.022911667823791504 std: 31.318010330200195
Logits - mean: nan std: nan
Latent vector - mean: -0.33376985788345337 std: 30.957292556762695
Logits - mean: nan std: nan
Latent vector - mean: -0.42740485072135925 std: 33.37141418457031
Logits - mean: nan std: nan
Latent vector - mean: -0.2757417559623718 std: 30.678794860839844
Logits - mean: nan std: nan
Latent vector - mean: -188267.640625 std: 17399632.0
Logits - mean: nan std: nan
Latent vector - mean: -0.29758355021476746 std: 34.54841232299805
Logits - mean: nan std: nan
Latent vector - mean: -0.8314472436904907 std: 33.126033782958984
Logits - mean: nan std: nan
Latent vector - mean: -0.1928766667842865 std: 32.291751861572266
Logits - mean: nan std: nan
Latent vector - mean: -19878463406080.0 std: 2429366646603776.0
Logits - mean: nan std: nan
Latent vector - mean: -0.5234308838844299 std: 28.765439987182617
Logits - mean: nan std: nan
Latent vector - mean: -534507002265600.0 std: 4.837805206064333e+16
Logits - mean: nan std: nan
Latent vector - mean: -0.2717318534851074 std: 27.793447494506836
Logits - mean: nan std: nan
Latent vector - mean: -0.8060309886932373 std: 36.45918655395508
Logits - mean: nan std: nan
Latent vector - mean: 379393.15625 std: 34338764.0
Logits - mean: nan std: nan
Latent vector - mean: 454.45220947265625 std: 45425.66015625
Logits - mean: nan std: nan
Latent vector - mean: 1469342154752.0 std: 132989677731840.0
Logits - mean: nan std: nan
Latent vector - mean: 15277.3076171875 std: 1382741.75
Logits - mean: nan std: nan
Latent vector - mean: -1637.1016845703125 std: 148143.859375
Logits - mean: nan std: nan
Latent vector - mean: -0.44953566789627075 std: 29.832063674926758
Logits - mean: nan std: nan
Latent vector - mean: -0.13404834270477295 std: 31.13711166381836
Logits - mean: nan std: nan
Latent vector - mean: -0.324491024017334 std: 29.567052841186523
Logits - mean: nan std: nan
Latent vector - mean: 353.0638732910156 std: 31962.99609375
Logits - mean: nan std: nan
Latent vector - mean: -2126153.75 std: 192437408.0
Logits - mean: nan std: nan
Latent vector - mean: -0.19774872064590454 std: 32.40564727783203
Logits - mean: nan std: nan
Latent vector - mean: 0.04370824992656708 std: 29.207395553588867
Logits - mean: nan std: nan
Latent vector - mean: -0.3659563958644867 std: 33.29950714111328
Logits - mean: nan std: nan
Latent vector - mean: -0.5578278303146362 std: 28.694570541381836
Logits - mean: nan std: nan
Latent vector - mean: -0.6193833351135254 std: 34.7459602355957
Logits - mean: nan std: nan
Latent vector - mean: -1056799.25 std: 95650544.0
Logits - mean: nan std: nan
Latent vector - mean: -0.653956413269043 std: 30.095870971679688
Logits - mean: nan std: nan
Latent vector - mean: -0.5915061235427856 std: 28.448537826538086
Logits - mean: nan std: nan
Latent vector - mean: -0.04032871127128601 std: 32.78424835205078
Logits - mean: nan std: nan
Latent vector - mean: -11121622.0 std: 1006614336.0
Logits - mean: nan std: nan
Latent vector - mean: 27445.931640625 std: 2484176.0
Logits - mean: nan std: nan
Latent vector - mean: -0.21384570002555847 std: 38.57069778442383
Logits - mean: nan std: nan
Latent vector - mean: -0.8131567239761353 std: 30.859350204467773
Logits - mean: nan std: nan
Latent vector - mean: -0.5450469255447388 std: 29.48558235168457
Logits - mean: nan std: nan
Latent vector - mean: -0.2906153202056885 std: 34.51762390136719
Logits - mean: nan std: nan
Latent vector - mean: 199113472.0 std: 14517261312.0
Logits - mean: nan std: nan
Latent vector - mean: -0.48892509937286377 std: 34.12824249267578
Logits - mean: nan std: nan
Latent vector - mean: 0.10164585709571838 std: 29.352313995361328
Logits - mean: nan std: nan
Latent vector - mean: -0.6830744743347168 std: 33.06121826171875
Logits - mean: nan std: nan
Latent vector - mean: -1.577573098059458e+34 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -34.58211898803711 std: 3054.92919921875
Logits - mean: nan std: nan
Latent vector - mean: -0.20282919704914093 std: 32.79768371582031
Logits - mean: nan std: nan
Latent vector - mean: -0.18654802441596985 std: 32.29588317871094
Logits - mean: nan std: nan
Latent vector - mean: 0.039295703172683716 std: 28.83817481994629
Logits - mean: nan std: nan
Latent vector - mean: -0.48667073249816895 std: 31.62383460998535
Logits - mean: nan std: nan
Latent vector - mean: -9.747579574584961 std: 822.4312133789062
Logits - mean: nan std: nan
Latent vector - mean: -0.032542139291763306 std: 27.34617805480957
Logits - mean: nan std: nan
Latent vector - mean: 0.02575552463531494 std: 31.68651008605957
Logits - mean: nan std: nan
Latent vector - mean: -0.6221541166305542 std: 32.73854064941406
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.12401078641414642 std: 29.060791015625
Logits - mean: nan std: nan
Latent vector - mean: -0.39519423246383667 std: 32.97166442871094
Logits - mean: nan std: nan
Latent vector - mean: 0.19327251613140106 std: 31.141376495361328
Logits - mean: nan std: nan
Latent vector - mean: -0.03603343665599823 std: 33.07658004760742
Logits - mean: nan std: nan
Latent vector - mean: -0.41492483019828796 std: 32.253875732421875
Logits - mean: nan std: nan
Latent vector - mean: -0.20858199894428253 std: 29.667757034301758
Logits - mean: nan std: nan
Latent vector - mean: -20.041994094848633 std: 1791.6763916015625
Logits - mean: nan std: nan
Latent vector - mean: -0.23519505560398102 std: 34.43657684326172
Logits - mean: nan std: nan
Latent vector - mean: -0.11534412205219269 std: 30.54299545288086
Logits - mean: nan std: nan
Latent vector - mean: -0.24049925804138184 std: 31.268091201782227
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4/10, Train Loss: nan, Train Accuracy: 41.00%, Val Loss: nan, Val Accuracy: 38.04%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5/10 - Train:  25%|██▌       | 1/4 [00:00&lt;00:00,  6.66batch/s, accuracy=41, loss=nan]  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: -0.5599571466445923 std: 36.44732666015625
Logits - mean: nan std: nan
Latent vector - mean: -0.5175164937973022 std: 37.95774459838867
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -5.43568754196167 std: 48.71965789794922
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5/10 - Train: 100%|██████████| 4/4 [00:00&lt;00:00, 15.11batch/s, accuracy=41, loss=nan]
Validating:  26%|██▌       | 56/215 [00:00&lt;00:00, 250.08batch/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: -0.29725223779678345 std: 36.139705657958984
Logits - mean: nan std: nan
Latent vector - mean: -4070507.25 std: 367504384.0
Logits - mean: nan std: nan
Latent vector - mean: -0.6290279626846313 std: 35.191368103027344
Logits - mean: nan std: nan
Latent vector - mean: -0.32719630002975464 std: 32.95555114746094
Logits - mean: nan std: nan
Latent vector - mean: -0.24012285470962524 std: 30.43336296081543
Logits - mean: nan std: nan
Latent vector - mean: -0.5398039817810059 std: 32.54275131225586
Logits - mean: nan std: nan
Latent vector - mean: -2933874432.0 std: 224997523456.0
Logits - mean: nan std: nan
Latent vector - mean: -0.43434756994247437 std: 33.73381423950195
Logits - mean: nan std: nan
Latent vector - mean: 25.36590003967285 std: 2337.22021484375
Logits - mean: nan std: nan
Latent vector - mean: -0.48226749897003174 std: 32.07373046875
Logits - mean: nan std: nan
Latent vector - mean: -0.048230841755867004 std: 30.546960830688477
Logits - mean: nan std: nan
Latent vector - mean: nan std: nan
Logits - mean: nan std: nan
Latent vector - mean: 0.04807582497596741 std: 32.00050735473633
Logits - mean: nan std: nan
Latent vector - mean: -0.5915381908416748 std: 34.65311813354492
Logits - mean: nan std: nan
Latent vector - mean: -62065104.0 std: 5617491968.0
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.9195479154586792 std: 34.781394958496094
Logits - mean: nan std: nan
Latent vector - mean: 16069633.0 std: 1454457216.0
Logits - mean: nan std: nan
Latent vector - mean: -0.416653573513031 std: 33.588932037353516
Logits - mean: nan std: nan
Latent vector - mean: -34479722496.0 std: 3120748298240.0
Logits - mean: nan std: nan
Latent vector - mean: -37.56375503540039 std: 3478.68310546875
Logits - mean: nan std: nan
Latent vector - mean: -0.299793004989624 std: 30.845922470092773
Logits - mean: nan std: nan
Latent vector - mean: -0.6612684726715088 std: 32.114349365234375
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.4237019419670105 std: 31.973007202148438
Logits - mean: nan std: nan
Latent vector - mean: -0.210317462682724 std: 36.42055130004883
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.20451778173446655 std: 32.19536209106445
Logits - mean: nan std: nan
Latent vector - mean: -0.7345023155212402 std: 31.38296890258789
Logits - mean: nan std: nan
Latent vector - mean: -0.44833752512931824 std: 34.56074523925781
Logits - mean: nan std: nan
Latent vector - mean: -6.486195152033807e+23 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 0.2490248680114746 std: 36.29289627075195
Logits - mean: nan std: nan
Latent vector - mean: 325.37933349609375 std: 29700.337890625
Logits - mean: nan std: nan
Latent vector - mean: -69071101952.0 std: 6300033875968.0
Logits - mean: nan std: nan
Latent vector - mean: -0.27273210883140564 std: 34.10747146606445
Logits - mean: nan std: nan
Latent vector - mean: -0.843403160572052 std: 30.39409828186035
Logits - mean: nan std: nan
Latent vector - mean: 0.20634733140468597 std: 31.152751922607422
Logits - mean: nan std: nan
Latent vector - mean: 1.665160882243502e+19 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -0.5835724472999573 std: 35.217506408691406
Logits - mean: nan std: nan
Latent vector - mean: -0.43678465485572815 std: 30.327007293701172
Logits - mean: nan std: nan
Latent vector - mean: -0.25318044424057007 std: 33.14552688598633
Logits - mean: nan std: nan
Latent vector - mean: -0.1515621393918991 std: 33.19113540649414
Logits - mean: nan std: nan
Latent vector - mean: -67.39415740966797 std: 6134.53759765625
Logits - mean: nan std: nan
Latent vector - mean: 680.6306762695312 std: 61645.078125
Logits - mean: nan std: nan
Latent vector - mean: -0.2905401587486267 std: 32.49244689941406
Logits - mean: nan std: nan
Latent vector - mean: -6.537943368025091e+29 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 968895.9375 std: 87892456.0
Logits - mean: nan std: nan
Latent vector - mean: -0.5027956962585449 std: 34.46842956542969
Logits - mean: nan std: nan
Latent vector - mean: -0.5615739822387695 std: 29.705522537231445
Logits - mean: nan std: nan
Latent vector - mean: -0.4638165235519409 std: 30.776508331298828
Logits - mean: nan std: nan
Latent vector - mean: 0.06352312862873077 std: 31.11005210876465
Logits - mean: nan std: nan
Latent vector - mean: -0.5599732995033264 std: 31.70346450805664
Logits - mean: nan std: nan
Latent vector - mean: -0.5328470468521118 std: 41.57965087890625
Logits - mean: nan std: nan
Latent vector - mean: -0.5974295139312744 std: 35.428585052490234
Logits - mean: nan std: nan
Latent vector - mean: 8250775040.0 std: 667686862848.0
Logits - mean: nan std: nan
Latent vector - mean: -12627.625 std: 1142925.75
Logits - mean: nan std: nan
Latent vector - mean: -0.4650399684906006 std: 33.574493408203125
Logits - mean: nan std: nan
Latent vector - mean: 0.043415337800979614 std: 29.642187118530273
Logits - mean: nan std: nan
Latent vector - mean: -0.6615103483200073 std: 35.59849166870117
Logits - mean: nan std: nan
Latent vector - mean: 0.006018772721290588 std: 31.914453506469727
Logits - mean: nan std: nan
Latent vector - mean: -0.25262248516082764 std: 29.2250919342041
Logits - mean: nan std: nan
Latent vector - mean: -0.5283463001251221 std: 28.009639739990234
Logits - mean: nan std: nan
Latent vector - mean: -1.453490972518921 std: 101.39834594726562
Logits - mean: nan std: nan
Latent vector - mean: -0.9018032550811768 std: 31.32182502746582
Logits - mean: nan std: nan
Latent vector - mean: -0.5841708183288574 std: 32.267723083496094
Logits - mean: nan std: nan
Latent vector - mean: -0.5505831241607666 std: 32.43990707397461
Logits - mean: nan std: nan
Latent vector - mean: 0.14161106944084167 std: 30.446609497070312
Logits - mean: nan std: nan
Latent vector - mean: 0.07050781697034836 std: 31.67576789855957
Logits - mean: nan std: nan
Latent vector - mean: -15167.052734375 std: 1372728.875
Logits - mean: nan std: nan
Latent vector - mean: -0.20977473258972168 std: 33.46577835083008
Logits - mean: nan std: nan
Latent vector - mean: -4.349247932434082 std: 1085.4881591796875
Logits - mean: nan std: nan
Latent vector - mean: 0.03834550082683563 std: 30.46820640563965
Logits - mean: nan std: nan
Latent vector - mean: -3.2416820725813386e+29 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 533305.625 std: 48269376.0
Logits - mean: nan std: nan
Latent vector - mean: -0.7469756007194519 std: 35.39353561401367
Logits - mean: nan std: nan
Latent vector - mean: -0.3133277893066406 std: 34.67750549316406
Logits - mean: nan std: nan
Latent vector - mean: -0.04189462959766388 std: 32.179588317871094
Logits - mean: nan std: nan
Latent vector - mean: -0.4195246994495392 std: 31.17938804626465
Logits - mean: nan std: nan
Latent vector - mean: -0.25270748138427734 std: 33.60615921020508
Logits - mean: nan std: nan
Latent vector - mean: 7.558395862579346 std: 684.2169799804688
Logits - mean: nan std: nan
Latent vector - mean: -0.47233307361602783 std: 29.704011917114258
Logits - mean: nan std: nan
Latent vector - mean: -0.13095691800117493 std: 34.14116287231445
Logits - mean: nan std: nan
Latent vector - mean: 20483783262208.0 std: 1853980346941440.0
Logits - mean: nan std: nan
Latent vector - mean: -0.525234043598175 std: 32.25668716430664
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: 425282.3125 std: 38492240.0
Logits - mean: nan std: nan
Latent vector - mean: -0.16681888699531555 std: 30.629541397094727
Logits - mean: nan std: nan
Latent vector - mean: -0.4533458948135376 std: 33.42618942260742
Logits - mean: nan std: nan
Latent vector - mean: -0.3886588215827942 std: 32.745941162109375
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: 3558808.5 std: 322106560.0
Logits - mean: nan std: nan
Latent vector - mean: 792.5347290039062 std: 71462.2421875
Logits - mean: nan std: nan
Latent vector - mean: -0.16009902954101562 std: 32.136817932128906
Logits - mean: nan std: nan
Latent vector - mean: -1705.372802734375 std: 154321.90625
Logits - mean: nan std: nan
Latent vector - mean: -0.5488459467887878 std: 31.55765724182129
Logits - mean: nan std: nan
Latent vector - mean: -44821396.0 std: 4056769536.0
Logits - mean: nan std: nan
Latent vector - mean: -0.4226111173629761 std: 33.6257438659668
Logits - mean: nan std: nan
Latent vector - mean: 13.797130584716797 std: 1312.284912109375
Logits - mean: nan std: nan
Latent vector - mean: -0.13187651336193085 std: 32.25110626220703
Logits - mean: nan std: nan
Latent vector - mean: 64969654272.0 std: 5880381702144.0
Logits - mean: nan std: nan
Latent vector - mean: -0.033831119537353516 std: 32.28506851196289
Logits - mean: nan std: nan
Latent vector - mean: -0.705441415309906 std: 36.019142150878906
Logits - mean: nan std: nan
Latent vector - mean: -0.3352603316307068 std: 31.419836044311523
Logits - mean: nan std: nan
Latent vector - mean: 0.041214704513549805 std: 31.215845108032227
Logits - mean: nan std: nan
Latent vector - mean: -0.6554362177848816 std: 36.309879302978516
Logits - mean: nan std: nan
Latent vector - mean: -0.4813920855522156 std: 32.08344650268555
Logits - mean: nan std: nan
Latent vector - mean: -0.2780938744544983 std: 31.365949630737305
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.5421461462974548 std: 36.02853775024414
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Validating:  76%|███████▋  | 164/215 [00:00&lt;00:00, 424.76batch/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: -0.38155874609947205 std: 30.073089599609375
Logits - mean: nan std: nan
Latent vector - mean: 5.564920405950464e+16 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 168776.546875 std: 15276934.0
Logits - mean: nan std: nan
Latent vector - mean: -1759202766749696.0 std: 1.592248658433147e+17
Logits - mean: nan std: nan
Latent vector - mean: 378932952039424.0 std: 3.429704473038029e+16
Logits - mean: nan std: nan
Latent vector - mean: -14215049904128.0 std: 1286602684891136.0
Logits - mean: nan std: nan
Latent vector - mean: 9601406.0 std: 869014720.0
Logits - mean: nan std: nan
Latent vector - mean: -0.7275905609130859 std: 32.292823791503906
Logits - mean: nan std: nan
Latent vector - mean: -0.19132345914840698 std: 31.68462371826172
Logits - mean: nan std: nan
Latent vector - mean: -27758.693359375 std: 2512407.25
Logits - mean: nan std: nan
Latent vector - mean: 1.5026116945332142e+18 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 30233.349609375 std: 2736007.0
Logits - mean: nan std: nan
Latent vector - mean: -0.5933606624603271 std: 31.742650985717773
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.07108756899833679 std: 30.565834045410156
Logits - mean: nan std: nan
Latent vector - mean: 0.08446591347455978 std: 31.88134765625
Logits - mean: nan std: nan
Latent vector - mean: 5153094782418944.0 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -0.32020652294158936 std: 31.117149353027344
Logits - mean: nan std: nan
Latent vector - mean: 0.009378433227539062 std: 31.300662994384766
Logits - mean: nan std: nan
Latent vector - mean: -0.4928826093673706 std: 33.53546142578125
Logits - mean: nan std: nan
Latent vector - mean: -0.21863801777362823 std: 28.96411895751953
Logits - mean: nan std: nan
Latent vector - mean: -0.08724359422922134 std: 30.335235595703125
Logits - mean: nan std: nan
Latent vector - mean: -0.405304491519928 std: 35.38591766357422
Logits - mean: nan std: nan
Latent vector - mean: -0.4956502914428711 std: 32.79511260986328
Logits - mean: nan std: nan
Latent vector - mean: -0.7014463543891907 std: 31.095184326171875
Logits - mean: nan std: nan
Latent vector - mean: 2252485.75 std: 203871760.0
Logits - mean: nan std: nan
Latent vector - mean: -0.10480120778083801 std: 31.546541213989258
Logits - mean: nan std: nan
Latent vector - mean: 5.308645248413086 std: 471.2185363769531
Logits - mean: nan std: nan
Latent vector - mean: -0.5166813135147095 std: 36.317665100097656
Logits - mean: nan std: nan
Latent vector - mean: -0.8496816158294678 std: 36.56137466430664
Logits - mean: nan std: nan
Latent vector - mean: -0.40108269453048706 std: 35.72474670410156
Logits - mean: nan std: nan
Latent vector - mean: -0.3320808708667755 std: 31.37973403930664
Logits - mean: nan std: nan
Latent vector - mean: 0.1530185341835022 std: 30.612241744995117
Logits - mean: nan std: nan
Latent vector - mean: -37076144.0 std: 2455708416.0
Logits - mean: nan std: nan
Latent vector - mean: -148933424.0 std: 13479914496.0
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: 2.3367788791656494 std: 230.5218505859375
Logits - mean: nan std: nan
Latent vector - mean: 0.5476000308990479 std: 88.09558868408203
Logits - mean: nan std: nan
Latent vector - mean: -21.82008934020996 std: 1936.894287109375
Logits - mean: nan std: nan
Latent vector - mean: -0.36249637603759766 std: 32.49205780029297
Logits - mean: nan std: nan
Latent vector - mean: -0.6769106388092041 std: 32.27745056152344
Logits - mean: nan std: nan
Latent vector - mean: -101.82042694091797 std: 9135.66796875
Logits - mean: nan std: nan
Latent vector - mean: -0.40284502506256104 std: 41.093475341796875
Logits - mean: nan std: nan
Latent vector - mean: 0.042008429765701294 std: 31.207897186279297
Logits - mean: nan std: nan
Latent vector - mean: -0.3340111970901489 std: 30.9572811126709
Logits - mean: nan std: nan
Latent vector - mean: -0.37239494919776917 std: 33.150428771972656
Logits - mean: nan std: nan
Latent vector - mean: -0.275608628988266 std: 30.678903579711914
Logits - mean: nan std: nan
Latent vector - mean: -274004.4375 std: 22834714.0
Logits - mean: nan std: nan
Latent vector - mean: -0.297870010137558 std: 34.54823684692383
Logits - mean: nan std: nan
Latent vector - mean: -0.8313442468643188 std: 33.12602233886719
Logits - mean: nan std: nan
Latent vector - mean: -0.19303515553474426 std: 32.29182434082031
Logits - mean: nan std: nan
Latent vector - mean: -228581414273024.0 std: 2.0923495823179776e+16
Logits - mean: nan std: nan
Latent vector - mean: -0.5232906937599182 std: 28.76534652709961
Logits - mean: nan std: nan
Latent vector - mean: 162039787945984.0 std: 1.4666166559571968e+16
Logits - mean: nan std: nan
Latent vector - mean: -0.2713773846626282 std: 27.793716430664062
Logits - mean: nan std: nan
Latent vector - mean: -0.8046644330024719 std: 36.452796936035156
Logits - mean: nan std: nan
Latent vector - mean: 226866.234375 std: 20533604.0
Logits - mean: nan std: nan
Latent vector - mean: 1791.56103515625 std: 172149.109375
Logits - mean: nan std: nan
Latent vector - mean: 908361334784.0 std: 82215480328192.0
Logits - mean: nan std: nan
Latent vector - mean: 321.579345703125 std: 29084.701171875
Logits - mean: nan std: nan
Latent vector - mean: -894.8407592773438 std: 80962.0703125
Logits - mean: nan std: nan
Latent vector - mean: -0.4496385157108307 std: 29.83183479309082
Logits - mean: nan std: nan
Latent vector - mean: -0.1348446011543274 std: 31.136524200439453
Logits - mean: nan std: nan
Latent vector - mean: -0.3251227140426636 std: 29.56764030456543
Logits - mean: nan std: nan
Latent vector - mean: 426.67181396484375 std: 38625.3046875
Logits - mean: nan std: nan
Latent vector - mean: 4330362.5 std: 391939680.0
Logits - mean: nan std: nan
Latent vector - mean: -0.19755437970161438 std: 32.40554428100586
Logits - mean: nan std: nan
Latent vector - mean: 0.04375913739204407 std: 29.207565307617188
Logits - mean: nan std: nan
Latent vector - mean: -0.36599868535995483 std: 33.29954147338867
Logits - mean: nan std: nan
Latent vector - mean: -0.5578747987747192 std: 28.694364547729492
Logits - mean: nan std: nan
Latent vector - mean: -0.8597816228866577 std: 34.58565139770508
Logits - mean: nan std: nan
Latent vector - mean: -35386.96875 std: 3202833.25
Logits - mean: nan std: nan
Latent vector - mean: -0.6544182896614075 std: 30.0954647064209
Logits - mean: nan std: nan
Latent vector - mean: -0.5915004014968872 std: 28.448474884033203
Logits - mean: nan std: nan
Latent vector - mean: -0.040385156869888306 std: 32.78433609008789
Logits - mean: nan std: nan
Latent vector - mean: -40698248.0 std: 3683585024.0
Logits - mean: nan std: nan
Latent vector - mean: 106864.859375 std: 9672352.0
Logits - mean: nan std: nan
Latent vector - mean: -0.19069194793701172 std: 37.56652069091797
Logits - mean: nan std: nan
Latent vector - mean: -0.8130180835723877 std: 30.859630584716797
Logits - mean: nan std: nan
Latent vector - mean: -0.5451420545578003 std: 29.4855899810791
Logits - mean: nan std: nan
Latent vector - mean: -0.29080134630203247 std: 34.517601013183594
Logits - mean: nan std: nan
Latent vector - mean: -473299808.0 std: 41115164672.0
Logits - mean: nan std: nan
Latent vector - mean: -0.4888867735862732 std: 34.12819290161133
Logits - mean: nan std: nan
Latent vector - mean: 0.10141447186470032 std: 29.35230255126953
Logits - mean: nan std: nan
Latent vector - mean: -0.6833382248878479 std: 33.061153411865234
Logits - mean: nan std: nan
Latent vector - mean: -6.462044529189606e+33 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -66.14317321777344 std: 5911.39794921875
Logits - mean: nan std: nan
Latent vector - mean: -0.20275777578353882 std: 32.797523498535156
Logits - mean: nan std: nan
Latent vector - mean: -0.18666504323482513 std: 32.295806884765625
Logits - mean: nan std: nan
Latent vector - mean: 0.03960379213094711 std: 28.837657928466797
Logits - mean: nan std: nan
Latent vector - mean: -0.4868521988391876 std: 31.623750686645508
Logits - mean: nan std: nan
Latent vector - mean: -30.086965560913086 std: 2662.8134765625
Logits - mean: nan std: nan
Latent vector - mean: -0.03254294395446777 std: 27.34636688232422
Logits - mean: nan std: nan
Latent vector - mean: 0.0256643146276474 std: 31.686338424682617
Logits - mean: nan std: nan
Latent vector - mean: -0.6221572160720825 std: 32.738521575927734
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.12414947152137756 std: 29.060657501220703
Logits - mean: nan std: nan
Latent vector - mean: -0.3947720229625702 std: 32.97123336791992
Logits - mean: nan std: nan
Latent vector - mean: 0.19327831268310547 std: 31.141338348388672
Logits - mean: nan std: nan
Latent vector - mean: -0.03576985001564026 std: 33.0764274597168
Logits - mean: nan std: nan
Latent vector - mean: -0.41424649953842163 std: 32.25401306152344
Logits - mean: nan std: nan
Latent vector - mean: -0.20874983072280884 std: 29.667692184448242
Logits - mean: nan std: nan
Latent vector - mean: 7.499859809875488 std: 702.3517456054688
Logits - mean: nan std: nan
Latent vector - mean: -0.2355557531118393 std: 34.436519622802734
Logits - mean: nan std: nan
Latent vector - mean: -0.11556118726730347 std: 30.542863845825195
Logits - mean: nan std: nan
Latent vector - mean: -0.24029222130775452 std: 31.267980575561523
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5/10, Train Loss: nan, Train Accuracy: 41.00%, Val Loss: nan, Val Accuracy: 38.04%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 6/10 - Train:  25%|██▌       | 1/4 [00:00&lt;00:00,  6.49batch/s, accuracy=41, loss=nan]  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: 2.8236785588954636e+32 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -0.5338250994682312 std: 36.17919158935547
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.3753902316093445 std: 41.20439910888672
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 6/10 - Train: 100%|██████████| 4/4 [00:00&lt;00:00, 15.45batch/s, accuracy=41, loss=nan]
Validating:  25%|██▌       | 54/215 [00:00&lt;00:00, 251.44batch/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: -0.2973407208919525 std: 36.139671325683594
Logits - mean: nan std: nan
Latent vector - mean: -3216881.5 std: 295357600.0
Logits - mean: nan std: nan
Latent vector - mean: -0.6235254406929016 std: 35.157249450683594
Logits - mean: nan std: nan
Latent vector - mean: -0.3270997703075409 std: 32.955570220947266
Logits - mean: nan std: nan
Latent vector - mean: -0.24038155376911163 std: 30.43337631225586
Logits - mean: nan std: nan
Latent vector - mean: -0.5396913886070251 std: 32.542808532714844
Logits - mean: nan std: nan
Latent vector - mean: -58029522944.0 std: 5169437212672.0
Logits - mean: nan std: nan
Latent vector - mean: -0.4341796636581421 std: 33.7332878112793
Logits - mean: nan std: nan
Latent vector - mean: -13.98381519317627 std: 1224.97412109375
Logits - mean: nan std: nan
Latent vector - mean: -0.4820404052734375 std: 32.07377624511719
Logits - mean: nan std: nan
Latent vector - mean: -0.048216432332992554 std: 30.547033309936523
Logits - mean: nan std: nan
Latent vector - mean: nan std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.041502468287944794 std: 31.93858528137207
Logits - mean: nan std: nan
Latent vector - mean: -0.5915655493736267 std: 34.653038024902344
Logits - mean: nan std: nan
Latent vector - mean: -12962152.0 std: 1173199872.0
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.9197980165481567 std: 34.78160095214844
Logits - mean: nan std: nan
Latent vector - mean: -17647780.0 std: 1597294592.0
Logits - mean: nan std: nan
Latent vector - mean: -0.4165922999382019 std: 33.58905792236328
Logits - mean: nan std: nan
Latent vector - mean: 10716866560.0 std: 969980051456.0
Logits - mean: nan std: nan
Latent vector - mean: -68.12028503417969 std: 6145.892578125
Logits - mean: nan std: nan
Latent vector - mean: -0.2998616397380829 std: 30.84598159790039
Logits - mean: nan std: nan
Latent vector - mean: -0.6612797975540161 std: 32.11445236206055
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.42371317744255066 std: 31.9730167388916
Logits - mean: nan std: nan
Latent vector - mean: -0.20958298444747925 std: 36.41987991333008
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.17099027335643768 std: 31.772544860839844
Logits - mean: nan std: nan
Latent vector - mean: -0.7343704700469971 std: 31.383087158203125
Logits - mean: nan std: nan
Latent vector - mean: -0.4486481845378876 std: 34.56093215942383
Logits - mean: nan std: nan
Latent vector - mean: -9.087941230012371e+23 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 0.13726158440113068 std: 36.216922760009766
Logits - mean: nan std: nan
Latent vector - mean: -442.6485900878906 std: 39467.8671875
Logits - mean: nan std: nan
Latent vector - mean: 25099767808.0 std: 2300416884736.0
Logits - mean: nan std: nan
Latent vector - mean: -0.27244794368743896 std: 34.10770034790039
Logits - mean: nan std: nan
Latent vector - mean: -0.8437405228614807 std: 30.393888473510742
Logits - mean: nan std: nan
Latent vector - mean: 0.20653784275054932 std: 31.152925491333008
Logits - mean: nan std: nan
Latent vector - mean: 1.4050352327605354e+19 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -0.58336341381073 std: 35.21738815307617
Logits - mean: nan std: nan
Latent vector - mean: -0.43763232231140137 std: 30.327260971069336
Logits - mean: nan std: nan
Latent vector - mean: -0.26996833086013794 std: 33.005706787109375
Logits - mean: nan std: nan
Latent vector - mean: -0.15205833315849304 std: 33.19117736816406
Logits - mean: nan std: nan
Latent vector - mean: -34.82392501831055 std: 3186.67041015625
Logits - mean: nan std: nan
Latent vector - mean: -836.0634155273438 std: 75625.96875
Logits - mean: nan std: nan
Latent vector - mean: -0.2905334532260895 std: 32.49250793457031
Logits - mean: nan std: nan
Latent vector - mean: -7.806407273098467e+29 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 12830944.0 std: 1161566464.0
Logits - mean: nan std: nan
Latent vector - mean: -0.5028612613677979 std: 34.46843338012695
Logits - mean: nan std: nan
Latent vector - mean: -0.5617361068725586 std: 29.70555305480957
Logits - mean: nan std: nan
Latent vector - mean: -0.4641066789627075 std: 30.77651596069336
Logits - mean: nan std: nan
Latent vector - mean: 0.06328126788139343 std: 31.10995864868164
Logits - mean: nan std: nan
Latent vector - mean: -0.5606619119644165 std: 31.70391845703125
Logits - mean: nan std: nan
Latent vector - mean: -0.8253874778747559 std: 35.03645324707031
Logits - mean: nan std: nan
Latent vector - mean: -0.597804069519043 std: 35.42866134643555
Logits - mean: nan std: nan
Latent vector - mean: -20302829568.0 std: 1817562185728.0
Logits - mean: nan std: nan
Latent vector - mean: 6899.26416015625 std: 624446.6875
Logits - mean: nan std: nan
Latent vector - mean: -0.46527615189552307 std: 33.574398040771484
Logits - mean: nan std: nan
Latent vector - mean: 0.043315500020980835 std: 29.64192008972168
Logits - mean: nan std: nan
Latent vector - mean: -0.661651611328125 std: 35.59858703613281
Logits - mean: nan std: nan
Latent vector - mean: 0.005851581692695618 std: 31.914216995239258
Logits - mean: nan std: nan
Latent vector - mean: -0.2524624168872833 std: 29.22537612915039
Logits - mean: nan std: nan
Latent vector - mean: -0.5285457372665405 std: 28.009105682373047
Logits - mean: nan std: nan
Latent vector - mean: -1.3361384868621826 std: 91.45028686523438
Logits - mean: nan std: nan
Latent vector - mean: -0.9018179178237915 std: 31.3219051361084
Logits - mean: nan std: nan
Latent vector - mean: -0.5839670300483704 std: 32.26769256591797
Logits - mean: nan std: nan
Latent vector - mean: -0.5508453845977783 std: 32.439659118652344
Logits - mean: nan std: nan
Latent vector - mean: 0.1415722817182541 std: 30.44656753540039
Logits - mean: nan std: nan
Latent vector - mean: 0.07031421363353729 std: 31.675796508789062
Logits - mean: nan std: nan
Latent vector - mean: -16282.673828125 std: 1473703.5
Logits - mean: nan std: nan
Latent vector - mean: -0.2099224030971527 std: 33.46563720703125
Logits - mean: nan std: nan
Latent vector - mean: 15.352426528930664 std: 1436.565673828125
Logits - mean: nan std: nan
Latent vector - mean: 0.03950302302837372 std: 30.46967124938965
Logits - mean: nan std: nan
Latent vector - mean: 3.51868286784032e+29 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 746305.9375 std: 67547960.0
Logits - mean: nan std: nan
Latent vector - mean: -0.7813680768013 std: 35.37704849243164
Logits - mean: nan std: nan
Latent vector - mean: -0.313077837228775 std: 34.67763900756836
Logits - mean: nan std: nan
Latent vector - mean: -0.042081378400325775 std: 32.17942810058594
Logits - mean: nan std: nan
Latent vector - mean: -0.419830858707428 std: 31.179412841796875
Logits - mean: nan std: nan
Latent vector - mean: -0.2529107630252838 std: 33.60602569580078
Logits - mean: nan std: nan
Latent vector - mean: -8.578413009643555 std: 778.0228271484375
Logits - mean: nan std: nan
Latent vector - mean: -0.47244417667388916 std: 29.704118728637695
Logits - mean: nan std: nan
Latent vector - mean: -0.13128773868083954 std: 34.14124298095703
Logits - mean: nan std: nan
Latent vector - mean: -1814187343872.0 std: 164201498673152.0
Logits - mean: nan std: nan
Latent vector - mean: -0.5248973965644836 std: 32.256900787353516
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: 418031.1875 std: 37835944.0
Logits - mean: nan std: nan
Latent vector - mean: -0.16678087413311005 std: 30.629390716552734
Logits - mean: nan std: nan
Latent vector - mean: -0.45327475666999817 std: 33.426212310791016
Logits - mean: nan std: nan
Latent vector - mean: -0.38904181122779846 std: 32.74845886230469
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: 3985700.75 std: 360744448.0
Logits - mean: nan std: nan
Latent vector - mean: -2439.430908203125 std: 220685.203125
Logits - mean: nan std: nan
Latent vector - mean: -0.160068079829216 std: 32.13704299926758
Logits - mean: nan std: nan
Latent vector - mean: -136.62261962890625 std: 12334.90234375
Logits - mean: nan std: nan
Latent vector - mean: -0.5486438870429993 std: 31.55767059326172
Logits - mean: nan std: nan
Latent vector - mean: 6353606.0 std: 575062784.0
Logits - mean: nan std: nan
Latent vector - mean: -0.42288029193878174 std: 33.62570571899414
Logits - mean: nan std: nan
Latent vector - mean: -17.100391387939453 std: 1485.0042724609375
Logits - mean: nan std: nan
Latent vector - mean: -0.13163086771965027 std: 32.25082778930664
Logits - mean: nan std: nan
Latent vector - mean: 28466499584.0 std: 2576493576192.0
Logits - mean: nan std: nan
Latent vector - mean: -0.03397423028945923 std: 32.28513717651367
Logits - mean: nan std: nan
Latent vector - mean: -0.7051236033439636 std: 36.019439697265625
Logits - mean: nan std: nan
Latent vector - mean: -0.33521029353141785 std: 31.419696807861328
Logits - mean: nan std: nan
Latent vector - mean: 0.04148700833320618 std: 31.216054916381836
Logits - mean: nan std: nan
Latent vector - mean: -0.6538143754005432 std: 36.31340789794922
Logits - mean: nan std: nan
Latent vector - mean: -0.4811440110206604 std: 32.08319091796875
Logits - mean: nan std: nan
Latent vector - mean: -0.2778381407260895 std: 31.365690231323242
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.5341520309448242 std: 36.02973175048828
Logits - mean: nan std: nan
Latent vector - mean: -0.3816554546356201 std: 30.07295036315918
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Validating:  80%|████████  | 172/215 [00:00&lt;00:00, 461.90batch/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: 2.6850026705649664e+16 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 79502.2421875 std: 7196626.0
Logits - mean: nan std: nan
Latent vector - mean: 1763830459793408.0 std: 1.596437110540206e+17
Logits - mean: nan std: nan
Latent vector - mean: -85992694349824.0 std: 7783008484458496.0
Logits - mean: nan std: nan
Latent vector - mean: 12990411702272.0 std: 1175728506798080.0
Logits - mean: nan std: nan
Latent vector - mean: 759096.125 std: 68706424.0
Logits - mean: nan std: nan
Latent vector - mean: -0.7344459891319275 std: 32.31595230102539
Logits - mean: nan std: nan
Latent vector - mean: -0.19115135073661804 std: 31.684858322143555
Logits - mean: nan std: nan
Latent vector - mean: 277703.59375 std: 25134882.0
Logits - mean: nan std: nan
Latent vector - mean: -1.7526802211080765e+18 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 71534.3359375 std: 6457250.0
Logits - mean: nan std: nan
Latent vector - mean: -0.593220591545105 std: 31.742345809936523
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.07098130881786346 std: 30.566089630126953
Logits - mean: nan std: nan
Latent vector - mean: 0.08500310033559799 std: 31.881364822387695
Logits - mean: nan std: nan
Latent vector - mean: -1.0531820303024128e+16 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -0.32058465480804443 std: 31.11673355102539
Logits - mean: nan std: nan
Latent vector - mean: 0.00948670506477356 std: 31.300777435302734
Logits - mean: nan std: nan
Latent vector - mean: -0.49244818091392517 std: 33.53377151489258
Logits - mean: nan std: nan
Latent vector - mean: -0.2185436189174652 std: 28.963987350463867
Logits - mean: nan std: nan
Latent vector - mean: -0.08765645325183868 std: 30.33523941040039
Logits - mean: nan std: nan
Latent vector - mean: -0.40518826246261597 std: 35.3859748840332
Logits - mean: nan std: nan
Latent vector - mean: -0.4957810938358307 std: 32.795074462890625
Logits - mean: nan std: nan
Latent vector - mean: -0.7010451555252075 std: 31.095195770263672
Logits - mean: nan std: nan
Latent vector - mean: -241311.34375 std: 21841012.0
Logits - mean: nan std: nan
Latent vector - mean: -0.10488536953926086 std: 31.546297073364258
Logits - mean: nan std: nan
Latent vector - mean: 1.6271693706512451 std: 140.8625030517578
Logits - mean: nan std: nan
Latent vector - mean: -0.5163876414299011 std: 36.317684173583984
Logits - mean: nan std: nan
Latent vector - mean: -0.849692702293396 std: 36.561466217041016
Logits - mean: nan std: nan
Latent vector - mean: -0.2430211752653122 std: 35.68451690673828
Logits - mean: nan std: nan
Latent vector - mean: -0.3318999409675598 std: 31.37946128845215
Logits - mean: nan std: nan
Latent vector - mean: 0.15308883786201477 std: 30.612281799316406
Logits - mean: nan std: nan
Latent vector - mean: -286210272.0 std: 24236042240.0
Logits - mean: nan std: nan
Latent vector - mean: -516704640.0 std: 46766768128.0
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: 8.38797378540039 std: 775.9818115234375
Logits - mean: nan std: nan
Latent vector - mean: -0.8561010360717773 std: 58.81718826293945
Logits - mean: nan std: nan
Latent vector - mean: 43.071537017822266 std: 3936.85888671875
Logits - mean: nan std: nan
Latent vector - mean: -0.3626489043235779 std: 32.49183654785156
Logits - mean: nan std: nan
Latent vector - mean: -0.676856517791748 std: 32.277042388916016
Logits - mean: nan std: nan
Latent vector - mean: -1.5839004516601562 std: 71.63851165771484
Logits - mean: nan std: nan
Latent vector - mean: 1.7536752223968506 std: 174.63536071777344
Logits - mean: nan std: nan
Latent vector - mean: -0.003411427140235901 std: 31.841907501220703
Logits - mean: nan std: nan
Latent vector - mean: -0.33378320932388306 std: 30.95740509033203
Logits - mean: nan std: nan
Latent vector - mean: -0.35056886076927185 std: 33.32107925415039
Logits - mean: nan std: nan
Latent vector - mean: -0.2753615081310272 std: 30.67885398864746
Logits - mean: nan std: nan
Latent vector - mean: -147517.640625 std: 13241768.0
Logits - mean: nan std: nan
Latent vector - mean: -0.2979593873023987 std: 34.548301696777344
Logits - mean: nan std: nan
Latent vector - mean: -0.8309913277626038 std: 33.12632751464844
Logits - mean: nan std: nan
Latent vector - mean: -0.1931508481502533 std: 32.2919921875
Logits - mean: nan std: nan
Latent vector - mean: -108566723690496.0 std: 7681553303863296.0
Logits - mean: nan std: nan
Latent vector - mean: -0.5234087705612183 std: 28.76554298400879
Logits - mean: nan std: nan
Latent vector - mean: 341833628516352.0 std: 3.093924574081843e+16
Logits - mean: nan std: nan
Latent vector - mean: -0.2712215781211853 std: 27.793502807617188
Logits - mean: nan std: nan
Latent vector - mean: -0.8055583238601685 std: 36.457584381103516
Logits - mean: nan std: nan
Latent vector - mean: 486434.15625 std: 44027008.0
Logits - mean: nan std: nan
Latent vector - mean: 750.7276000976562 std: 45977.01953125
Logits - mean: nan std: nan
Latent vector - mean: -682862903296.0 std: 61805699268608.0
Logits - mean: nan std: nan
Latent vector - mean: -3100.6494140625 std: 280649.40625
Logits - mean: nan std: nan
Latent vector - mean: 5223.865234375 std: 472840.0625
Logits - mean: nan std: nan
Latent vector - mean: -0.44966843724250793 std: 29.832035064697266
Logits - mean: nan std: nan
Latent vector - mean: -0.13437148928642273 std: 31.136795043945312
Logits - mean: nan std: nan
Latent vector - mean: -0.32533299922943115 std: 29.567384719848633
Logits - mean: nan std: nan
Latent vector - mean: 27.118249893188477 std: 2461.91064453125
Logits - mean: nan std: nan
Latent vector - mean: -1348258.375 std: 122030376.0
Logits - mean: nan std: nan
Latent vector - mean: -0.1976528763771057 std: 32.40567398071289
Logits - mean: nan std: nan
Latent vector - mean: 0.04235370457172394 std: 29.207984924316406
Logits - mean: nan std: nan
Latent vector - mean: -0.36551761627197266 std: 33.29947280883789
Logits - mean: nan std: nan
Latent vector - mean: -0.5578719973564148 std: 28.69446563720703
Logits - mean: nan std: nan
Latent vector - mean: -0.7061487436294556 std: 33.06533432006836
Logits - mean: nan std: nan
Latent vector - mean: 31768.044921875 std: 2875344.75
Logits - mean: nan std: nan
Latent vector - mean: -0.6536439657211304 std: 30.09578514099121
Logits - mean: nan std: nan
Latent vector - mean: -0.5942482948303223 std: 28.446029663085938
Logits - mean: nan std: nan
Latent vector - mean: -0.04018598794937134 std: 32.78430938720703
Logits - mean: nan std: nan
Latent vector - mean: -25656522.0 std: 2322163200.0
Logits - mean: nan std: nan
Latent vector - mean: -32333.9296875 std: 2926483.75
Logits - mean: nan std: nan
Latent vector - mean: 0.015740931034088135 std: 33.381996154785156
Logits - mean: nan std: nan
Latent vector - mean: -0.8131942749023438 std: 30.859275817871094
Logits - mean: nan std: nan
Latent vector - mean: -0.5452514886856079 std: 29.485198974609375
Logits - mean: nan std: nan
Latent vector - mean: -0.29055917263031006 std: 34.517513275146484
Logits - mean: nan std: nan
Latent vector - mean: -314179808.0 std: 28481038336.0
Logits - mean: nan std: nan
Latent vector - mean: -0.48909589648246765 std: 34.12813949584961
Logits - mean: nan std: nan
Latent vector - mean: 0.10150021314620972 std: 29.352420806884766
Logits - mean: nan std: nan
Latent vector - mean: -0.6832857131958008 std: 33.06108474731445
Logits - mean: nan std: nan
Latent vector - mean: -1.3691441047010727e+34 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -71.7790756225586 std: 6421.49853515625
Logits - mean: nan std: nan
Latent vector - mean: -0.20294126868247986 std: 32.79781723022461
Logits - mean: nan std: nan
Latent vector - mean: -0.18660950660705566 std: 32.29585266113281
Logits - mean: nan std: nan
Latent vector - mean: 0.03945353627204895 std: 28.8377628326416
Logits - mean: nan std: nan
Latent vector - mean: -0.48697009682655334 std: 31.623620986938477
Logits - mean: nan std: nan
Latent vector - mean: -107.07825469970703 std: 9631.1328125
Logits - mean: nan std: nan
Latent vector - mean: -0.03229115903377533 std: 27.34616470336914
Logits - mean: nan std: nan
Latent vector - mean: 0.025352507829666138 std: 31.686080932617188
Logits - mean: nan std: nan
Latent vector - mean: -0.6219937205314636 std: 32.73844909667969
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.12471061944961548 std: 29.060434341430664
Logits - mean: nan std: nan
Latent vector - mean: -0.3951389789581299 std: 32.97187423706055
Logits - mean: nan std: nan
Latent vector - mean: 0.19343405961990356 std: 31.14158821105957
Logits - mean: nan std: nan
Latent vector - mean: -0.03591006249189377 std: 33.07645797729492
Logits - mean: nan std: nan
Latent vector - mean: -0.4150392413139343 std: 32.2539176940918
Logits - mean: nan std: nan
Latent vector - mean: -0.20878513157367706 std: 29.667556762695312
Logits - mean: nan std: nan
Latent vector - mean: -24.0794734954834 std: 2157.03515625
Logits - mean: nan std: nan
Latent vector - mean: -0.2354739010334015 std: 34.43635559082031
Logits - mean: nan std: nan
Latent vector - mean: -0.1155155748128891 std: 30.54291343688965
Logits - mean: nan std: nan
Latent vector - mean: -0.24083343148231506 std: 31.267812728881836
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 6/10, Train Loss: nan, Train Accuracy: 41.00%, Val Loss: nan, Val Accuracy: 38.04%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 7/10 - Train:  25%|██▌       | 1/4 [00:00&lt;00:00,  6.52batch/s, accuracy=41, loss=nan]  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -1.5442478656768799 std: 66.88745880126953
Logits - mean: nan std: nan
Latent vector - mean: -0.3149781823158264 std: 34.85064697265625
Logits - mean: nan std: nan
Latent vector - mean: -1.0383474826812744 std: 40.1633415222168
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 7/10 - Train: 100%|██████████| 4/4 [00:00&lt;00:00, 14.53batch/s, accuracy=41, loss=nan]
Validating:  22%|██▏       | 48/215 [00:00&lt;00:00, 231.73batch/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: -0.2972280979156494 std: 36.139705657958984
Logits - mean: nan std: nan
Latent vector - mean: 283553.84375 std: 27754406.0
Logits - mean: nan std: nan
Latent vector - mean: -0.6260731220245361 std: 35.17470932006836
Logits - mean: nan std: nan
Latent vector - mean: -0.32713592052459717 std: 32.9555549621582
Logits - mean: nan std: nan
Latent vector - mean: -0.24037818610668182 std: 30.4334774017334
Logits - mean: nan std: nan
Latent vector - mean: -0.53965163230896 std: 32.542728424072266
Logits - mean: nan std: nan
Latent vector - mean: -51879817216.0 std: 4758361866240.0
Logits - mean: nan std: nan
Latent vector - mean: -0.43381738662719727 std: 33.73429870605469
Logits - mean: nan std: nan
Latent vector - mean: -35.66545486450195 std: 3187.092041015625
Logits - mean: nan std: nan
Latent vector - mean: -0.48200368881225586 std: 32.07377243041992
Logits - mean: nan std: nan
Latent vector - mean: -0.04847295582294464 std: 30.547208786010742
Logits - mean: nan std: nan
Latent vector - mean: nan std: nan
Logits - mean: nan std: nan
Latent vector - mean: 0.01823613792657852 std: 31.749013900756836
Logits - mean: nan std: nan
Latent vector - mean: -0.5917639136314392 std: 34.6528205871582
Logits - mean: nan std: nan
Latent vector - mean: -23950990.0 std: 2167795968.0
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.9206659197807312 std: 34.781288146972656
Logits - mean: nan std: nan
Latent vector - mean: 18130134.0 std: 1640952576.0
Logits - mean: nan std: nan
Latent vector - mean: -0.41661810874938965 std: 33.589054107666016
Logits - mean: nan std: nan
Latent vector - mean: 16593146880.0 std: 1501840277504.0
Logits - mean: nan std: nan
Latent vector - mean: -51.8338508605957 std: 4730.8916015625
Logits - mean: nan std: nan
Latent vector - mean: -0.2999385595321655 std: 30.845874786376953
Logits - mean: nan std: nan
Latent vector - mean: -0.6610323786735535 std: 32.11452865600586
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.42364102602005005 std: 31.972902297973633
Logits - mean: nan std: nan
Latent vector - mean: -0.21034230291843414 std: 36.420745849609375
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.08195081353187561 std: 32.04154968261719
Logits - mean: nan std: nan
Latent vector - mean: -0.7343162298202515 std: 31.382923126220703
Logits - mean: nan std: nan
Latent vector - mean: -0.4483110010623932 std: 34.560665130615234
Logits - mean: nan std: nan
Latent vector - mean: 5.4594425314196995e+23 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 0.25148001313209534 std: 36.32688903808594
Logits - mean: nan std: nan
Latent vector - mean: -155.3909912109375 std: 14405.0625
Logits - mean: nan std: nan
Latent vector - mean: -74980876288.0 std: 6836453376000.0
Logits - mean: nan std: nan
Latent vector - mean: -0.272609680891037 std: 34.107826232910156
Logits - mean: nan std: nan
Latent vector - mean: -0.8440134525299072 std: 30.39372444152832
Logits - mean: nan std: nan
Latent vector - mean: 0.2063790261745453 std: 31.152875900268555
Logits - mean: nan std: nan
Latent vector - mean: -5.702592318448599e+17 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -0.5836301445960999 std: 35.21702575683594
Logits - mean: nan std: nan
Latent vector - mean: -0.4365867078304291 std: 30.326704025268555
Logits - mean: nan std: nan
Latent vector - mean: -0.33425068855285645 std: 33.16261291503906
Logits - mean: nan std: nan
Latent vector - mean: -0.15148594975471497 std: 33.190895080566406
Logits - mean: nan std: nan
Latent vector - mean: 26.866960525512695 std: 2397.362060546875
Logits - mean: nan std: nan
Latent vector - mean: 222.24337768554688 std: 20161.1171875
Logits - mean: nan std: nan
Latent vector - mean: -0.2903883159160614 std: 32.49257278442383
Logits - mean: nan std: nan
Latent vector - mean: -9.843241195075804e+28 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 12080743.0 std: 1093340800.0
Logits - mean: nan std: nan
Latent vector - mean: -0.5026527047157288 std: 34.468414306640625
Logits - mean: nan std: nan
Latent vector - mean: -0.5616300106048584 std: 29.705577850341797
Logits - mean: nan std: nan
Latent vector - mean: -0.46389657258987427 std: 30.77654457092285
Logits - mean: nan std: nan
Latent vector - mean: 0.06308597326278687 std: 31.109952926635742
Logits - mean: nan std: nan
Latent vector - mean: -0.5608617663383484 std: 31.70392417907715
Logits - mean: nan std: nan
Latent vector - mean: -0.4813251495361328 std: 44.327667236328125
Logits - mean: nan std: nan
Latent vector - mean: -0.5971755385398865 std: 35.428932189941406
Logits - mean: nan std: nan
Latent vector - mean: 15739169792.0 std: 1359060795392.0
Logits - mean: nan std: nan
Latent vector - mean: 3578.797119140625 std: 323912.28125
Logits - mean: nan std: nan
Latent vector - mean: -0.46531134843826294 std: 33.57426071166992
Logits - mean: nan std: nan
Latent vector - mean: 0.04311126470565796 std: 29.641984939575195
Logits - mean: nan std: nan
Latent vector - mean: -0.6613924503326416 std: 35.59861755371094
Logits - mean: nan std: nan
Latent vector - mean: 0.00601842999458313 std: 31.914030075073242
Logits - mean: nan std: nan
Latent vector - mean: -0.2527441382408142 std: 29.224929809570312
Logits - mean: nan std: nan
Latent vector - mean: -0.528613805770874 std: 28.009292602539062
Logits - mean: nan std: nan
Latent vector - mean: -0.0643281415104866 std: 44.94824981689453
Logits - mean: nan std: nan
Latent vector - mean: -0.9015956521034241 std: 31.321985244750977
Logits - mean: nan std: nan
Latent vector - mean: -0.5839567184448242 std: 32.26780319213867
Logits - mean: nan std: nan
Latent vector - mean: -0.5504752397537231 std: 32.43958282470703
Logits - mean: nan std: nan
Latent vector - mean: 0.1414615362882614 std: 30.4466495513916
Logits - mean: nan std: nan
Latent vector - mean: 0.07070431113243103 std: 31.675622940063477
Logits - mean: nan std: nan
Latent vector - mean: 13861.888671875 std: 1254671.0
Logits - mean: nan std: nan
Latent vector - mean: -0.2099992036819458 std: 33.465782165527344
Logits - mean: nan std: nan
Latent vector - mean: 9.033393859863281 std: 1002.1663208007812
Logits - mean: nan std: nan
Latent vector - mean: 0.03610517084598541 std: 30.467233657836914
Logits - mean: nan std: nan
Latent vector - mean: 1.12776486805679e+29 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -1177716.25 std: 106594648.0
Logits - mean: nan std: nan
Latent vector - mean: -0.7616405487060547 std: 35.35248565673828
Logits - mean: nan std: nan
Latent vector - mean: -0.3132615387439728 std: 34.67747116088867
Logits - mean: nan std: nan
Latent vector - mean: -0.04225637763738632 std: 32.17945098876953
Logits - mean: nan std: nan
Latent vector - mean: -0.4199995696544647 std: 31.179296493530273
Logits - mean: nan std: nan
Latent vector - mean: -0.25313040614128113 std: 33.60593032836914
Logits - mean: nan std: nan
Latent vector - mean: -1.9992502927780151 std: 185.03787231445312
Logits - mean: nan std: nan
Latent vector - mean: -0.47244808077812195 std: 29.70392417907715
Logits - mean: nan std: nan
Latent vector - mean: -0.1312488615512848 std: 34.14109802246094
Logits - mean: nan std: nan
Latent vector - mean: 42281373532160.0 std: 3826873037488128.0
Logits - mean: nan std: nan
Latent vector - mean: -0.5249398350715637 std: 32.25688552856445
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: 1045047.25 std: 94586968.0
Logits - mean: nan std: nan
Latent vector - mean: -0.1668008267879486 std: 30.629531860351562
Logits - mean: nan std: nan
Latent vector - mean: -0.45340484380722046 std: 33.42607498168945
Logits - mean: nan std: nan
Latent vector - mean: -0.39125576615333557 std: 32.75983810424805
Logits - mean: nan std: nan
Latent vector - mean: nan std: nan
Logits - mean: nan std: nan
Latent vector - mean: 3899219.0 std: 352917024.0
Logits - mean: nan std: nan
Latent vector - mean: 4995.8359375 std: 451994.5
Logits - mean: nan std: nan
Latent vector - mean: -0.1599390208721161 std: 32.136959075927734
Logits - mean: nan std: nan
Latent vector - mean: 453.2861328125 std: 41057.625
Logits - mean: nan std: nan
Latent vector - mean: -0.5481449365615845 std: 31.557310104370117
Logits - mean: nan std: nan
Latent vector - mean: -20962226.0 std: 1897284224.0
Logits - mean: nan std: nan
Latent vector - mean: -0.4224308431148529 std: 33.62555694580078
Logits - mean: nan std: nan
Latent vector - mean: 287.57183837890625 std: 26091.154296875
Logits - mean: nan std: nan
Latent vector - mean: -0.13200828433036804 std: 32.25094985961914
Logits - mean: nan std: nan
Latent vector - mean: -76908273664.0 std: 6960941891584.0
Logits - mean: nan std: nan
Latent vector - mean: -0.033259570598602295 std: 32.285194396972656
Logits - mean: nan std: nan
Latent vector - mean: -0.7049487829208374 std: 36.019371032714844
Logits - mean: nan std: nan
Latent vector - mean: -0.334932416677475 std: 31.420238494873047
Logits - mean: nan std: nan
Latent vector - mean: 0.041197001934051514 std: 31.21611976623535
Logits - mean: nan std: nan
Latent vector - mean: -0.6537868976593018 std: 36.313148498535156
Logits - mean: nan std: nan
Latent vector - mean: -0.48104384541511536 std: 32.08357238769531
Logits - mean: nan std: nan
Latent vector - mean: -0.27805426716804504 std: 31.36553382873535
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.5370932817459106 std: 36.02743911743164
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Validating:  80%|████████  | 173/215 [00:00&lt;00:00, 475.05batch/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Logits - mean: nan std: nan
Latent vector - mean: -0.38167518377304077 std: 30.072965621948242
Logits - mean: nan std: nan
Latent vector - mean: -9428599970988032.0 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -103216.640625 std: 9339837.0
Logits - mean: nan std: nan
Latent vector - mean: -5316705119109120.0 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 964438865739776.0 std: 8.72912417414185e+16
Logits - mean: nan std: nan
Latent vector - mean: -25432346853376.0 std: 2301868931809280.0
Logits - mean: nan std: nan
Latent vector - mean: 12599336.0 std: 1140370048.0
Logits - mean: nan std: nan
Latent vector - mean: -0.7364506125450134 std: 32.32572937011719
Logits - mean: nan std: nan
Latent vector - mean: -0.19135797023773193 std: 31.684646606445312
Logits - mean: nan std: nan
Latent vector - mean: 1122175.25 std: 101567736.0
Logits - mean: nan std: nan
Latent vector - mean: -9.214734823262781e+17 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -91205.125 std: 8266478.5
Logits - mean: nan std: nan
Latent vector - mean: -0.5915718078613281 std: 31.741565704345703
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.07130750268697739 std: 30.56593132019043
Logits - mean: nan std: nan
Latent vector - mean: 0.08506327867507935 std: 31.881420135498047
Logits - mean: nan std: nan
Latent vector - mean: -8030210159017984.0 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -0.3204159140586853 std: 31.1170654296875
Logits - mean: nan std: nan
Latent vector - mean: 0.009407579898834229 std: 31.300743103027344
Logits - mean: nan std: nan
Latent vector - mean: -0.49141907691955566 std: 33.53297805786133
Logits - mean: nan std: nan
Latent vector - mean: -0.2183292806148529 std: 28.96422576904297
Logits - mean: nan std: nan
Latent vector - mean: -0.08799196034669876 std: 30.3351993560791
Logits - mean: nan std: nan
Latent vector - mean: -0.40560072660446167 std: 35.38575744628906
Logits - mean: nan std: nan
Latent vector - mean: -0.49596068263053894 std: 32.795040130615234
Logits - mean: nan std: nan
Latent vector - mean: -0.7012912034988403 std: 31.095151901245117
Logits - mean: nan std: nan
Latent vector - mean: -1142969.125 std: 103449752.0
Logits - mean: nan std: nan
Latent vector - mean: -0.10475316643714905 std: 31.546491622924805
Logits - mean: nan std: nan
Latent vector - mean: 10.565200805664062 std: 946.4293212890625
Logits - mean: nan std: nan
Latent vector - mean: -0.5165132284164429 std: 36.317657470703125
Logits - mean: nan std: nan
Latent vector - mean: -0.8496687412261963 std: 36.56145477294922
Logits - mean: nan std: nan
Latent vector - mean: -0.4157346189022064 std: 36.01722717285156
Logits - mean: nan std: nan
Latent vector - mean: -0.33172306418418884 std: 31.379600524902344
Logits - mean: nan std: nan
Latent vector - mean: 0.15285024046897888 std: 30.612337112426758
Logits - mean: nan std: nan
Latent vector - mean: 127071936.0 std: 11345563648.0
Logits - mean: nan std: nan
Latent vector - mean: 173930832.0 std: 15742423040.0
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: 9.003875732421875 std: 831.6881713867188
Logits - mean: nan std: nan
Latent vector - mean: 1.3371573686599731 std: 156.10760498046875
Logits - mean: nan std: nan
Latent vector - mean: 263.7325134277344 std: 23908.685546875
Logits - mean: nan std: nan
Latent vector - mean: -0.3624762296676636 std: 32.49186706542969
Logits - mean: nan std: nan
Latent vector - mean: -0.6769732236862183 std: 32.276641845703125
Logits - mean: nan std: nan
Latent vector - mean: -144.80831909179688 std: 13026.447265625
Logits - mean: nan std: nan
Latent vector - mean: -2.789903163909912 std: 242.19107055664062
Logits - mean: nan std: nan
Latent vector - mean: -0.055668920278549194 std: 31.124868392944336
Logits - mean: nan std: nan
Latent vector - mean: -0.3340887427330017 std: 30.957275390625
Logits - mean: nan std: nan
Latent vector - mean: -0.35496222972869873 std: 33.407814025878906
Logits - mean: nan std: nan
Latent vector - mean: -0.27577534317970276 std: 30.678850173950195
Logits - mean: nan std: nan
Latent vector - mean: 64601.56640625 std: 4368454.0
Logits - mean: nan std: nan
Latent vector - mean: -0.29770150780677795 std: 34.54839324951172
Logits - mean: nan std: nan
Latent vector - mean: -0.8316192626953125 std: 33.1260871887207
Logits - mean: nan std: nan
Latent vector - mean: -0.19301626086235046 std: 32.29182434082031
Logits - mean: nan std: nan
Latent vector - mean: 92416556138496.0 std: 5128937738862592.0
Logits - mean: nan std: nan
Latent vector - mean: -0.5237281322479248 std: 28.765382766723633
Logits - mean: nan std: nan
Latent vector - mean: -358817774698496.0 std: 3.2476476813082624e+16
Logits - mean: nan std: nan
Latent vector - mean: -0.27138689160346985 std: 27.793292999267578
Logits - mean: nan std: nan
Latent vector - mean: -0.8054251670837402 std: 36.458213806152344
Logits - mean: nan std: nan
Latent vector - mean: 604578.6875 std: 54720228.0
Logits - mean: nan std: nan
Latent vector - mean: 1331.828369140625 std: 145083.421875
Logits - mean: nan std: nan
Latent vector - mean: 173489881088.0 std: 15702511583232.0
Logits - mean: nan std: nan
Latent vector - mean: -11852.21484375 std: 1072790.0
Logits - mean: nan std: nan
Latent vector - mean: 2294.770263671875 std: 207728.546875
Logits - mean: nan std: nan
Latent vector - mean: -0.4495052397251129 std: 29.831960678100586
Logits - mean: nan std: nan
Latent vector - mean: -0.13435007631778717 std: 31.136600494384766
Logits - mean: nan std: nan
Latent vector - mean: -0.3263431191444397 std: 29.568744659423828
Logits - mean: nan std: nan
Latent vector - mean: 485.7889709472656 std: 43975.953125
Logits - mean: nan std: nan
Latent vector - mean: -386678.21875 std: 34998056.0
Logits - mean: nan std: nan
Latent vector - mean: -0.19751715660095215 std: 32.40549087524414
Logits - mean: nan std: nan
Latent vector - mean: 0.042767301201820374 std: 29.20751953125
Logits - mean: nan std: nan
Latent vector - mean: -0.36612212657928467 std: 33.29954147338867
Logits - mean: nan std: nan
Latent vector - mean: -0.5579343438148499 std: 28.69440269470215
Logits - mean: nan std: nan
Latent vector - mean: -0.5260336399078369 std: 38.24994659423828
Logits - mean: nan std: nan
Latent vector - mean: 172587.34375 std: 15620851.0
Logits - mean: nan std: nan
Latent vector - mean: -0.6539096236228943 std: 30.095996856689453
Logits - mean: nan std: nan
Latent vector - mean: -0.593998908996582 std: 28.445863723754883
Logits - mean: nan std: nan
Latent vector - mean: -0.040540337562561035 std: 32.78388595581055
Logits - mean: nan std: nan
Latent vector - mean: 16961060.0 std: 1535139968.0
Logits - mean: nan std: nan
Latent vector - mean: -109724.6953125 std: 9931096.0
Logits - mean: nan std: nan
Latent vector - mean: -0.07453438639640808 std: 34.03425979614258
Logits - mean: nan std: nan
Latent vector - mean: -0.81292325258255 std: 30.859676361083984
Logits - mean: nan std: nan
Latent vector - mean: -0.5452530384063721 std: 29.48501205444336
Logits - mean: nan std: nan
Latent vector - mean: -0.29057347774505615 std: 34.517513275146484
Logits - mean: nan std: nan
Latent vector - mean: -90677120.0 std: 7150329856.0
Logits - mean: nan std: nan
Latent vector - mean: -0.48919737339019775 std: 34.12812423706055
Logits - mean: nan std: nan
Latent vector - mean: 0.10175326466560364 std: 29.35256576538086
Logits - mean: nan std: nan
Latent vector - mean: -0.6829254627227783 std: 33.06116485595703
Logits - mean: nan std: nan
Latent vector - mean: 3.678035480316534e+34 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 23.34687614440918 std: 2188.68701171875
Logits - mean: nan std: nan
Latent vector - mean: -0.20284461975097656 std: 32.79774475097656
Logits - mean: nan std: nan
Latent vector - mean: -0.18654875457286835 std: 32.29593276977539
Logits - mean: nan std: nan
Latent vector - mean: 0.03961576521396637 std: 28.837860107421875
Logits - mean: nan std: nan
Latent vector - mean: -0.48687687516212463 std: 31.623863220214844
Logits - mean: nan std: nan
Latent vector - mean: -12.2387056350708 std: 1047.7269287109375
Logits - mean: nan std: nan
Latent vector - mean: -0.03230394423007965 std: 27.346195220947266
Logits - mean: nan std: nan
Latent vector - mean: 0.025714397430419922 std: 31.68633270263672
Logits - mean: nan std: nan
Latent vector - mean: -0.6219622492790222 std: 32.73845291137695
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.12400223314762115 std: 29.060956954956055
Logits - mean: nan std: nan
Latent vector - mean: -0.39486390352249146 std: 32.971431732177734
Logits - mean: nan std: nan
Latent vector - mean: 0.1932036429643631 std: 31.141481399536133
Logits - mean: nan std: nan
Latent vector - mean: -0.03588859736919403 std: 33.076568603515625
Logits - mean: nan std: nan
Latent vector - mean: -0.41553208231925964 std: 32.2537841796875
Logits - mean: nan std: nan
Latent vector - mean: -0.20854568481445312 std: 29.667707443237305
Logits - mean: nan std: nan
Latent vector - mean: 3.4995129108428955 std: 341.22906494140625
Logits - mean: nan std: nan
Latent vector - mean: -0.23541463911533356 std: 34.43649673461914
Logits - mean: nan std: nan
Latent vector - mean: -0.11533612012863159 std: 30.54293441772461
Logits - mean: nan std: nan
Latent vector - mean: -0.2406395524740219 std: 31.267805099487305
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 7/10, Train Loss: nan, Train Accuracy: 41.00%, Val Loss: nan, Val Accuracy: 38.04%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/10 - Train:  25%|██▌       | 1/4 [00:00&lt;00:00,  6.72batch/s, accuracy=41, loss=nan]  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: -0.8474489450454712 std: 37.77874755859375
Logits - mean: nan std: nan
Latent vector - mean: 1.6671677827835083 std: 196.5267333984375
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: 1.2228214740753174 std: 41.187461853027344
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 8/10 - Train: 100%|██████████| 4/4 [00:00&lt;00:00, 16.80batch/s, accuracy=41, loss=nan]
Validating:  11%|█         | 23/215 [00:00&lt;00:01, 110.25batch/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: -0.29710260033607483 std: 36.1396598815918
Logits - mean: nan std: nan
Latent vector - mean: -6634481.5 std: 600734656.0
Logits - mean: nan std: nan
Latent vector - mean: -0.6276421546936035 std: 35.183738708496094
Logits - mean: nan std: nan
Latent vector - mean: -0.32711100578308105 std: 32.95558547973633
Logits - mean: nan std: nan
Latent vector - mean: -0.2402074784040451 std: 30.433456420898438
Logits - mean: nan std: nan
Latent vector - mean: -0.5399078130722046 std: 32.54273986816406
Logits - mean: nan std: nan
Latent vector - mean: 7205618176.0 std: 784936271872.0
Logits - mean: nan std: nan
Latent vector - mean: -0.43377524614334106 std: 33.73443603515625
Logits - mean: nan std: nan
Latent vector - mean: 1.92904794216156 std: 218.1639862060547
Logits - mean: nan std: nan
Latent vector - mean: -0.4821590781211853 std: 32.07368087768555
Logits - mean: nan std: nan
Latent vector - mean: -0.04869192838668823 std: 30.547090530395508
Logits - mean: nan std: nan
Latent vector - mean: nan std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.07183272391557693 std: 32.37635040283203
Logits - mean: nan std: nan
Latent vector - mean: -0.5917596817016602 std: 34.653446197509766
Logits - mean: nan std: nan
Latent vector - mean: 16913164.0 std: 1530804736.0
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.9212989807128906 std: 34.78128433227539
Logits - mean: nan std: nan
Latent vector - mean: 18473896.0 std: 1672066304.0
Logits - mean: nan std: nan
Latent vector - mean: -0.416495144367218 std: 33.5890998840332
Logits - mean: nan std: nan
Latent vector - mean: -20796323840.0 std: 1882268237824.0
Logits - mean: nan std: nan
Latent vector - mean: 50.52351379394531 std: 4578.70166015625
Logits - mean: nan std: nan
Latent vector - mean: -0.299858957529068 std: 30.845897674560547
Logits - mean: nan std: nan
Latent vector - mean: -0.6609416007995605 std: 32.11458206176758
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.42361852526664734 std: 31.97291374206543
Logits - mean: nan std: nan
Latent vector - mean: -0.209720641374588 std: 36.41981887817383
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.12338963150978088 std: 31.662134170532227
Logits - mean: nan std: nan
Latent vector - mean: -0.7344250679016113 std: 31.383045196533203
Logits - mean: nan std: nan
Latent vector - mean: -0.44855690002441406 std: 34.56045150756836
Logits - mean: nan std: nan
Latent vector - mean: -1.4670560093544415e+24 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 0.0828799307346344 std: 37.18745803833008
Logits - mean: nan std: nan
Latent vector - mean: 218.73069763183594 std: 19806.984375
Logits - mean: nan std: nan
Latent vector - mean: 37374595072.0 std: 3418344390656.0
Logits - mean: nan std: nan
Latent vector - mean: -0.2723631262779236 std: 34.10753631591797
Logits - mean: nan std: nan
Latent vector - mean: -0.8444782495498657 std: 30.393329620361328
Logits - mean: nan std: nan
Latent vector - mean: 0.20641665160655975 std: 31.152925491333008
Logits - mean: nan std: nan
Latent vector - mean: 6.554217950230872e+18 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -0.5837089419364929 std: 35.217193603515625
Logits - mean: nan std: nan
Latent vector - mean: -0.43656444549560547 std: 30.32663917541504
Logits - mean: nan std: nan
Latent vector - mean: -0.22820129990577698 std: 33.46183395385742
Logits - mean: nan std: nan
Latent vector - mean: -0.15195533633232117 std: 33.19115447998047
Logits - mean: nan std: nan
Latent vector - mean: -82.66948699951172 std: 7517.08984375
Logits - mean: nan std: nan
Latent vector - mean: 478.4791259765625 std: 43350.171875
Logits - mean: nan std: nan
Latent vector - mean: -0.29050368070602417 std: 32.49234390258789
Logits - mean: nan std: nan
Latent vector - mean: -1.7152108058009476e+30 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 19088262.0 std: 1727553024.0
Logits - mean: nan std: nan
Latent vector - mean: -0.5027158260345459 std: 34.46855545043945
Logits - mean: nan std: nan
Latent vector - mean: -0.5617546439170837 std: 29.70549774169922
Logits - mean: nan std: nan
Latent vector - mean: -0.46399542689323425 std: 30.776506423950195
Logits - mean: nan std: nan
Latent vector - mean: 0.06324639171361923 std: 31.11017608642578
Logits - mean: nan std: nan
Latent vector - mean: -0.559881865978241 std: 31.70296287536621
Logits - mean: nan std: nan
Latent vector - mean: -0.8600393533706665 std: 35.51015853881836
Logits - mean: nan std: nan
Latent vector - mean: -0.5975204110145569 std: 35.42887496948242
Logits - mean: nan std: nan
Latent vector - mean: 5327363072.0 std: 534075965440.0
Logits - mean: nan std: nan
Latent vector - mean: -121.9981918334961 std: 11045.466796875
Logits - mean: nan std: nan
Latent vector - mean: -0.4653071463108063 std: 33.57447814941406
Logits - mean: nan std: nan
Latent vector - mean: 0.04354734718799591 std: 29.641862869262695
Logits - mean: nan std: nan
Latent vector - mean: -0.6615664958953857 std: 35.598533630371094
Logits - mean: nan std: nan
Latent vector - mean: 0.005721777677536011 std: 31.914432525634766
Logits - mean: nan std: nan
Latent vector - mean: -0.2526850998401642 std: 29.225027084350586
Logits - mean: nan std: nan
Latent vector - mean: -0.5287024974822998 std: 28.009061813354492
Logits - mean: nan std: nan
Latent vector - mean: -0.9385240077972412 std: 59.42691421508789
Logits - mean: nan std: nan
Latent vector - mean: -0.9022701978683472 std: 31.32196807861328
Logits - mean: nan std: nan
Latent vector - mean: -0.5838750004768372 std: 32.26768493652344
Logits - mean: nan std: nan
Latent vector - mean: -0.5507866740226746 std: 32.44003677368164
Logits - mean: nan std: nan
Latent vector - mean: 0.1415378898382187 std: 30.44654083251953
Logits - mean: nan std: nan
Latent vector - mean: 0.07023924589157104 std: 31.675758361816406
Logits - mean: nan std: nan
Latent vector - mean: 2751.578369140625 std: 249080.46875
Logits - mean: nan std: nan
Latent vector - mean: -0.2099812924861908 std: 33.46571731567383
Logits - mean: nan std: nan
Latent vector - mean: 16.971019744873047 std: 1524.1929931640625
Logits - mean: nan std: nan
Latent vector - mean: 0.036831095814704895 std: 30.4672794342041
Logits - mean: nan std: nan
Latent vector - mean: 1.5625312383541177e+29 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 728020.5 std: 65892956.0
Logits - mean: nan std: nan
Latent vector - mean: -0.7792977094650269 std: 35.370086669921875
Logits - mean: nan std: nan
Latent vector - mean: -0.3131895661354065 std: 34.677452087402344
Logits - mean: nan std: nan
Latent vector - mean: -0.04195891320705414 std: 32.17936325073242
Logits - mean: nan std: nan
Latent vector - mean: -0.41954249143600464 std: 31.17933464050293
Logits - mean: nan std: nan
Latent vector - mean: -0.2527353763580322 std: 33.60602569580078
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Validating:  64%|██████▍   | 138/215 [00:00&lt;00:00, 399.65batch/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: -1.845092535018921 std: 171.3857879638672
Logits - mean: nan std: nan
Latent vector - mean: -0.47244560718536377 std: 29.703960418701172
Logits - mean: nan std: nan
Latent vector - mean: -0.1311180293560028 std: 34.1414794921875
Logits - mean: nan std: nan
Latent vector - mean: 20681074933760.0 std: 1871837210345472.0
Logits - mean: nan std: nan
Latent vector - mean: -0.5252484679222107 std: 32.256839752197266
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -599910.0 std: 54297564.0
Logits - mean: nan std: nan
Latent vector - mean: -0.16677667200565338 std: 30.629528045654297
Logits - mean: nan std: nan
Latent vector - mean: -0.4529787600040436 std: 33.42623519897461
Logits - mean: nan std: nan
Latent vector - mean: -0.390695184469223 std: 32.756996154785156
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: 7253816.5 std: 656540544.0
Logits - mean: nan std: nan
Latent vector - mean: -945.8967895507812 std: 85684.4921875
Logits - mean: nan std: nan
Latent vector - mean: -0.1600431352853775 std: 32.1368522644043
Logits - mean: nan std: nan
Latent vector - mean: 2054.3359375 std: 185968.0625
Logits - mean: nan std: nan
Latent vector - mean: -0.5480911135673523 std: 31.55720329284668
Logits - mean: nan std: nan
Latent vector - mean: 33097554.0 std: 2995648768.0
Logits - mean: nan std: nan
Latent vector - mean: -0.42207181453704834 std: 33.62553405761719
Logits - mean: nan std: nan
Latent vector - mean: 122.57630920410156 std: 11157.47265625
Logits - mean: nan std: nan
Latent vector - mean: -0.13199461996555328 std: 32.25096130371094
Logits - mean: nan std: nan
Latent vector - mean: -194544140288.0 std: 17608126496768.0
Logits - mean: nan std: nan
Latent vector - mean: -0.033434510231018066 std: 32.285179138183594
Logits - mean: nan std: nan
Latent vector - mean: -0.7052847146987915 std: 36.01945114135742
Logits - mean: nan std: nan
Latent vector - mean: -0.3351098895072937 std: 31.41973304748535
Logits - mean: nan std: nan
Latent vector - mean: 0.041207849979400635 std: 31.21613883972168
Logits - mean: nan std: nan
Latent vector - mean: -0.6529685854911804 std: 36.31392288208008
Logits - mean: nan std: nan
Latent vector - mean: -0.4811689257621765 std: 32.0841178894043
Logits - mean: nan std: nan
Latent vector - mean: -0.2779589295387268 std: 31.365938186645508
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.5225454568862915 std: 36.05711364746094
Logits - mean: nan std: nan
Latent vector - mean: -0.3811799883842468 std: 30.073368072509766
Logits - mean: nan std: nan
Latent vector - mean: 2.170659291529216e+16 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -34826.83203125 std: 3152357.25
Logits - mean: nan std: nan
Latent vector - mean: -1.0829818018922496e+16 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -99198879924224.0 std: 8978361233702912.0
Logits - mean: nan std: nan
Latent vector - mean: 35407022522368.0 std: 3204697364103168.0
Logits - mean: nan std: nan
Latent vector - mean: -8683844.0 std: 785968256.0
Logits - mean: nan std: nan
Latent vector - mean: -0.7299529314041138 std: 32.299400329589844
Logits - mean: nan std: nan
Latent vector - mean: -0.19119152426719666 std: 31.68467903137207
Logits - mean: nan std: nan
Latent vector - mean: -90449.1640625 std: 8186500.0
Logits - mean: nan std: nan
Latent vector - mean: 6.876700312611062e+17 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 755.6297607421875 std: 60520.65625
Logits - mean: nan std: nan
Latent vector - mean: -0.593686044216156 std: 31.743406295776367
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.07165570557117462 std: 30.565820693969727
Logits - mean: nan std: nan
Latent vector - mean: 0.08508892357349396 std: 31.881710052490234
Logits - mean: nan std: nan
Latent vector - mean: 1.0187203938353152e+16 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -0.3202957510948181 std: 31.117366790771484
Logits - mean: nan std: nan
Latent vector - mean: 0.009742587804794312 std: 31.300983428955078
Logits - mean: nan std: nan
Latent vector - mean: -0.4910305142402649 std: 33.53168869018555
Logits - mean: nan std: nan
Latent vector - mean: -0.21841935813426971 std: 28.964296340942383
Logits - mean: nan std: nan
Latent vector - mean: -0.08745183050632477 std: 30.33527183532715
Logits - mean: nan std: nan
Latent vector - mean: -0.40564364194869995 std: 35.38560485839844
Logits - mean: nan std: nan
Latent vector - mean: -0.49602118134498596 std: 32.79485321044922
Logits - mean: nan std: nan
Latent vector - mean: -0.7014068365097046 std: 31.095195770263672
Logits - mean: nan std: nan
Latent vector - mean: 2018816.0 std: 182722384.0
Logits - mean: nan std: nan
Latent vector - mean: -0.10485133528709412 std: 31.546415328979492
Logits - mean: nan std: nan
Latent vector - mean: -2.633918523788452 std: 251.08859252929688
Logits - mean: nan std: nan
Latent vector - mean: -0.5167577862739563 std: 36.31770706176758
Logits - mean: nan std: nan
Latent vector - mean: -0.8495792746543884 std: 36.56148147583008
Logits - mean: nan std: nan
Latent vector - mean: -0.2942536473274231 std: 35.06261444091797
Logits - mean: nan std: nan
Latent vector - mean: -0.3319409489631653 std: 31.379756927490234
Logits - mean: nan std: nan
Latent vector - mean: 0.15288782119750977 std: 30.612285614013672
Logits - mean: nan std: nan
Latent vector - mean: 569599936.0 std: 52299513856.0
Logits - mean: nan std: nan
Latent vector - mean: -738880256.0 std: 66875801600.0
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -4.119845867156982 std: 358.69610595703125
Logits - mean: nan std: nan
Latent vector - mean: -4.258279323577881 std: 356.3258361816406
Logits - mean: nan std: nan
Latent vector - mean: 127.43026733398438 std: 11572.0703125
Logits - mean: nan std: nan
Latent vector - mean: -0.3623480796813965 std: 32.4919548034668
Logits - mean: nan std: nan
Latent vector - mean: -0.6762888431549072 std: 32.27723693847656
Logits - mean: nan std: nan
Latent vector - mean: -185.67861938476562 std: 16725.697265625
Logits - mean: nan std: nan
Latent vector - mean: -0.6567779779434204 std: 57.558780670166016
Logits - mean: nan std: nan
Latent vector - mean: 0.0010014474391937256 std: 31.10040283203125
Logits - mean: nan std: nan
Latent vector - mean: -0.3340885043144226 std: 30.957229614257812
Logits - mean: nan std: nan
Latent vector - mean: -0.46705901622772217 std: 34.10265350341797
Logits - mean: nan std: nan
Latent vector - mean: -0.2752968370914459 std: 30.678882598876953
Logits - mean: nan std: nan
Latent vector - mean: 110826.15625 std: 11015478.0
Logits - mean: nan std: nan
Latent vector - mean: -0.2982460856437683 std: 34.54845428466797
Logits - mean: nan std: nan
Latent vector - mean: -0.8315672278404236 std: 33.12611770629883
Logits - mean: nan std: nan
Latent vector - mean: -0.19326895475387573 std: 32.29206085205078
Logits - mean: nan std: nan
Latent vector - mean: 48218377289728.0 std: 9750038544646144.0
Logits - mean: nan std: nan
Latent vector - mean: -0.5234916806221008 std: 28.76541519165039
Logits - mean: nan std: nan
Latent vector - mean: -126224944857088.0 std: 1.1424577573879808e+16
Logits - mean: nan std: nan
Latent vector - mean: -0.2712065577507019 std: 27.79355239868164
Logits - mean: nan std: nan
Latent vector - mean: -0.8060484528541565 std: 36.4605598449707
Logits - mean: nan std: nan
Latent vector - mean: 24772.3203125 std: 2242149.0
Logits - mean: nan std: nan
Latent vector - mean: 202.5667266845703 std: 13236.59375
Logits - mean: nan std: nan
Latent vector - mean: -94425964544.0 std: 8546462728192.0
Logits - mean: nan std: nan
Latent vector - mean: -7200.08203125 std: 651690.375
Logits - mean: nan std: nan
Latent vector - mean: 5586.3857421875 std: 505651.71875
Logits - mean: nan std: nan
Latent vector - mean: -0.44920632243156433 std: 29.831941604614258
Logits - mean: nan std: nan
Latent vector - mean: -0.1343860775232315 std: 31.137123107910156
Logits - mean: nan std: nan
Latent vector - mean: -0.3251326382160187 std: 29.5673770904541
Logits - mean: nan std: nan
Latent vector - mean: 419.9173278808594 std: 38013.8671875
Logits - mean: nan std: nan
Latent vector - mean: 1428580.25 std: 129300368.0
Logits - mean: nan std: nan
Latent vector - mean: -0.19726568460464478 std: 32.405452728271484
Logits - mean: nan std: nan
Latent vector - mean: 0.043753013014793396 std: 29.207677841186523
Logits - mean: nan std: nan
Latent vector - mean: -0.36577343940734863 std: 33.299705505371094
Logits - mean: nan std: nan
Latent vector - mean: -0.5577249526977539 std: 28.694536209106445
Logits - mean: nan std: nan
Latent vector - mean: -0.829070508480072 std: 33.868370056152344
Logits - mean: nan std: nan
Latent vector - mean: -65883.34375 std: 5963049.5
Logits - mean: nan std: nan
Latent vector - mean: -0.6538557410240173 std: 30.09571075439453
Logits - mean: nan std: nan
Latent vector - mean: -0.5938552021980286 std: 28.446319580078125
Logits - mean: nan std: nan
Latent vector - mean: -0.03989025950431824 std: 32.784732818603516
Logits - mean: nan std: nan
Latent vector - mean: 33207494.0 std: 3005599488.0
Logits - mean: nan std: nan
Latent vector - mean: 120314.703125 std: 10889694.0
Logits - mean: nan std: nan
Latent vector - mean: -0.14219099283218384 std: 35.75640869140625
Logits - mean: nan std: nan
Latent vector - mean: -0.8132205009460449 std: 30.859376907348633
Logits - mean: nan std: nan
Latent vector - mean: -0.5452946424484253 std: 29.484882354736328
Logits - mean: nan std: nan
Latent vector - mean: -0.2903884947299957 std: 34.517555236816406
Logits - mean: nan std: nan
Latent vector - mean: 207753472.0 std: 20463695872.0
Logits - mean: nan std: nan
Latent vector - mean: -0.489132821559906 std: 34.12809753417969
Logits - mean: nan std: nan
Latent vector - mean: 0.10129161179065704 std: 29.3525447845459
Logits - mean: nan std: nan
Latent vector - mean: -0.6832653284072876 std: 33.0611686706543
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: 2.357016789818696e+34 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 30.0035400390625 std: 2791.120361328125
Logits - mean: nan std: nan
Latent vector - mean: -0.20289674401283264 std: 32.797752380371094
Logits - mean: nan std: nan
Latent vector - mean: -0.1865767538547516 std: 32.29599380493164
Logits - mean: nan std: nan
Latent vector - mean: 0.03960795700550079 std: 28.83763313293457
Logits - mean: nan std: nan
Latent vector - mean: -0.48663386702537537 std: 31.623689651489258
Logits - mean: nan std: nan
Latent vector - mean: 6.99113130569458 std: 694.1980590820312
Logits - mean: nan std: nan
Latent vector - mean: -0.032348282635211945 std: 27.346181869506836
Logits - mean: nan std: nan
Latent vector - mean: 0.02564847469329834 std: 31.68625259399414
Logits - mean: nan std: nan
Latent vector - mean: -0.6221522688865662 std: 32.73838424682617
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.12423507869243622 std: 29.060718536376953
Logits - mean: nan std: nan
Latent vector - mean: -0.3950344920158386 std: 32.97196578979492
Logits - mean: nan std: nan
Latent vector - mean: 0.1933097243309021 std: 31.141368865966797
Logits - mean: nan std: nan
Latent vector - mean: -0.0363810658454895 std: 33.07658386230469
Logits - mean: nan std: nan
Latent vector - mean: -0.41504961252212524 std: 32.25395202636719
Logits - mean: nan std: nan
Latent vector - mean: -0.2087651640176773 std: 29.66779899597168
Logits - mean: nan std: nan
Latent vector - mean: -20.656953811645508 std: 1847.3287353515625
Logits - mean: nan std: nan
Latent vector - mean: -0.23539257049560547 std: 34.43656539916992
Logits - mean: nan std: nan
Latent vector - mean: -0.11528787016868591 std: 30.542842864990234
Logits - mean: nan std: nan
Latent vector - mean: -0.2408379167318344 std: 31.267864227294922
Logits - mean: nan std: nan
Epoch 8/10, Train Loss: nan, Train Accuracy: 41.00%, Val Loss: nan, Val Accuracy: 38.04%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 9/10 - Train: 100%|██████████| 4/4 [00:00&lt;00:00, 14.60batch/s, accuracy=41, loss=nan]  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -8.99009895324707 std: 753.2763671875
Logits - mean: nan std: nan
Latent vector - mean: 8.781019113967221e+26 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -1.195526361465454 std: 51.908504486083984
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Validating:  29%|██▉       | 63/215 [00:00&lt;00:00, 311.95batch/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: -0.29738175868988037 std: 36.13966369628906
Logits - mean: nan std: nan
Latent vector - mean: -3765222.25 std: 341705472.0
Logits - mean: nan std: nan
Latent vector - mean: -0.6266649961471558 std: 35.174835205078125
Logits - mean: nan std: nan
Latent vector - mean: -0.327243447303772 std: 32.95553970336914
Logits - mean: nan std: nan
Latent vector - mean: -0.24004893004894257 std: 30.43333625793457
Logits - mean: nan std: nan
Latent vector - mean: -0.5397520065307617 std: 32.54283142089844
Logits - mean: nan std: nan
Latent vector - mean: 10915479552.0 std: 1031431520256.0
Logits - mean: nan std: nan
Latent vector - mean: -0.4335497319698334 std: 33.734500885009766
Logits - mean: nan std: nan
Latent vector - mean: 10.172988891601562 std: 962.4459838867188
Logits - mean: nan std: nan
Latent vector - mean: -0.4822062849998474 std: 32.07360076904297
Logits - mean: nan std: nan
Latent vector - mean: -0.048356011509895325 std: 30.547035217285156
Logits - mean: nan std: nan
Latent vector - mean: nan std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.019550517201423645 std: 31.759418487548828
Logits - mean: nan std: nan
Latent vector - mean: -0.5918869376182556 std: 34.653160095214844
Logits - mean: nan std: nan
Latent vector - mean: -5173550.5 std: 468256256.0
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.9214161038398743 std: 34.78129577636719
Logits - mean: nan std: nan
Latent vector - mean: 14360344.0 std: 1299750144.0
Logits - mean: nan std: nan
Latent vector - mean: -0.41657936573028564 std: 33.58904266357422
Logits - mean: nan std: nan
Latent vector - mean: -24340910080.0 std: 2203087798272.0
Logits - mean: nan std: nan
Latent vector - mean: -29.0190486907959 std: 2503.9970703125
Logits - mean: nan std: nan
Latent vector - mean: -0.300317645072937 std: 30.845746994018555
Logits - mean: nan std: nan
Latent vector - mean: -0.6611706018447876 std: 32.1146125793457
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.42342159152030945 std: 31.973217010498047
Logits - mean: nan std: nan
Latent vector - mean: -0.20973700284957886 std: 36.42005157470703
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.051486194133758545 std: 32.59377670288086
Logits - mean: nan std: nan
Latent vector - mean: -0.7345907688140869 std: 31.38310432434082
Logits - mean: nan std: nan
Latent vector - mean: -0.44877564907073975 std: 34.56047821044922
Logits - mean: nan std: nan
Latent vector - mean: 3.3773224990230834e+23 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 0.37485408782958984 std: 39.62012481689453
Logits - mean: nan std: nan
Latent vector - mean: -269.494384765625 std: 24290.19921875
Logits - mean: nan std: nan
Latent vector - mean: 46388281344.0 std: 4079375089664.0
Logits - mean: nan std: nan
Latent vector - mean: -0.27259618043899536 std: 34.107601165771484
Logits - mean: nan std: nan
Latent vector - mean: -0.84446781873703 std: 30.393417358398438
Logits - mean: nan std: nan
Latent vector - mean: 0.20657116174697876 std: 31.15290069580078
Logits - mean: nan std: nan
Latent vector - mean: 1.3865030742255337e+19 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -0.5834608674049377 std: 35.217350006103516
Logits - mean: nan std: nan
Latent vector - mean: -0.4364975690841675 std: 30.326616287231445
Logits - mean: nan std: nan
Latent vector - mean: -0.4203004539012909 std: 34.89442443847656
Logits - mean: nan std: nan
Latent vector - mean: -0.15153266489505768 std: 33.1909294128418
Logits - mean: nan std: nan
Latent vector - mean: 39.16470718383789 std: 3510.32861328125
Logits - mean: nan std: nan
Latent vector - mean: -105.21614837646484 std: 9489.6767578125
Logits - mean: nan std: nan
Latent vector - mean: -0.29052066802978516 std: 32.49251174926758
Logits - mean: nan std: nan
Latent vector - mean: 1.5356677921637907e+30 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 16656285.0 std: 1507314560.0
Logits - mean: nan std: nan
Latent vector - mean: -0.5026870369911194 std: 34.46841812133789
Logits - mean: nan std: nan
Latent vector - mean: -0.5615670680999756 std: 29.70562744140625
Logits - mean: nan std: nan
Latent vector - mean: -0.4639078378677368 std: 30.77640151977539
Logits - mean: nan std: nan
Latent vector - mean: 0.06364233046770096 std: 31.1101016998291
Logits - mean: nan std: nan
Latent vector - mean: -0.5604941844940186 std: 31.703758239746094
Logits - mean: nan std: nan
Latent vector - mean: -0.5093495845794678 std: 42.80528259277344
Logits - mean: nan std: nan
Latent vector - mean: -0.5978175401687622 std: 35.42855453491211
Logits - mean: nan std: nan
Latent vector - mean: 38061928448.0 std: 3429524570112.0
Logits - mean: nan std: nan
Latent vector - mean: 10808.7197265625 std: 978290.125
Logits - mean: nan std: nan
Latent vector - mean: -0.46527066826820374 std: 33.57447052001953
Logits - mean: nan std: nan
Latent vector - mean: 0.04370350390672684 std: 29.642353057861328
Logits - mean: nan std: nan
Latent vector - mean: -0.6616450548171997 std: 35.59859085083008
Logits - mean: nan std: nan
Latent vector - mean: 0.005793020129203796 std: 31.914430618286133
Logits - mean: nan std: nan
Latent vector - mean: -0.25278207659721375 std: 29.224916458129883
Logits - mean: nan std: nan
Latent vector - mean: -0.5289919972419739 std: 28.0092830657959
Logits - mean: nan std: nan
Latent vector - mean: -2.1765613555908203 std: 164.5805206298828
Logits - mean: nan std: nan
Latent vector - mean: -0.9023075103759766 std: 31.321693420410156
Logits - mean: nan std: nan
Latent vector - mean: -0.5842273235321045 std: 32.26761245727539
Logits - mean: nan std: nan
Latent vector - mean: -0.5509228110313416 std: 32.43983459472656
Logits - mean: nan std: nan
Latent vector - mean: 0.14145930111408234 std: 30.446758270263672
Logits - mean: nan std: nan
Latent vector - mean: 0.07063086330890656 std: 31.675769805908203
Logits - mean: nan std: nan
Latent vector - mean: -6291.91064453125 std: 569442.5625
Logits - mean: nan std: nan
Latent vector - mean: -0.20962393283843994 std: 33.465728759765625
Logits - mean: nan std: nan
Latent vector - mean: 33.44317626953125 std: 2844.596923828125
Logits - mean: nan std: nan
Latent vector - mean: 0.038791388273239136 std: 30.468563079833984
Logits - mean: nan std: nan
Latent vector - mean: 2.3274566666981455e+29 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -360276.03125 std: 32608408.0
Logits - mean: nan std: nan
Latent vector - mean: -0.7602214217185974 std: 35.354183197021484
Logits - mean: nan std: nan
Latent vector - mean: -0.31334394216537476 std: 34.67756271362305
Logits - mean: nan std: nan
Latent vector - mean: -0.042066752910614014 std: 32.17943572998047
Logits - mean: nan std: nan
Latent vector - mean: -0.4200771749019623 std: 31.179407119750977
Logits - mean: nan std: nan
Latent vector - mean: -0.2530733644962311 std: 33.60595703125
Logits - mean: nan std: nan
Latent vector - mean: -12.302125930786133 std: 1114.837646484375
Logits - mean: nan std: nan
Latent vector - mean: -0.4725455641746521 std: 29.704038619995117
Logits - mean: nan std: nan
Latent vector - mean: -0.13132423162460327 std: 34.141082763671875
Logits - mean: nan std: nan
Latent vector - mean: 29891651174400.0 std: 2705483383177216.0
Logits - mean: nan std: nan
Latent vector - mean: -0.5251955986022949 std: 32.25678634643555
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -413851.46875 std: 37457480.0
Logits - mean: nan std: nan
Latent vector - mean: -0.16714516282081604 std: 30.62965965270996
Logits - mean: nan std: nan
Latent vector - mean: -0.4534425139427185 std: 33.426063537597656
Logits - mean: nan std: nan
Latent vector - mean: -0.3906151354312897 std: 32.7558708190918
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: 520969.4375 std: 47152808.0
Logits - mean: nan std: nan
Latent vector - mean: -2111.77734375 std: 191160.71875
Logits - mean: nan std: nan
Latent vector - mean: -0.16013699769973755 std: 32.136783599853516
Logits - mean: nan std: nan
Latent vector - mean: -805.1046752929688 std: 72838.9375
Logits - mean: nan std: nan
Latent vector - mean: -0.5476394891738892 std: 31.557157516479492
Logits - mean: nan std: nan
Latent vector - mean: -11403830.0 std: 1032156928.0
Logits - mean: nan std: nan
Latent vector - mean: -0.42170852422714233 std: 33.62563705444336
Logits - mean: nan std: nan
Latent vector - mean: -50.425559997558594 std: 4501.017578125
Logits - mean: nan std: nan
Latent vector - mean: -0.13199655711650848 std: 32.25096130371094
Logits - mean: nan std: nan
Latent vector - mean: -71728594944.0 std: 6492130902016.0
Logits - mean: nan std: nan
Latent vector - mean: -0.033687934279441833 std: 32.28515625
Logits - mean: nan std: nan
Latent vector - mean: -0.70570307970047 std: 36.019222259521484
Logits - mean: nan std: nan
Latent vector - mean: -0.33507269620895386 std: 31.419652938842773
Logits - mean: nan std: nan
Latent vector - mean: 0.041546761989593506 std: 31.21625518798828
Logits - mean: nan std: nan
Latent vector - mean: -0.6549704074859619 std: 36.310142517089844
Logits - mean: nan std: nan
Latent vector - mean: -0.48086851835250854 std: 32.0836067199707
Logits - mean: nan std: nan
Latent vector - mean: -0.2779145836830139 std: 31.365848541259766
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.5375649929046631 std: 36.027320861816406
Logits - mean: nan std: nan
Latent vector - mean: -0.38153183460235596 std: 30.072843551635742
Logits - mean: nan std: nan
Latent vector - mean: 4729453703856128.0 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -41277.21484375 std: 3738011.5
Logits - mean: nan std: nan
Latent vector - mean: 4330619014217728.0 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -402138425458688.0 std: 3.639723649348403e+16
Logits - mean: nan std: nan
Latent vector - mean: -7425971191808.0 std: 672112519938048.0
Logits - mean: nan std: nan
Latent vector - mean: -10148791.0 std: 918561792.0
Logits - mean: nan std: nan
Latent vector - mean: -0.7264043688774109 std: 32.289485931396484
Logits - mean: nan std: nan
Latent vector - mean: -0.19161096215248108 std: 31.684656143188477
Logits - mean: nan std: nan
Latent vector - mean: 157317.328125 std: 14238761.0
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Validating:  82%|████████▏ | 176/215 [00:00&lt;00:00, 469.94batch/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: 1.6914077366270034e+18 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 18145.974609375 std: 1630370.75
Logits - mean: nan std: nan
Latent vector - mean: -0.5941174030303955 std: 31.744783401489258
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.07142037898302078 std: 30.56606674194336
Logits - mean: nan std: nan
Latent vector - mean: 0.08522579073905945 std: 31.88141632080078
Logits - mean: nan std: nan
Latent vector - mean: -976532554121216.0 std: 8.838564235811226e+16
Logits - mean: nan std: nan
Latent vector - mean: -0.32063865661621094 std: 31.116853713989258
Logits - mean: nan std: nan
Latent vector - mean: 0.009354978799819946 std: 31.30084228515625
Logits - mean: nan std: nan
Latent vector - mean: -0.4930696487426758 std: 33.53536605834961
Logits - mean: nan std: nan
Latent vector - mean: -0.21889139711856842 std: 28.9638729095459
Logits - mean: nan std: nan
Latent vector - mean: -0.0877738669514656 std: 30.335247039794922
Logits - mean: nan std: nan
Latent vector - mean: -0.405262291431427 std: 35.38578414916992
Logits - mean: nan std: nan
Latent vector - mean: -0.4961649179458618 std: 32.79487228393555
Logits - mean: nan std: nan
Latent vector - mean: -0.7013171315193176 std: 31.095169067382812
Logits - mean: nan std: nan
Latent vector - mean: 199793.140625 std: 18083208.0
Logits - mean: nan std: nan
Latent vector - mean: -0.10480919480323792 std: 31.546356201171875
Logits - mean: nan std: nan
Latent vector - mean: -5.217591285705566 std: 483.84075927734375
Logits - mean: nan std: nan
Latent vector - mean: -0.5167704820632935 std: 36.31770706176758
Logits - mean: nan std: nan
Latent vector - mean: -0.8497467041015625 std: 36.56147766113281
Logits - mean: nan std: nan
Latent vector - mean: -0.3486461043357849 std: 35.068851470947266
Logits - mean: nan std: nan
Latent vector - mean: -0.33177894353866577 std: 31.37932014465332
Logits - mean: nan std: nan
Latent vector - mean: 0.15295162796974182 std: 30.612285614013672
Logits - mean: nan std: nan
Latent vector - mean: -695761600.0 std: 63696769024.0
Logits - mean: nan std: nan
Latent vector - mean: 222661184.0 std: 20152989696.0
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: 5.212623596191406 std: 489.1463928222656
Logits - mean: nan std: nan
Latent vector - mean: 3.0639662742614746 std: 310.2742004394531
Logits - mean: nan std: nan
Latent vector - mean: -257.62548828125 std: 23279.267578125
Logits - mean: nan std: nan
Latent vector - mean: -0.36262550950050354 std: 32.49180221557617
Logits - mean: nan std: nan
Latent vector - mean: -0.6771079301834106 std: 32.27698516845703
Logits - mean: nan std: nan
Latent vector - mean: -167.2879180908203 std: 15061.111328125
Logits - mean: nan std: nan
Latent vector - mean: -1.0606963634490967 std: 89.81189727783203
Logits - mean: nan std: nan
Latent vector - mean: 0.10921558737754822 std: 32.83095932006836
Logits - mean: nan std: nan
Latent vector - mean: -0.33365005254745483 std: 30.957260131835938
Logits - mean: nan std: nan
Latent vector - mean: -0.4134834408760071 std: 33.288639068603516
Logits - mean: nan std: nan
Latent vector - mean: -0.275417685508728 std: 30.679014205932617
Logits - mean: nan std: nan
Latent vector - mean: -136933.03125 std: 10758694.0
Logits - mean: nan std: nan
Latent vector - mean: -0.298062801361084 std: 34.548343658447266
Logits - mean: nan std: nan
Latent vector - mean: -0.8313308358192444 std: 33.12619400024414
Logits - mean: nan std: nan
Latent vector - mean: -0.1926257312297821 std: 32.291988372802734
Logits - mean: nan std: nan
Latent vector - mean: -74137426984960.0 std: 8227213866434560.0
Logits - mean: nan std: nan
Latent vector - mean: -0.5235719680786133 std: 28.765438079833984
Logits - mean: nan std: nan
Latent vector - mean: -513400190795776.0 std: 4.64676806721536e+16
Logits - mean: nan std: nan
Latent vector - mean: -0.27141672372817993 std: 27.793508529663086
Logits - mean: nan std: nan
Latent vector - mean: -0.8043888807296753 std: 36.45122146606445
Logits - mean: nan std: nan
Latent vector - mean: -40940.72265625 std: 3705516.75
Logits - mean: nan std: nan
Latent vector - mean: -2337.49462890625 std: 230612.9375
Logits - mean: nan std: nan
Latent vector - mean: -723455377408.0 std: 65479704051712.0
Logits - mean: nan std: nan
Latent vector - mean: -6290.61865234375 std: 569361.25
Logits - mean: nan std: nan
Latent vector - mean: -4520.2021484375 std: 409092.25
Logits - mean: nan std: nan
Latent vector - mean: -0.4498198330402374 std: 29.831958770751953
Logits - mean: nan std: nan
Latent vector - mean: -0.13485416769981384 std: 31.13656234741211
Logits - mean: nan std: nan
Latent vector - mean: -0.3238166272640228 std: 29.56675148010254
Logits - mean: nan std: nan
Latent vector - mean: 1082.2598876953125 std: 97962.2421875
Logits - mean: nan std: nan
Latent vector - mean: 2651630.25 std: 239998240.0
Logits - mean: nan std: nan
Latent vector - mean: -0.19755595922470093 std: 32.40535354614258
Logits - mean: nan std: nan
Latent vector - mean: 0.04344433546066284 std: 29.207626342773438
Logits - mean: nan std: nan
Latent vector - mean: -0.3657985031604767 std: 33.299530029296875
Logits - mean: nan std: nan
Latent vector - mean: -0.5578195452690125 std: 28.694442749023438
Logits - mean: nan std: nan
Latent vector - mean: -0.7985779047012329 std: 33.31829071044922
Logits - mean: nan std: nan
Latent vector - mean: 153222.53125 std: 13868147.0
Logits - mean: nan std: nan
Latent vector - mean: -0.6537947654724121 std: 30.095993041992188
Logits - mean: nan std: nan
Latent vector - mean: -0.5910618305206299 std: 28.449081420898438
Logits - mean: nan std: nan
Latent vector - mean: -0.04040864109992981 std: 32.78440856933594
Logits - mean: nan std: nan
Latent vector - mean: -34362732.0 std: 3110159616.0
Logits - mean: nan std: nan
Latent vector - mean: -298905.375 std: 27053772.0
Logits - mean: nan std: nan
Latent vector - mean: -0.11411815881729126 std: 34.9260139465332
Logits - mean: nan std: nan
Latent vector - mean: -0.8129053115844727 std: 30.859760284423828
Logits - mean: nan std: nan
Latent vector - mean: -0.544833242893219 std: 29.485305786132812
Logits - mean: nan std: nan
Latent vector - mean: -0.2902193069458008 std: 34.517581939697266
Logits - mean: nan std: nan
Latent vector - mean: -432415552.0 std: 43897327616.0
Logits - mean: nan std: nan
Latent vector - mean: -0.48902419209480286 std: 34.12815856933594
Logits - mean: nan std: nan
Latent vector - mean: 0.10115271806716919 std: 29.352474212646484
Logits - mean: nan std: nan
Latent vector - mean: -0.6834811568260193 std: 33.06111526489258
Logits - mean: nan std: nan
Latent vector - mean: -3.6706672612027075e+34 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -38.40653610229492 std: 3401.052001953125
Logits - mean: nan std: nan
Latent vector - mean: -0.20331768691539764 std: 32.79789352416992
Logits - mean: nan std: nan
Latent vector - mean: -0.18647775053977966 std: 32.29587936401367
Logits - mean: nan std: nan
Latent vector - mean: 0.03972988575696945 std: 28.837488174438477
Logits - mean: nan std: nan
Latent vector - mean: -0.4869564175605774 std: 31.623628616333008
Logits - mean: nan std: nan
Latent vector - mean: -17.350666046142578 std: 1510.259765625
Logits - mean: nan std: nan
Latent vector - mean: -0.03228859603404999 std: 27.346521377563477
Logits - mean: nan std: nan
Latent vector - mean: 0.025466598570346832 std: 31.686145782470703
Logits - mean: nan std: nan
Latent vector - mean: -0.6221908330917358 std: 32.73831558227539
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.12438325583934784 std: 29.060352325439453
Logits - mean: nan std: nan
Latent vector - mean: -0.39499950408935547 std: 32.97202682495117
Logits - mean: nan std: nan
Latent vector - mean: 0.193206325173378 std: 31.141395568847656
Logits - mean: nan std: nan
Latent vector - mean: -0.03606460988521576 std: 33.076454162597656
Logits - mean: nan std: nan
Latent vector - mean: -0.41539472341537476 std: 32.253753662109375
Logits - mean: nan std: nan
Latent vector - mean: -0.20845770835876465 std: 29.667619705200195
Logits - mean: nan std: nan
Latent vector - mean: 7.435624599456787 std: 696.5564575195312
Logits - mean: nan std: nan
Latent vector - mean: -0.2353014498949051 std: 34.43641662597656
Logits - mean: nan std: nan
Latent vector - mean: -0.11549916863441467 std: 30.542863845825195
Logits - mean: nan std: nan
Latent vector - mean: -0.24088208377361298 std: 31.267902374267578
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 9/10, Train Loss: nan, Train Accuracy: 41.00%, Val Loss: nan, Val Accuracy: 38.04%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 10/10 - Train:  25%|██▌       | 1/4 [00:00&lt;00:00,  6.44batch/s, accuracy=41, loss=nan]  
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: 11545.65234375 std: 1045072.125
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: 2.1165287101151293e+21 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -1.9746814966201782 std: 32.371002197265625
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 10/10 - Train: 100%|██████████| 4/4 [00:00&lt;00:00, 15.47batch/s, accuracy=41, loss=nan]
Validating:  29%|██▉       | 63/215 [00:00&lt;00:00, 302.74batch/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: -0.2970247268676758 std: 36.139671325683594
Logits - mean: nan std: nan
Latent vector - mean: -8724374.0 std: 791562944.0
Logits - mean: nan std: nan
Latent vector - mean: -0.6254413723945618 std: 35.16704177856445
Logits - mean: nan std: nan
Latent vector - mean: -0.32698312401771545 std: 32.955482482910156
Logits - mean: nan std: nan
Latent vector - mean: -0.24006417393684387 std: 30.43343734741211
Logits - mean: nan std: nan
Latent vector - mean: -0.5397599339485168 std: 32.542877197265625
Logits - mean: nan std: nan
Latent vector - mean: 21664774144.0 std: 1954461777920.0
Logits - mean: nan std: nan
Latent vector - mean: -0.43428516387939453 std: 33.7335090637207
Logits - mean: nan std: nan
Latent vector - mean: 36.65868377685547 std: 3359.266357421875
Logits - mean: nan std: nan
Latent vector - mean: -0.48214900493621826 std: 32.073753356933594
Logits - mean: nan std: nan
Latent vector - mean: -0.048468202352523804 std: 30.547239303588867
Logits - mean: nan std: nan
Latent vector - mean: nan std: nan
Logits - mean: nan std: nan
Latent vector - mean: 0.016368962824344635 std: 31.740625381469727
Logits - mean: nan std: nan
Latent vector - mean: -0.5917725563049316 std: 34.653236389160156
Logits - mean: nan std: nan
Latent vector - mean: -56660896.0 std: 5128358912.0
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.9211397767066956 std: 34.78147888183594
Logits - mean: nan std: nan
Latent vector - mean: 1709609.375 std: 154736208.0
Logits - mean: nan std: nan
Latent vector - mean: -0.4166637063026428 std: 33.58894348144531
Logits - mean: nan std: nan
Latent vector - mean: 51715555328.0 std: 4680757280768.0
Logits - mean: nan std: nan
Latent vector - mean: -2.3487865924835205 std: 146.4933319091797
Logits - mean: nan std: nan
Latent vector - mean: -0.29995453357696533 std: 30.84592628479004
Logits - mean: nan std: nan
Latent vector - mean: -0.6609715819358826 std: 32.11466598510742
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.42381495237350464 std: 31.972929000854492
Logits - mean: nan std: nan
Latent vector - mean: -0.20988920331001282 std: 36.42033004760742
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.18644428253173828 std: 31.93068504333496
Logits - mean: nan std: nan
Latent vector - mean: -0.7343171238899231 std: 31.382959365844727
Logits - mean: nan std: nan
Latent vector - mean: -0.44863665103912354 std: 34.56075668334961
Logits - mean: nan std: nan
Latent vector - mean: 1.8431812299073012e+24 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 0.008155472576618195 std: 39.47919464111328
Logits - mean: nan std: nan
Latent vector - mean: 335.6777038574219 std: 30535.017578125
Logits - mean: nan std: nan
Latent vector - mean: 96854122496.0 std: 8762823278592.0
Logits - mean: nan std: nan
Latent vector - mean: -0.2723187804222107 std: 34.10759353637695
Logits - mean: nan std: nan
Latent vector - mean: -0.8447186946868896 std: 30.39304542541504
Logits - mean: nan std: nan
Latent vector - mean: 0.20629455149173737 std: 31.15290641784668
Logits - mean: nan std: nan
Latent vector - mean: 2.79392254297532e+18 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -0.5833747386932373 std: 35.21706008911133
Logits - mean: nan std: nan
Latent vector - mean: -0.4388040602207184 std: 30.328550338745117
Logits - mean: nan std: nan
Latent vector - mean: -0.3905752897262573 std: 34.10511779785156
Logits - mean: nan std: nan
Latent vector - mean: -0.1515151560306549 std: 33.19094467163086
Logits - mean: nan std: nan
Latent vector - mean: -31.580381393432617 std: 2893.111083984375
Logits - mean: nan std: nan
Latent vector - mean: -63.46179962158203 std: 5690.99951171875
Logits - mean: nan std: nan
Latent vector - mean: -0.2906695604324341 std: 32.4925422668457
Logits - mean: nan std: nan
Latent vector - mean: -3.333835465496013e+29 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 30927270.0 std: 2799542272.0
Logits - mean: nan std: nan
Latent vector - mean: -0.5027843117713928 std: 34.46868133544922
Logits - mean: nan std: nan
Latent vector - mean: -0.5615432262420654 std: 29.70554542541504
Logits - mean: nan std: nan
Latent vector - mean: -0.4640730023384094 std: 30.776559829711914
Logits - mean: nan std: nan
Latent vector - mean: 0.063100665807724 std: 31.109853744506836
Logits - mean: nan std: nan
Latent vector - mean: -0.5600817203521729 std: 31.70370864868164
Logits - mean: nan std: nan
Latent vector - mean: -1.0011979341506958 std: 40.00117874145508
Logits - mean: nan std: nan
Latent vector - mean: -0.5981975793838501 std: 35.42860412597656
Logits - mean: nan std: nan
Latent vector - mean: -23285862400.0 std: 2134682632192.0
Logits - mean: nan std: nan
Latent vector - mean: 7935.35498046875 std: 718222.9375
Logits - mean: nan std: nan
Latent vector - mean: -0.4651113748550415 std: 33.57461166381836
Logits - mean: nan std: nan
Latent vector - mean: 0.04316708445549011 std: 29.64182472229004
Logits - mean: nan std: nan
Latent vector - mean: -0.661433219909668 std: 35.59858703613281
Logits - mean: nan std: nan
Latent vector - mean: 0.005720257759094238 std: 31.914196014404297
Logits - mean: nan std: nan
Latent vector - mean: -0.25275713205337524 std: 29.224750518798828
Logits - mean: nan std: nan
Latent vector - mean: -0.5285991430282593 std: 28.009178161621094
Logits - mean: nan std: nan
Latent vector - mean: -1.2259939908981323 std: 82.2431869506836
Logits - mean: nan std: nan
Latent vector - mean: -0.9017393589019775 std: 31.321834564208984
Logits - mean: nan std: nan
Latent vector - mean: -0.5840858817100525 std: 32.26771926879883
Logits - mean: nan std: nan
Latent vector - mean: -0.5511758327484131 std: 32.43950653076172
Logits - mean: nan std: nan
Latent vector - mean: 0.14133237302303314 std: 30.446807861328125
Logits - mean: nan std: nan
Latent vector - mean: 0.0706208199262619 std: 31.675735473632812
Logits - mean: nan std: nan
Latent vector - mean: -9508.4482421875 std: 860570.375
Logits - mean: nan std: nan
Latent vector - mean: -0.2101510465145111 std: 33.46559143066406
Logits - mean: nan std: nan
Latent vector - mean: 47.479610443115234 std: 4237.33447265625
Logits - mean: nan std: nan
Latent vector - mean: 0.03831915557384491 std: 30.468366622924805
Logits - mean: nan std: nan
Latent vector - mean: 1.1740223367030913e+29 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -241408.5 std: 21849748.0
Logits - mean: nan std: nan
Latent vector - mean: -0.7657259702682495 std: 35.35036849975586
Logits - mean: nan std: nan
Latent vector - mean: -0.3131779730319977 std: 34.677589416503906
Logits - mean: nan std: nan
Latent vector - mean: -0.04217659682035446 std: 32.179473876953125
Logits - mean: nan std: nan
Latent vector - mean: -0.41972702741622925 std: 31.17931365966797
Logits - mean: nan std: nan
Latent vector - mean: -0.25315067172050476 std: 33.605953216552734
Logits - mean: nan std: nan
Latent vector - mean: -4.710682392120361 std: 428.5555114746094
Logits - mean: nan std: nan
Latent vector - mean: -0.4722844362258911 std: 29.70411491394043
Logits - mean: nan std: nan
Latent vector - mean: -0.13134798407554626 std: 34.14138412475586
Logits - mean: nan std: nan
Latent vector - mean: 18245450989568.0 std: 1651389692379136.0
Logits - mean: nan std: nan
Latent vector - mean: -0.5248998999595642 std: 32.2568359375
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -68435.2890625 std: 6193976.0
Logits - mean: nan std: nan
Latent vector - mean: -0.1668921262025833 std: 30.629587173461914
Logits - mean: nan std: nan
Latent vector - mean: -0.45334291458129883 std: 33.426055908203125
Logits - mean: nan std: nan
Latent vector - mean: -0.3895869553089142 std: 32.751102447509766
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -5106314.5 std: 462170816.0
Logits - mean: nan std: nan
Latent vector - mean: 1062.7930908203125 std: 96307.6171875
Logits - mean: nan std: nan
Latent vector - mean: -0.15995453298091888 std: 32.13691329956055
Logits - mean: nan std: nan
Latent vector - mean: 109.60649871826172 std: 9951.310546875
Logits - mean: nan std: nan
Latent vector - mean: -0.5478688478469849 std: 31.557043075561523
Logits - mean: nan std: nan
Latent vector - mean: 25300208.0 std: 2289913088.0
Logits - mean: nan std: nan
Latent vector - mean: -0.42197564244270325 std: 33.62559127807617
Logits - mean: nan std: nan
Latent vector - mean: -89.29499816894531 std: 8019.0185546875
Logits - mean: nan std: nan
Latent vector - mean: -0.13201044499874115 std: 32.250953674316406
Logits - mean: nan std: nan
Latent vector - mean: -13281033.0 std: 1202061312.0
Logits - mean: nan std: nan
Latent vector - mean: -0.033688247203826904 std: 32.28532791137695
Logits - mean: nan std: nan
Latent vector - mean: -0.705062747001648 std: 36.01944351196289
Logits - mean: nan std: nan
Latent vector - mean: -0.33523809909820557 std: 31.419647216796875
Logits - mean: nan std: nan
Latent vector - mean: 0.04152044653892517 std: 31.215919494628906
Logits - mean: nan std: nan
Latent vector - mean: -0.6553258299827576 std: 36.309410095214844
Logits - mean: nan std: nan
Latent vector - mean: -0.481229305267334 std: 32.083499908447266
Logits - mean: nan std: nan
Latent vector - mean: -0.27796006202697754 std: 31.36587142944336
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.5409961342811584 std: 36.027313232421875
Logits - mean: nan std: nan
Latent vector - mean: -0.38126686215400696 std: 30.072795867919922
Logits - mean: nan std: nan
Latent vector - mean: 5.86042875880407e+16 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -16628.5859375 std: 1506970.625
Logits - mean: nan std: nan
Latent vector - mean: 5357108413333504.0 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 487410303500288.0 std: 4.411538721367654e+16
Logits - mean: nan std: nan
Latent vector - mean: 9162799972352.0 std: 829324026445824.0
Logits - mean: nan std: nan
Latent vector - mean: 3297157.5 std: 298425312.0
Logits - mean: nan std: nan
Latent vector - mean: -0.7255824208259583 std: 32.286861419677734
Logits - mean: nan std: nan
Latent vector - mean: -0.19121021032333374 std: 31.684532165527344
Logits - mean: nan std: nan
Latent vector - mean: 389032.40625 std: 35211216.0
Logits - mean: nan std: nan
Latent vector - mean: -4.840190922958307e+18 std: inf
Logits - mean: nan std: nan
Latent vector - mean: 37890.5078125 std: 3434292.25
Logits - mean: nan std: nan
Latent vector - mean: -0.5927122831344604 std: 31.74234962463379
Logits - mean: nan std: nan
Latent vector - mean: inf std: nan
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Validating:  86%|████████▌ | 184/215 [00:00&lt;00:00, 488.57batch/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Latent vector - mean: -0.07145092636346817 std: 30.5660343170166
Logits - mean: nan std: nan
Latent vector - mean: 0.08523440361022949 std: 31.88157081604004
Logits - mean: nan std: nan
Latent vector - mean: -1667896728092672.0 std: 1.509607818301276e+17
Logits - mean: nan std: nan
Latent vector - mean: -0.3202199935913086 std: 31.11732292175293
Logits - mean: nan std: nan
Latent vector - mean: 0.009202778339385986 std: 31.300668716430664
Logits - mean: nan std: nan
Latent vector - mean: -0.49166548252105713 std: 33.532798767089844
Logits - mean: nan std: nan
Latent vector - mean: -0.21882840991020203 std: 28.963703155517578
Logits - mean: nan std: nan
Latent vector - mean: -0.08746307343244553 std: 30.33513832092285
Logits - mean: nan std: nan
Latent vector - mean: -0.40600502490997314 std: 35.385406494140625
Logits - mean: nan std: nan
Latent vector - mean: -0.49593809247016907 std: 32.79514694213867
Logits - mean: nan std: nan
Latent vector - mean: -0.7010594606399536 std: 31.095279693603516
Logits - mean: nan std: nan
Latent vector - mean: -70245.75 std: 6357922.0
Logits - mean: nan std: nan
Latent vector - mean: -0.10485222935676575 std: 31.546432495117188
Logits - mean: nan std: nan
Latent vector - mean: -6.986365795135498 std: 643.6321411132812
Logits - mean: nan std: nan
Latent vector - mean: -0.5166141390800476 std: 36.31766891479492
Logits - mean: nan std: nan
Latent vector - mean: -0.8497869372367859 std: 36.56148147583008
Logits - mean: nan std: nan
Latent vector - mean: -0.4205797016620636 std: 36.125675201416016
Logits - mean: nan std: nan
Latent vector - mean: -0.331848680973053 std: 31.379661560058594
Logits - mean: nan std: nan
Latent vector - mean: 0.1528232991695404 std: 30.612323760986328
Logits - mean: nan std: nan
Latent vector - mean: -1352243200.0 std: 121949831168.0
Logits - mean: nan std: nan
Latent vector - mean: 527836064.0 std: 47774265344.0
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -14.15211296081543 std: 1265.3917236328125
Logits - mean: nan std: nan
Latent vector - mean: 3.5545127391815186 std: 354.40948486328125
Logits - mean: nan std: nan
Latent vector - mean: -58.155391693115234 std: 5225.3828125
Logits - mean: nan std: nan
Latent vector - mean: -0.3623020052909851 std: 32.49188232421875
Logits - mean: nan std: nan
Latent vector - mean: -0.6770492792129517 std: 32.27688217163086
Logits - mean: nan std: nan
Latent vector - mean: 11.834980010986328 std: 1151.898681640625
Logits - mean: nan std: nan
Latent vector - mean: -0.874642550945282 std: 74.48075103759766
Logits - mean: nan std: nan
Latent vector - mean: -0.10314157605171204 std: 32.01533126831055
Logits - mean: nan std: nan
Latent vector - mean: -0.3339729309082031 std: 30.957351684570312
Logits - mean: nan std: nan
Latent vector - mean: -0.42229336500167847 std: 33.405521392822266
Logits - mean: nan std: nan
Latent vector - mean: -0.2754189372062683 std: 30.678882598876953
Logits - mean: nan std: nan
Latent vector - mean: -100251.8046875 std: 8286875.5
Logits - mean: nan std: nan
Latent vector - mean: -0.29766103625297546 std: 34.548377990722656
Logits - mean: nan std: nan
Latent vector - mean: -0.831362247467041 std: 33.12620162963867
Logits - mean: nan std: nan
Latent vector - mean: -0.19247150421142578 std: 32.292022705078125
Logits - mean: nan std: nan
Latent vector - mean: -10987455381504.0 std: 3037180217786368.0
Logits - mean: nan std: nan
Latent vector - mean: -0.5234284400939941 std: 28.765377044677734
Logits - mean: nan std: nan
Latent vector - mean: 241023615762432.0 std: 2.181496782507213e+16
Logits - mean: nan std: nan
Latent vector - mean: -0.2716156840324402 std: 27.793516159057617
Logits - mean: nan std: nan
Latent vector - mean: -0.8056998252868652 std: 36.458335876464844
Logits - mean: nan std: nan
Latent vector - mean: 1086879.875 std: 98373136.0
Logits - mean: nan std: nan
Latent vector - mean: 976.2861938476562 std: 100847.9765625
Logits - mean: nan std: nan
Latent vector - mean: 823527997440.0 std: 74537253208064.0
Logits - mean: nan std: nan
Latent vector - mean: 9527.591796875 std: 862304.75
Logits - mean: nan std: nan
Latent vector - mean: -1729.6524658203125 std: 156520.625
Logits - mean: nan std: nan
Latent vector - mean: -0.44942590594291687 std: 29.831939697265625
Logits - mean: nan std: nan
Latent vector - mean: -0.13503523170948029 std: 31.13690185546875
Logits - mean: nan std: nan
Latent vector - mean: -0.3244752585887909 std: 29.56710433959961
Logits - mean: nan std: nan
Latent vector - mean: 344.9869384765625 std: 31232.07421875
Logits - mean: nan std: nan
Latent vector - mean: -1550524.875 std: 140337456.0
Logits - mean: nan std: nan
Latent vector - mean: -0.19764047861099243 std: 32.405643463134766
Logits - mean: nan std: nan
Latent vector - mean: 0.043478235602378845 std: 29.20745277404785
Logits - mean: nan std: nan
Latent vector - mean: -0.36573469638824463 std: 33.29950714111328
Logits - mean: nan std: nan
Latent vector - mean: -0.5579402446746826 std: 28.69436264038086
Logits - mean: nan std: nan
Latent vector - mean: -0.5384114980697632 std: 37.79838562011719
Logits - mean: nan std: nan
Latent vector - mean: 911178.5625 std: 82470496.0
Logits - mean: nan std: nan
Latent vector - mean: -0.6534391641616821 std: 30.095808029174805
Logits - mean: nan std: nan
Latent vector - mean: -0.5909723043441772 std: 28.449426651000977
Logits - mean: nan std: nan
Latent vector - mean: -0.039621949195861816 std: 32.78495788574219
Logits - mean: nan std: nan
Latent vector - mean: -11974665.0 std: 1083822976.0
Logits - mean: nan std: nan
Latent vector - mean: -5992.08203125 std: 542289.625
Logits - mean: nan std: nan
Latent vector - mean: 0.07968154549598694 std: 34.11520004272461
Logits - mean: nan std: nan
Latent vector - mean: -0.8129658102989197 std: 30.859596252441406
Logits - mean: nan std: nan
Latent vector - mean: -0.5451028347015381 std: 29.484962463378906
Logits - mean: nan std: nan
Latent vector - mean: -0.2904284596443176 std: 34.51762390136719
Logits - mean: nan std: nan
Latent vector - mean: 649284416.0 std: 58705297408.0
Logits - mean: nan std: nan
Latent vector - mean: -0.4889780879020691 std: 34.12822723388672
Logits - mean: nan std: nan
Latent vector - mean: 0.1014910638332367 std: 29.352325439453125
Logits - mean: nan std: nan
Latent vector - mean: -0.6832985281944275 std: 33.06097412109375
Logits - mean: nan std: nan
Latent vector - mean: -3.3911998214539543e+34 std: inf
Logits - mean: nan std: nan
Latent vector - mean: -10.064469337463379 std: 836.3804321289062
Logits - mean: nan std: nan
Latent vector - mean: -0.20297321677207947 std: 32.79779815673828
Logits - mean: nan std: nan
Latent vector - mean: -0.18633511662483215 std: 32.29623031616211
Logits - mean: nan std: nan
Latent vector - mean: 0.03961366415023804 std: 28.837730407714844
Logits - mean: nan std: nan
Latent vector - mean: -0.486816942691803 std: 31.62368392944336
Logits - mean: nan std: nan
Latent vector - mean: 95.91722869873047 std: 8742.0888671875
Logits - mean: nan std: nan
Latent vector - mean: -0.03229858726263046 std: 27.34623908996582
Logits - mean: nan std: nan
Latent vector - mean: 0.025626778602600098 std: 31.6862735748291
Logits - mean: nan std: nan
Latent vector - mean: -0.6221712231636047 std: 32.73841094970703
Logits - mean: nan std: nan
Latent vector - mean: -inf std: nan
Logits - mean: nan std: nan
Latent vector - mean: -0.12411719560623169 std: 29.061017990112305
Logits - mean: nan std: nan
Latent vector - mean: -0.394828200340271 std: 32.971282958984375
Logits - mean: nan std: nan
Latent vector - mean: 0.19324159622192383 std: 31.141498565673828
Logits - mean: nan std: nan
Latent vector - mean: -0.03600069880485535 std: 33.076576232910156
Logits - mean: nan std: nan
Latent vector - mean: -0.41562995314598083 std: 32.25385284423828
Logits - mean: nan std: nan
Latent vector - mean: -0.2087150514125824 std: 29.66761589050293
Logits - mean: nan std: nan
Latent vector - mean: -23.132102966308594 std: 2071.30908203125
Logits - mean: nan std: nan
Latent vector - mean: -0.2355087846517563 std: 34.43647384643555
Logits - mean: nan std: nan
Latent vector - mean: -0.11581185460090637 std: 30.54258155822754
Logits - mean: nan std: nan
Latent vector - mean: -0.24124768376350403 std: 31.26786994934082
Logits - mean: nan std: nan
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                                                 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 10/10, Train Loss: nan, Train Accuracy: 41.00%, Val Loss: nan, Val Accuracy: 38.04%
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>

<span class="k">class</span><span class="w"> </span><span class="nc">VAECls</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vae</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">VAECls</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Use encoder part from VAE</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">vae</span><span class="o">.</span><span class="n">encoder</span>
        
        <span class="c1"># Assuming the final part of the encoder outputs features of size `latent_dim`</span>
        <span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">256</span>  <span class="c1"># You should set this according to your VAE settings</span>
        
        <span class="c1"># Append a new layer for binary classification</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">encoded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">encoded</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">VAECls</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vae</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">output_features</span><span class="o">=</span><span class="mi">256</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">VAECls</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">vae</span><span class="o">.</span><span class="n">encoder</span>  <span class="c1"># Assuming the encoder part is what you need</span>
        
        <span class="c1"># Find last encoded feature size automatically if not known (inspect the encoder output)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_temp_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Replace `x_shape` with the shape of your input images</span>
        <span class="k">if</span> <span class="n">pretrained</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_temp_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_temp_x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># self._temp_x = self.encoder(self._temp_x).view(-1).shape[0]</span>
        
        <span class="c1"># Define a classifier network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_temp_x</span><span class="p">,</span> <span class="n">output_features</span><span class="p">),</span>  <span class="c1"># Assuming the flattened features are `self._temp_x` size</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">output_features</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Flatten the features</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># # Assuming `vae` is your already trained VAE model loaded and moved to the appropriate device</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="c1"># vae_model = VAECls(vae)</span>

<span class="c1"># # Move the model to the correct device</span>
<span class="c1"># vae_model = vae_model.to(device)</span>

<span class="c1"># # Compile the model with optimizer and loss function for binary classification</span>
<span class="c1"># optimizer = optim.Adam(vae_model.parameters(), lr=0.001)</span>
<span class="c1"># criterion = nn.BCELoss()</span>

<span class="c1"># # Assume `training_data` and `labels` have been defined and loaded here</span>
<span class="c1"># # Example forward pass (training)</span>
<span class="c1"># # You should further complete this with a full training loop including loading your data</span>
<span class="c1"># vae_model.train()</span>
<span class="c1"># for data, target in training_loader:  # training_loader should be set up to load your data and labels</span>
<span class="c1">#     data, target = data.to(device), target.to(device)</span>
<span class="c1">#     optimizer.zero_grad()</span>
<span class="c1">#     outputs = vae_model(data)</span>
<span class="c1">#     loss = criterion(outputs, target.float().unsqueeze(1))  # Ensure target is the correct shape and type</span>
<span class="c1">#     loss.backward()</span>
<span class="c1">#     optimizer.step()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#make a classification task to predict whether the location is in Scotland or England. Ensure that the classes are balanced (see sense_ae_metadata.csv)</span>
<span class="n">location</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span> <span class="k">if</span> <span class="s1">&#39;leeds&#39;</span> <span class="ow">in</span> <span class="n">i</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">filepaths</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(6953, 64, 64, 3)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision</span><span class="w"> </span><span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Convert numpy arrays to tensors</span>
<span class="n">data_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="c1"># Change data to (N, C, H, W) format expected by PyTorch Conv2D layers</span>
<span class="n">data_tensor</span> <span class="o">=</span> <span class="n">data_tensor</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">location_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">location</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Create dataset and dataloader - restrict training to only 100 samples</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">data_tensor</span><span class="p">[:</span><span class="mi">100</span><span class="p">],</span> <span class="n">location_tensor</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Validation dataset</span>
<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">data_tensor</span><span class="p">[</span><span class="mi">100</span><span class="p">:],</span> <span class="n">location_tensor</span><span class="p">[</span><span class="mi">100</span><span class="p">:])</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Ensure data are in the format (N, C, H, W) and normalized if necessary</span>
<span class="c1"># This might already be handled. If not, use an appropriate `transform`.</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Assuming `vae` is your already trained VAE model loaded and moved to the appropriate device</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">vae_model</span> <span class="o">=</span> <span class="n">VAECls</span><span class="p">(</span><span class="n">vae</span><span class="p">)</span>

<span class="c1"># Assuming VAECls is defined and instantiated as vae_model</span>
<span class="n">vae_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Define the optimizer and criterion</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">vae_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>  <span class="c1"># Binary Cross-Entropy Loss for binary classification</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_tensor</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([6953, 3, 64, 64])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision</span><span class="w"> </span><span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Convert numpy arrays to tensors</span>
<span class="n">data_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="c1"># Change data to (N, C, H, W) format expected by PyTorch Conv2D layers</span>
<span class="n">data_tensor</span> <span class="o">=</span> <span class="n">data_tensor</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">location_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">location</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Create dataset and dataloader - restrict training to only 100 samples</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">data_tensor</span><span class="p">[:</span><span class="mi">100</span><span class="p">],</span> <span class="n">location_tensor</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Validation dataset</span>
<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">data_tensor</span><span class="p">[</span><span class="mi">100</span><span class="p">:],</span> <span class="n">location_tensor</span><span class="p">[</span><span class="mi">100</span><span class="p">:])</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Ensure data are in the format (N, C, H, W) and normalized if necessary</span>
<span class="c1"># This might already be handled. If not, use an appropriate `transform`.</span>


<span class="c1"># Assuming `vae` is your already trained VAE model loaded and moved to the appropriate device</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="c1"># vae_model = VAECls(vae, pretrained=False)</span>
<span class="n">vae_model</span> <span class="o">=</span> <span class="n">VAECls</span><span class="p">(</span><span class="n">vae</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Assuming VAECls is defined and instantiated as vae_model</span>
<span class="n">vae_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Define the optimizer and criterion</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">vae_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>  <span class="c1"># Binary Cross-Entropy Loss for binary classification</span>

<span class="c1"># Define the number of epochs</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">vae_model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>  <span class="c1"># Set the model to training mode</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">for</span> <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Forward pass</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">vae_model</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>  <span class="c1"># Ensure output shape matches the labels shape</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="c1"># Backward and optimize</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Validation Loss</span>
    <span class="n">vae_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># Set the model to evaluation mode</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
            <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">vae_model</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Print training and validation loss</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s1">], &#39;</span>
          <span class="sa">f</span><span class="s1">&#39;Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, &#39;</span>
          <span class="sa">f</span><span class="s1">&#39;Val Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">-</span><span class="mi">100</span><span class="p">)</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [1/10], Train Loss: 1.3447, Val Loss: 0.9174
Epoch [2/10], Train Loss: 0.2866, Val Loss: 0.8154
Epoch [3/10], Train Loss: 0.1106, Val Loss: 0.9350
Epoch [4/10], Train Loss: 0.0454, Val Loss: 1.1163
Epoch [5/10], Train Loss: 0.0134, Val Loss: 1.2834
Epoch [6/10], Train Loss: 0.0037, Val Loss: 1.3942
Epoch [7/10], Train Loss: 0.0127, Val Loss: 1.4951
Epoch [8/10], Train Loss: 0.0047, Val Loss: 1.6007
Epoch [9/10], Train Loss: 0.0045, Val Loss: 1.8033
Epoch [10/10], Train Loss: 0.0013, Val Loss: 1.9433
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Given: data_tensor, location_tensor setup correctly as shown previously in the question.</span>

<span class="c1"># Create dataset and dataloader</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">data_tensor</span><span class="p">[:</span><span class="mi">100</span><span class="p">],</span> <span class="n">location_tensor</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">data_tensor</span><span class="p">[</span><span class="mi">100</span><span class="p">:],</span> <span class="n">location_tensor</span><span class="p">[</span><span class="mi">100</span><span class="p">:])</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Assuming a correctly setup VAECls model and transferred to an appropriate device</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">vae_model</span> <span class="o">=</span> <span class="n">VAECls</span><span class="p">(</span><span class="n">vae</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Ensure that VAECls uses the VAE encoder and has a classification layer</span>

<span class="c1"># Optimizer and loss function setup</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">vae_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>

<span class="c1"># Metrics storage</span>
<span class="n">history</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s1">&#39;train_accuracy&#39;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s1">&#39;val_accuracy&#39;</span><span class="p">:</span> <span class="p">[]</span>
<span class="p">}</span>

<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">vae_model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_correct</span><span class="p">,</span> <span class="n">train_total</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">vae_model</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="n">predicted</span> <span class="o">=</span> <span class="p">(</span><span class="n">outputs</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">train_correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">train_total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">train_accuracy</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">train_correct</span> <span class="o">/</span> <span class="n">train_total</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">))</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_accuracy</span><span class="p">)</span>

    <span class="c1"># Validation</span>
    <span class="n">vae_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_correct</span><span class="p">,</span> <span class="n">val_total</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
            <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">vae_model</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="n">predicted</span> <span class="o">=</span> <span class="p">(</span><span class="n">outputs</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">val_correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">val_total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">val_accuracy</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">val_correct</span> <span class="o">/</span> <span class="n">val_total</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">))</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_accuracy</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s1">, Train Loss: </span><span class="si">{</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;train_loss&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Train Acc: </span><span class="si">{</span><span class="n">train_accuracy</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%, &#39;</span> <span class="o">+</span>
          <span class="sa">f</span><span class="s1">&#39;Val Loss: </span><span class="si">{</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Val Acc: </span><span class="si">{</span><span class="n">val_accuracy</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>

<span class="c1"># You can now use `history` for plotting or other analyses as required:</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">TypeError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">130</span><span class="p">],</span> <span class="n">line</span> <span class="mi">16</span>
<span class="g g-Whitespace">     </span><span class="mi">14</span> <span class="c1"># Assuming a correctly setup VAECls model and transferred to an appropriate device</span>
<span class="g g-Whitespace">     </span><span class="mi">15</span> <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">16</span> <span class="n">vae_model</span> <span class="o">=</span> <span class="n">VAECls</span><span class="p">(</span><span class="n">vae</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Ensure that VAECls uses the VAE encoder and has a classification layer</span>
<span class="g g-Whitespace">     </span><span class="mi">18</span> <span class="c1"># Optimizer and loss function setup</span>
<span class="g g-Whitespace">     </span><span class="mi">19</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">vae_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

<span class="nn">Cell In[126], line 14,</span> in <span class="ni">VAECls.__init__</span><span class="nt">(self, vae, pretrained, output_features)</span>
<span class="g g-Whitespace">      </span><span class="mi">9</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_temp_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_temp_x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="g g-Whitespace">     </span><span class="mi">10</span> <span class="c1"># self._temp_x = self.encoder(self._temp_x).view(-1).shape[0]</span>
<span class="g g-Whitespace">     </span><span class="mi">11</span> 
<span class="g g-Whitespace">     </span><span class="mi">12</span> <span class="c1"># Define a classifier network</span>
<span class="g g-Whitespace">     </span><span class="mi">13</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
<span class="ne">---&gt; </span><span class="mi">14</span>     <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_temp_x</span><span class="p">,</span> <span class="n">output_features</span><span class="p">),</span>  <span class="c1"># Assuming the flattened features are `self._temp_x` size</span>
<span class="g g-Whitespace">     </span><span class="mi">15</span>     <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
<span class="g g-Whitespace">     </span><span class="mi">16</span>     <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">output_features</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
<span class="g g-Whitespace">     </span><span class="mi">17</span>     <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
<span class="g g-Whitespace">     </span><span class="mi">18</span> <span class="p">)</span>

<span class="nn">File /exports/csce/datastore/geos/users/s2112771/miniforge3/envs/sensebook/lib/python3.12/site-packages/torch/nn/modules/linear.py:106,</span> in <span class="ni">Linear.__init__</span><span class="nt">(self, in_features, out_features, bias, device, dtype)</span>
<span class="g g-Whitespace">    </span><span class="mi">103</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_features</span> <span class="o">=</span> <span class="n">in_features</span>
<span class="g g-Whitespace">    </span><span class="mi">104</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_features</span> <span class="o">=</span> <span class="n">out_features</span>
<span class="g g-Whitespace">    </span><span class="mi">105</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span>
<span class="ne">--&gt; </span><span class="mi">106</span>     <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">out_features</span><span class="p">,</span> <span class="n">in_features</span><span class="p">),</span> <span class="o">**</span><span class="n">factory_kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">107</span> <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">108</span> <span class="k">if</span> <span class="n">bias</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">109</span>     <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">out_features</span><span class="p">,</span> <span class="o">**</span><span class="n">factory_kwargs</span><span class="p">))</span>

<span class="ne">TypeError</span>: empty(): argument &#39;size&#39; failed to unpack the object at pos 2 with error &quot;type must be tuple of ints,but got Tensor&quot;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Plotting Loss</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Val Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Loss Through Epochs&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Plotting Accuracy</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Val Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Accuracy Through Epochs&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy (%)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/5cb0c0ccdafffa99559d886282fe71e8b3c32f03a293b03b2372136d20b4fb0d.png" src="../../../_images/5cb0c0ccdafffa99559d886282fe71e8b3c32f03a293b03b2372136d20b4fb0d.png" />
<img alt="../../../_images/6826c7eb79d70442532e094ead1615fac1dcbd559b77302db8393c15e919356e.png" src="../../../_images/6826c7eb79d70442532e094ead1615fac1dcbd559b77302db8393c15e919356e.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="n">history</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s1">&#39;train_accuracy&#39;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s1">&#39;val_accuracy&#39;</span><span class="p">:</span> <span class="p">[]</span>
<span class="p">}</span>

<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">vae_model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>  <span class="c1"># Set the model to training mode</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">vae_model</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">predicted</span> <span class="o">=</span> <span class="p">(</span><span class="n">outputs</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">train_accuracy</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">))</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_accuracy</span><span class="p">)</span>

    <span class="c1"># Validation phase</span>
    <span class="n">vae_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># Set the model to evaluation mode</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
            <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">vae_model</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

            <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">predicted</span> <span class="o">=</span> <span class="p">(</span><span class="n">outputs</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">val_accuracy</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">))</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_accuracy</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">, Train Loss: </span><span class="si">{</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;train_loss&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Train Acc: </span><span class="si">{</span><span class="n">train_accuracy</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%, &#39;</span>
          <span class="sa">f</span><span class="s1">&#39;Val Loss: </span><span class="si">{</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Val Acc: </span><span class="si">{</span><span class="n">val_accuracy</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1, Train Loss: 0.0003, Train Acc: 100.00%, Val Loss: 3.6685, Val Acc: 60.38%
Epoch 2, Train Loss: 0.0002, Train Acc: 100.00%, Val Loss: 3.6678, Val Acc: 60.24%
Epoch 3, Train Loss: 0.0003, Train Acc: 100.00%, Val Loss: 3.7127, Val Acc: 60.22%
Epoch 4, Train Loss: 0.0002, Train Acc: 100.00%, Val Loss: 3.8065, Val Acc: 60.34%
Epoch 5, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 3.9021, Val Acc: 60.47%
Epoch 6, Train Loss: 0.0003, Train Acc: 100.00%, Val Loss: 3.9303, Val Acc: 60.32%
Epoch 7, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 3.9600, Val Acc: 60.22%
Epoch 8, Train Loss: 0.0002, Train Acc: 100.00%, Val Loss: 3.9824, Val Acc: 60.15%
Epoch 9, Train Loss: 0.0001, Train Acc: 100.00%, Val Loss: 4.0184, Val Acc: 60.15%
Epoch 10, Train Loss: 0.0005, Train Acc: 100.00%, Val Loss: 4.0387, Val Acc: 60.16%
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plotting Loss</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Training and Validation Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Plotting Accuracy</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Training and Validation Accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy (%)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/2e489418d9331a3ed70a1559261c5a8e04c7cd28488acbd77b9289223adae8ce.png" src="../../../_images/2e489418d9331a3ed70a1559261c5a8e04c7cd28488acbd77b9289223adae8ce.png" />
<img alt="../../../_images/b8fe9b0cb79020ec3ee7565d5ff05c348e2c5e751928843d3c0e4a9c83d7ce25.png" src="../../../_images/b8fe9b0cb79020ec3ee7565d5ff05c348e2c5e751928843d3c0e4a9c83d7ce25.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># VAE model, optimizer setup</span>
<span class="n">vae</span> <span class="o">=</span> <span class="n">VariationalAutoencoder</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">latent_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">vae</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import torch</span>
<span class="c1"># from torch.utils.data import DataLoader, TensorDataset</span>
<span class="c1"># from sklearn.model_selection import train_test_split</span>
<span class="c1"># import numpy as np</span>

<span class="c1"># # Assuming `data` is your image data loaded in an (N, H, W, C) format and `location` are the labels</span>
<span class="c1"># data_tensor = torch.tensor(data).float()</span>
<span class="c1"># location_tensor = torch.tensor(location).float()</span>

<span class="c1"># # Change data to (N, C, H, W) format expected by PyTorch Conv2D layers</span>
<span class="c1"># data_tensor = data_tensor.permute(0, 3, 1, 2)</span>

<span class="c1"># # Split into training and validation sets</span>
<span class="c1"># train_data, valid_data, train_labels, valid_labels = train_test_split(</span>
<span class="c1">#     data_tensor, location_tensor, test_size=0.99, random_state=42, stratify=location  # using a large test size for quick example; adjust accordingly</span>
<span class="c1"># )</span>

<span class="c1"># # Create DataLoaders for training and validation sets</span>
<span class="c1"># batch_size = 10</span>
<span class="c1"># train_dataset = TensorDataset(train_data, train_labels)</span>
<span class="c1"># valid_dataset = TensorDataset(valid_data, valid_labels)</span>

<span class="c1"># train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)</span>
<span class="c1"># valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)</span>

<span class="c1"># # Assuming VAECls and vae_model are defined and setup correctly</span>
<span class="c1"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span>
<span class="c1"># vae_model = VAECls(vae).to(device)  # Make sure your model class is correctly initialized</span>

<span class="c1"># optimizer = torch.optim.Adam(vae_model.parameters(), lr=0.001)</span>
<span class="c1"># criterion = torch.nn.BCELoss()</span>

<span class="c1"># Training Loop</span>
<span class="n">vae_model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>  <span class="c1"># Set the model to training mode</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>  <span class="c1"># Assuming you want to run for 10 epochs</span>
    <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">vae_model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Ensure outputs and labels dimensions match</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">, Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">RuntimeError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">100</span><span class="p">],</span> <span class="n">line</span> <span class="mi">40</span>
<span class="g g-Whitespace">     </span><span class="mi">37</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">39</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="ne">---&gt; </span><span class="mi">40</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">vae_model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Ensure outputs and labels dimensions match</span>
<span class="g g-Whitespace">     </span><span class="mi">41</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">42</span> <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

<span class="nn">File /exports/csce/datastore/geos/users/s2112771/miniforge3/envs/sensebook/lib/python3.12/site-packages/torch/nn/modules/module.py:1739,</span> in <span class="ni">Module._wrapped_call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1737</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compiled_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
<span class="g g-Whitespace">   </span><span class="mi">1738</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1739</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File /exports/csce/datastore/geos/users/s2112771/miniforge3/envs/sensebook/lib/python3.12/site-packages/torch/nn/modules/module.py:1750,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1745</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1746</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1747</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1748</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1749</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1750</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1752</span> <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>
<span class="g g-Whitespace">   </span><span class="mi">1753</span> <span class="n">called_always_called_hooks</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

<span class="nn">Cell In[91], line 22,</span> in <span class="ni">VAECls.forward</span><span class="nt">(self, x)</span>
<span class="g g-Whitespace">     </span><span class="mi">20</span> <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="g g-Whitespace">     </span><span class="mi">21</span>     <span class="n">encoded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">22</span>     <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">encoded</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">23</span>     <span class="k">return</span> <span class="n">out</span>

<span class="nn">File /exports/csce/datastore/geos/users/s2112771/miniforge3/envs/sensebook/lib/python3.12/site-packages/torch/nn/modules/module.py:1739,</span> in <span class="ni">Module._wrapped_call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1737</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compiled_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
<span class="g g-Whitespace">   </span><span class="mi">1738</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1739</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File /exports/csce/datastore/geos/users/s2112771/miniforge3/envs/sensebook/lib/python3.12/site-packages/torch/nn/modules/module.py:1750,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1745</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1746</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1747</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1748</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1749</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1750</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1752</span> <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>
<span class="g g-Whitespace">   </span><span class="mi">1753</span> <span class="n">called_always_called_hooks</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

<span class="nn">File /exports/csce/datastore/geos/users/s2112771/miniforge3/envs/sensebook/lib/python3.12/site-packages/torch/nn/modules/container.py:250,</span> in <span class="ni">Sequential.forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">248</span> <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">249</span>     <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">250</span>         <span class="nb">input</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">251</span>     <span class="k">return</span> <span class="nb">input</span>

<span class="nn">File /exports/csce/datastore/geos/users/s2112771/miniforge3/envs/sensebook/lib/python3.12/site-packages/torch/nn/modules/module.py:1739,</span> in <span class="ni">Module._wrapped_call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1737</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compiled_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>
<span class="g g-Whitespace">   </span><span class="mi">1738</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1739</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_impl</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nn">File /exports/csce/datastore/geos/users/s2112771/miniforge3/envs/sensebook/lib/python3.12/site-packages/torch/nn/modules/module.py:1750,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1745</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1746</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1747</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_pre_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1748</span>         <span class="ow">or</span> <span class="n">_global_backward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1749</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1750</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1752</span> <span class="n">result</span> <span class="o">=</span> <span class="kc">None</span>
<span class="g g-Whitespace">   </span><span class="mi">1753</span> <span class="n">called_always_called_hooks</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

<span class="nn">File /exports/csce/datastore/geos/users/s2112771/miniforge3/envs/sensebook/lib/python3.12/site-packages/torch/nn/modules/linear.py:125,</span> in <span class="ni">Linear.forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">124</span> <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">125</span>     <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

<span class="ne">RuntimeError</span>: mat1 and mat2 shapes cannot be multiplied (10x8192 and 256x1)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Assuming `vae` is your already trained VAE model loaded and moved to the appropriate device</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

<span class="c1"># Define the VAE Classification model</span>
<span class="k">class</span><span class="w"> </span><span class="nc">VAECls</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vae</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">output_features</span><span class="o">=</span><span class="mi">256</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">VAECls</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">vae</span><span class="o">.</span><span class="n">encoder</span>  <span class="c1"># Assuming the encoder part is what you need</span>
        
        <span class="c1"># Find last encoded feature size automatically if not known (inspect the encoder output)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_temp_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Replace `x_shape` with the shape of your input images</span>
        <span class="k">if</span> <span class="n">pretrained</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_temp_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_temp_x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="c1"># Define a classifier network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_temp_x</span><span class="p">,</span> <span class="n">output_features</span><span class="p">),</span>  <span class="c1"># Assuming the flattened features are `self._temp_x` size</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">output_features</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Flatten the features</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># Convert numpy arrays to tensors</span>
<span class="n">data_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">data_tensor</span> <span class="o">=</span> <span class="n">data_tensor</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Change data to (N, C, H, W) format</span>
<span class="n">location_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">location</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Create dataset and dataloader - restrict training to only 100 samples</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">data_tensor</span><span class="p">[:</span><span class="mi">100</span><span class="p">],</span> <span class="n">location_tensor</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Validation dataset</span>
<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">data_tensor</span><span class="p">[</span><span class="mi">100</span><span class="p">:],</span> <span class="n">location_tensor</span><span class="p">[</span><span class="mi">100</span><span class="p">:])</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Instantiate the model</span>
<span class="n">vae_model</span> <span class="o">=</span> <span class="n">VAECls</span><span class="p">(</span><span class="n">vae</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Define the optimizer and criterion</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">vae_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>  <span class="c1"># Binary Cross-Entropy Loss for binary classification</span>

<span class="c1"># Define the number of epochs</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># History dictionary to store metrics</span>
<span class="n">history</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s1">&#39;train_accuracy&#39;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s1">&#39;val_accuracy&#39;</span><span class="p">:</span> <span class="p">[]</span>
<span class="p">}</span>

<span class="c1"># Function to calculate accuracy</span>
<span class="k">def</span><span class="w"> </span><span class="nf">calculate_accuracy</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="n">predicted</span> <span class="o">=</span> <span class="p">(</span><span class="n">outputs</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

<span class="c1"># Training function</span>
<span class="k">def</span><span class="w"> </span><span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">train_accuracy</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">for</span> <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Forward pass</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">calculate_accuracy</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="c1"># Backward and optimize</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">train_accuracy</span> <span class="o">+=</span> <span class="n">accuracy</span> <span class="o">*</span> <span class="n">imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">train_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">train_accuracy</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_accuracy</span>

<span class="c1"># Validation function</span>
<span class="k">def</span><span class="w"> </span><span class="nf">validate_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">val_accuracy</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
            <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="n">accuracy</span> <span class="o">=</span> <span class="n">calculate_accuracy</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

            <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">val_accuracy</span> <span class="o">+=</span> <span class="n">accuracy</span> <span class="o">*</span> <span class="n">imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">val_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">val_accuracy</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_accuracy</span>

<span class="c1"># Training loop</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_accuracy</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">vae_model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_accuracy</span> <span class="o">=</span> <span class="n">validate_model</span><span class="p">(</span><span class="n">vae_model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

    <span class="c1"># Store metrics in history</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_accuracy</span><span class="p">)</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_accuracy</span><span class="p">)</span>

    <span class="c1"># Print training and validation metrics</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s1">], &#39;</span>
          <span class="sa">f</span><span class="s1">&#39;Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Train Accuracy: </span><span class="si">{</span><span class="n">train_accuracy</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, &#39;</span>
          <span class="sa">f</span><span class="s1">&#39;Val Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Val Accuracy: </span><span class="si">{</span><span class="n">val_accuracy</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># Now you can use `history` to plot the metrics</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [1/10], Train Loss: 0.7478, Train Accuracy: 0.7500, Val Loss: 1.9194, Val Accuracy: 0.5519
Epoch [2/10], Train Loss: 0.4084, Train Accuracy: 0.8700, Val Loss: 3.2440, Val Accuracy: 0.6874
Epoch [3/10], Train Loss: 0.1836, Train Accuracy: 0.9500, Val Loss: 1.1162, Val Accuracy: 0.5256
Epoch [4/10], Train Loss: 0.0930, Train Accuracy: 0.9700, Val Loss: 1.2887, Val Accuracy: 0.6680
Epoch [5/10], Train Loss: 0.0220, Train Accuracy: 0.9900, Val Loss: 2.0047, Val Accuracy: 0.6781
Epoch [6/10], Train Loss: 0.0066, Train Accuracy: 1.0000, Val Loss: 2.1661, Val Accuracy: 0.6755
Epoch [7/10], Train Loss: 0.0031, Train Accuracy: 1.0000, Val Loss: 2.4687, Val Accuracy: 0.6787
Epoch [8/10], Train Loss: 0.0031, Train Accuracy: 1.0000, Val Loss: 2.6083, Val Accuracy: 0.6775
Epoch [9/10], Train Loss: 0.0003, Train Accuracy: 1.0000, Val Loss: 2.7970, Val Accuracy: 0.6823
Epoch [10/10], Train Loss: 0.0004, Train Accuracy: 1.0000, Val Loss: 2.9009, Val Accuracy: 0.6823
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Plot training &amp; validation loss values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Model Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Plot training &amp; validation accuracy values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Model Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/f1d79585a6424fe234475877537b640e9a29f6c7c5b745deacc7c305a2f9009c.png" src="../../../_images/f1d79585a6424fe234475877537b640e9a29f6c7c5b745deacc7c305a2f9009c.png" />
<img alt="../../../_images/54f5b48f3ab49d4f345dc24a6a4576274d64c42b84e151862439675f51773c1c.png" src="../../../_images/54f5b48f3ab49d4f345dc24a6a4576274d64c42b84e151862439675f51773c1c.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">VAECls</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vae</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">output_features</span><span class="o">=</span><span class="mi">256</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">VAECls</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="c1"># Use the pretrained encoder if `pretrained=True`, otherwise initialize a new encoder</span>
        <span class="k">if</span> <span class="n">pretrained</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">vae</span><span class="o">.</span><span class="n">encoder</span>  <span class="c1"># Use the pretrained encoder</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Define a new encoder with random initialization (assuming the same architecture as the VAE encoder)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>  <span class="c1"># Example layer</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>  <span class="c1"># Example layer</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>  <span class="c1"># Example layer</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>  <span class="c1"># Flatten the output for the classifier</span>
            <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Move the new encoder to the device</span>
        
        <span class="c1"># Determine the size of the flattened features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_temp_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Replace with the shape of your input images</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_temp_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_temp_x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="c1"># Define a classifier network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_temp_x</span><span class="p">,</span> <span class="n">output_features</span><span class="p">),</span>  <span class="c1"># Assuming the flattened features are `self._temp_x` size</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">output_features</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># Move the classifier to the device</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Flatten the features</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Instantiate the model with pretrained encoder</span>
<span class="n">vae_model_pretrained</span> <span class="o">=</span> <span class="n">VAECls</span><span class="p">(</span><span class="n">vae</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Instantiate the model with randomly initialized encoder</span>
<span class="n">vae_model_random</span> <span class="o">=</span> <span class="n">VAECls</span><span class="p">(</span><span class="n">vae</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># History dictionary to store metrics</span>
<span class="n">history</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s1">&#39;train_accuracy&#39;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s1">&#39;val_accuracy&#39;</span><span class="p">:</span> <span class="p">[]</span>
<span class="p">}</span>

<span class="c1"># Training loop</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="c1"># Training phase</span>
    <span class="n">vae_model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>  <span class="c1"># Set the model to training mode</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">train_accuracy</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">for</span> <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Forward pass</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">vae_model</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">calculate_accuracy</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="c1"># Backward pass and optimization</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">train_accuracy</span> <span class="o">+=</span> <span class="n">accuracy</span> <span class="o">*</span> <span class="n">imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Calculate average training loss and accuracy for the epoch</span>
    <span class="n">train_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">train_accuracy</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>

    <span class="c1"># Validation phase</span>
    <span class="n">vae_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># Set the model to evaluation mode</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">val_accuracy</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
            <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">vae_model</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="n">accuracy</span> <span class="o">=</span> <span class="n">calculate_accuracy</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

            <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">val_accuracy</span> <span class="o">+=</span> <span class="n">accuracy</span> <span class="o">*</span> <span class="n">imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Calculate average validation loss and accuracy for the epoch</span>
    <span class="n">val_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">val_accuracy</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>

    <span class="c1"># Store metrics in history</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_accuracy</span><span class="p">)</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_accuracy</span><span class="p">)</span>

    <span class="c1"># Print metrics for the epoch</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s1">], &#39;</span>
          <span class="sa">f</span><span class="s1">&#39;Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Train Accuracy: </span><span class="si">{</span><span class="n">train_accuracy</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, &#39;</span>
          <span class="sa">f</span><span class="s1">&#39;Val Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Val Accuracy: </span><span class="si">{</span><span class="n">val_accuracy</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [1/10], Train Loss: 1.2252, Train Accuracy: 0.9600, Val Loss: 12.7798, Val Accuracy: 0.6330
Epoch [2/10], Train Loss: 1.3116, Train Accuracy: 0.9400, Val Loss: 11.1174, Val Accuracy: 0.7068
Epoch [3/10], Train Loss: 0.5347, Train Accuracy: 0.9200, Val Loss: 7.5387, Val Accuracy: 0.5722
Epoch [4/10], Train Loss: 2.5313, Train Accuracy: 0.9200, Val Loss: 13.0840, Val Accuracy: 0.5672
Epoch [5/10], Train Loss: 1.6774, Train Accuracy: 0.9000, Val Loss: 9.3252, Val Accuracy: 0.6032
Epoch [6/10], Train Loss: 0.0865, Train Accuracy: 0.9600, Val Loss: 1.9306, Val Accuracy: 0.6146
Epoch [7/10], Train Loss: 0.1285, Train Accuracy: 0.9400, Val Loss: 1.9287, Val Accuracy: 0.6111
Epoch [8/10], Train Loss: 0.0612, Train Accuracy: 0.9700, Val Loss: 3.5971, Val Accuracy: 0.6679
Epoch [9/10], Train Loss: 0.0778, Train Accuracy: 0.9900, Val Loss: 3.2554, Val Accuracy: 0.6578
Epoch [10/10], Train Loss: 0.0040, Train Accuracy: 1.0000, Val Loss: 3.2147, Val Accuracy: 0.6606
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train the pretrained model</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_accuracy</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">vae_model_pretrained</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_accuracy</span> <span class="o">=</span> <span class="n">validate_model</span><span class="p">(</span><span class="n">vae_model_pretrained</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Pretrained Model - Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s1">], Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Val Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># Train the randomly initialized model</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_accuracy</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">vae_model_random</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_accuracy</span> <span class="o">=</span> <span class="n">validate_model</span><span class="p">(</span><span class="n">vae_model_random</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Random Model - Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s1">], Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Val Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pretrained Model - Epoch [1/10], Train Loss: 0.7433, Val Loss: 0.6471
Pretrained Model - Epoch [2/10], Train Loss: 0.5931, Val Loss: 0.6013
Pretrained Model - Epoch [3/10], Train Loss: 0.4903, Val Loss: 0.5940
Pretrained Model - Epoch [4/10], Train Loss: 0.4219, Val Loss: 0.6097
Pretrained Model - Epoch [5/10], Train Loss: 0.3762, Val Loss: 0.5909
Pretrained Model - Epoch [6/10], Train Loss: 0.2838, Val Loss: 0.6084
Pretrained Model - Epoch [7/10], Train Loss: 0.2542, Val Loss: 0.6668
Pretrained Model - Epoch [8/10], Train Loss: 0.1878, Val Loss: 0.7328
Pretrained Model - Epoch [9/10], Train Loss: 0.1700, Val Loss: 0.7895
Pretrained Model - Epoch [10/10], Train Loss: 0.1556, Val Loss: 0.8042
Random Model - Epoch [1/10], Train Loss: 0.9120, Val Loss: 1.0931
Random Model - Epoch [2/10], Train Loss: 0.9120, Val Loss: 1.0931
Random Model - Epoch [3/10], Train Loss: 0.9120, Val Loss: 1.0931
Random Model - Epoch [4/10], Train Loss: 0.9120, Val Loss: 1.0931
Random Model - Epoch [5/10], Train Loss: 0.9120, Val Loss: 1.0931
Random Model - Epoch [6/10], Train Loss: 0.9120, Val Loss: 1.0931
Random Model - Epoch [7/10], Train Loss: 0.9120, Val Loss: 1.0931
Random Model - Epoch [8/10], Train Loss: 0.9120, Val Loss: 1.0931
Random Model - Epoch [9/10], Train Loss: 0.9120, Val Loss: 1.0931
Random Model - Epoch [10/10], Train Loss: 0.9120, Val Loss: 1.0931
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train the model</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="c1"># Training phase</span>
    <span class="n">vae_model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">train_accuracy</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">for</span> <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">vae_model</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">calculate_accuracy</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">train_accuracy</span> <span class="o">+=</span> <span class="n">accuracy</span> <span class="o">*</span> <span class="n">imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">train_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">train_accuracy</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>

    <span class="c1"># Validation phase</span>
    <span class="n">vae_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">val_accuracy</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
            <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">vae_model</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="n">accuracy</span> <span class="o">=</span> <span class="n">calculate_accuracy</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

            <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">val_accuracy</span> <span class="o">+=</span> <span class="n">accuracy</span> <span class="o">*</span> <span class="n">imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">val_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">val_accuracy</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>

    <span class="c1"># Store metrics</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_accuracy</span><span class="p">)</span>
    <span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_accuracy</span><span class="p">)</span>

    <span class="c1"># Print metrics</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s1">], &#39;</span>
          <span class="sa">f</span><span class="s1">&#39;Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Train Accuracy: </span><span class="si">{</span><span class="n">train_accuracy</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, &#39;</span>
          <span class="sa">f</span><span class="s1">&#39;Val Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Val Accuracy: </span><span class="si">{</span><span class="n">val_accuracy</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># Plot the metrics</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="c1"># Plot loss</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Model Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="c1"># Plot accuracy</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Model Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [1/10], Train Loss: 0.0043, Train Accuracy: 1.0000, Val Loss: 2.7741, Val Accuracy: 0.6520
Epoch [2/10], Train Loss: 0.0054, Train Accuracy: 1.0000, Val Loss: 3.2794, Val Accuracy: 0.6590
Epoch [3/10], Train Loss: 0.0012, Train Accuracy: 1.0000, Val Loss: 3.9903, Val Accuracy: 0.6616
Epoch [4/10], Train Loss: 0.0006, Train Accuracy: 1.0000, Val Loss: 4.2416, Val Accuracy: 0.6641
Epoch [5/10], Train Loss: 0.0008, Train Accuracy: 1.0000, Val Loss: 4.3076, Val Accuracy: 0.6638
Epoch [6/10], Train Loss: 0.0005, Train Accuracy: 1.0000, Val Loss: 4.2991, Val Accuracy: 0.6639
Epoch [7/10], Train Loss: 0.0005, Train Accuracy: 1.0000, Val Loss: 4.2386, Val Accuracy: 0.6623
Epoch [8/10], Train Loss: 0.0017, Train Accuracy: 1.0000, Val Loss: 4.1355, Val Accuracy: 0.6619
Epoch [9/10], Train Loss: 0.0003, Train Accuracy: 1.0000, Val Loss: 4.1986, Val Accuracy: 0.6622
Epoch [10/10], Train Loss: 0.0003, Train Accuracy: 1.0000, Val Loss: 4.2870, Val Accuracy: 0.6600
</pre></div>
</div>
<img alt="../../../_images/22e40fcc5775bcb5236690bb22f3d38a429bfc6ac4d9b442cb44495a9cabf11e.png" src="../../../_images/22e40fcc5775bcb5236690bb22f3d38a429bfc6ac4d9b442cb44495a9cabf11e.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Function to calculate accuracy</span>
<span class="k">def</span><span class="w"> </span><span class="nf">calculate_accuracy</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="n">predicted</span> <span class="o">=</span> <span class="p">(</span><span class="n">outputs</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">accuracy</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

<span class="c1"># Function to train a model and return its history</span>
<span class="k">def</span><span class="w"> </span><span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">epochs</span><span class="p">):</span>
    <span class="n">history</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s1">&#39;train_accuracy&#39;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s1">&#39;val_accuracy&#39;</span><span class="p">:</span> <span class="p">[]</span>
    <span class="p">}</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="c1"># Training phase</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">train_accuracy</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="k">for</span> <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
            <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="n">accuracy</span> <span class="o">=</span> <span class="n">calculate_accuracy</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">train_accuracy</span> <span class="o">+=</span> <span class="n">accuracy</span> <span class="o">*</span> <span class="n">imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">train_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
        <span class="n">train_accuracy</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>

        <span class="c1"># Validation phase</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">val_accuracy</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
                <span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
                <span class="n">accuracy</span> <span class="o">=</span> <span class="n">calculate_accuracy</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

                <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">val_accuracy</span> <span class="o">+=</span> <span class="n">accuracy</span> <span class="o">*</span> <span class="n">imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">val_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
        <span class="n">val_accuracy</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>

        <span class="c1"># Store metrics</span>
        <span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
        <span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
        <span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_accuracy</span><span class="p">)</span>
        <span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_accuracy</span><span class="p">)</span>

        <span class="c1"># Print metrics</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s1">], &#39;</span>
              <span class="sa">f</span><span class="s1">&#39;Train Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Train Accuracy: </span><span class="si">{</span><span class="n">train_accuracy</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, &#39;</span>
              <span class="sa">f</span><span class="s1">&#39;Val Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Val Accuracy: </span><span class="si">{</span><span class="n">val_accuracy</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">history</span>

<span class="c1"># Define the number of epochs</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># Train the pretrained model</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training pretrained model...&quot;</span><span class="p">)</span>
<span class="n">vae_model_pretrained</span> <span class="o">=</span> <span class="n">VAECls</span><span class="p">(</span><span class="n">vae</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer_pretrained</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">vae_model_pretrained</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="n">history_pretrained</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">vae_model_pretrained</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer_pretrained</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">epochs</span><span class="p">)</span>

<span class="c1"># Train the randomly initialized model</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training randomly initialized model...&quot;</span><span class="p">)</span>
<span class="n">vae_model_random</span> <span class="o">=</span> <span class="n">VAECls</span><span class="p">(</span><span class="n">vae</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer_random</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">vae_model_random</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="n">history_random</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">vae_model_random</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer_random</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">epochs</span><span class="p">)</span>

<span class="c1"># Plot the results</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="c1"># Plot training and validation loss</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history_pretrained</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Pretrained Train Loss&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history_pretrained</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Pretrained Val Loss&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history_random</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Random Train Loss&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history_random</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Random Val Loss&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Loss Comparison&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="c1"># Plot training and validation accuracy</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history_pretrained</span><span class="p">[</span><span class="s1">&#39;train_accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Pretrained Train Accuracy&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history_pretrained</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Pretrained Val Accuracy&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history_random</span><span class="p">[</span><span class="s1">&#39;train_accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Random Train Accuracy&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history_random</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Random Val Accuracy&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Accuracy Comparison&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training pretrained model...
Epoch [1/10], Train Loss: 3.0699, Train Accuracy: 0.7200, Val Loss: 4.0315, Val Accuracy: 0.6895
Epoch [2/10], Train Loss: 1.3966, Train Accuracy: 0.8900, Val Loss: 1.6684, Val Accuracy: 0.5811
Epoch [3/10], Train Loss: 0.1874, Train Accuracy: 0.9500, Val Loss: 1.2158, Val Accuracy: 0.6394
Epoch [4/10], Train Loss: 0.0610, Train Accuracy: 0.9600, Val Loss: 1.2449, Val Accuracy: 0.6502
Epoch [5/10], Train Loss: 0.0283, Train Accuracy: 0.9900, Val Loss: 1.6304, Val Accuracy: 0.6826
Epoch [6/10], Train Loss: 0.0051, Train Accuracy: 1.0000, Val Loss: 2.0830, Val Accuracy: 0.6943
Epoch [7/10], Train Loss: 0.0824, Train Accuracy: 0.9900, Val Loss: 2.1189, Val Accuracy: 0.6899
Epoch [8/10], Train Loss: 0.0076, Train Accuracy: 1.0000, Val Loss: 1.9576, Val Accuracy: 0.6647
Epoch [9/10], Train Loss: 0.0068, Train Accuracy: 1.0000, Val Loss: 1.8953, Val Accuracy: 0.6930
Epoch [10/10], Train Loss: 0.0033, Train Accuracy: 1.0000, Val Loss: 1.8841, Val Accuracy: 0.6930
Training randomly initialized model...
Epoch [1/10], Train Loss: 30.6607, Train Accuracy: 0.5900, Val Loss: 38.1001, Val Accuracy: 0.6190
Epoch [2/10], Train Loss: 37.0000, Train Accuracy: 0.6300, Val Loss: 38.1001, Val Accuracy: 0.6190
Epoch [3/10], Train Loss: 37.0000, Train Accuracy: 0.6300, Val Loss: 38.1001, Val Accuracy: 0.6190
Epoch [4/10], Train Loss: 37.0000, Train Accuracy: 0.6300, Val Loss: 38.1001, Val Accuracy: 0.6190
Epoch [5/10], Train Loss: 37.0000, Train Accuracy: 0.6300, Val Loss: 38.1001, Val Accuracy: 0.6190
Epoch [6/10], Train Loss: 37.0000, Train Accuracy: 0.6300, Val Loss: 38.1001, Val Accuracy: 0.6190
Epoch [7/10], Train Loss: 37.0000, Train Accuracy: 0.6300, Val Loss: 38.1001, Val Accuracy: 0.6190
Epoch [8/10], Train Loss: 37.0000, Train Accuracy: 0.6300, Val Loss: 38.1001, Val Accuracy: 0.6190
Epoch [9/10], Train Loss: 37.0000, Train Accuracy: 0.6300, Val Loss: 38.1001, Val Accuracy: 0.6190
Epoch [10/10], Train Loss: 37.0000, Train Accuracy: 0.6300, Val Loss: 38.1001, Val Accuracy: 0.6190
</pre></div>
</div>
<img alt="../../../_images/006c28ad6e333d6ecf7b73a622a0ca4b822eb7015815c150eda0a11e999d5175.png" src="../../../_images/006c28ad6e333d6ecf7b73a622a0ca4b822eb7015815c150eda0a11e999d5175.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Plot training &amp; validation loss values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">val_loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Model Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Plot training &amp; validation accuracy values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_accuracy</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">val_accuracy</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Model Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/59027d0fe1da225c876cd379052a56ff255d8f87ebcd8d9c7067b876d580dd5c.png" src="../../../_images/59027d0fe1da225c876cd379052a56ff255d8f87ebcd8d9c7067b876d580dd5c.png" />
<img alt="../../../_images/e338c4b26bf2ee171774df6342f16bf6dcf7f99cbd229ad8e5c867f69f24ad6d.png" src="../../../_images/e338c4b26bf2ee171774df6342f16bf6dcf7f99cbd229ad8e5c867f69f24ad6d.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#uncomment this line if you want to rebuild the VAE with untrained weights</span>
<span class="c1">#autoencoder, ae_encoder, ae_decoder = build_autoencoder(input_shape=(64, 64, 3), dropout=0.3, latent_dim=256)</span>
<span class="c1"># vae, var_encoder, var_generator = build_var_autoencoder(latent_dim=256)</span>

<span class="c1"># Remove the decoder layers</span>
<span class="n">discriminator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">vae</span><span class="o">.</span><span class="n">layers</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
    <span class="n">discriminator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>

<span class="c1"># Add a new classification layer</span>
<span class="n">discriminator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>

<span class="c1"># Compile the model</span>
<span class="n">discriminator</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#make a classification task to predict whether the location is in Scotland or England. Ensure that the classes are balanced (see sense_ae_metadata.csv)</span>
<span class="n">location</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span> <span class="k">if</span> <span class="s1">&#39;leeds&#39;</span> <span class="ow">in</span> <span class="n">i</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">filepaths</span><span class="p">])</span>

<span class="c1">#restrict training to only 100 samples</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">discriminator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">[:</span><span class="mi">100</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">location</span><span class="p">[:</span><span class="mi">100</span><span class="p">],</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">100</span><span class="p">:],</span> <span class="n">location</span><span class="p">[</span><span class="mi">100</span><span class="p">:]),</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">history</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dict_keys([&#39;train_loss&#39;, &#39;val_loss&#39;])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#what differences do you see when training this model on a downstream task?</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;train_accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/4092efbd55ff9dc84da798ec08e739cc9f8dcef8c2e49a0e98487b7b93a2827b.png" src="../../../_images/4092efbd55ff9dc84da798ec08e739cc9f8dcef8c2e49a0e98487b7b93a2827b.png" />
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">AttributeError</span><span class="g g-Whitespace">                            </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">115</span><span class="p">],</span> <span class="n">line</span> <span class="mi">8</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="ne">----&gt; </span><span class="mi">8</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training accuracy&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">9</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation accuracy&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">10</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="ne">AttributeError</span>: &#39;dict&#39; object has no attribute &#39;history&#39;
</pre></div>
</div>
</div>
</div>
<p><a name="treasurehunt"></a></p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="autoencoder-treasure-hunt">
<h1>Autoencoder treasure hunt<a class="headerlink" href="#autoencoder-treasure-hunt" title="Link to this heading">#</a></h1>
<p>Clues have been hidden in a Sentinel 2 image. Your job is to find the treasure using an autoencoder - searching through many square kilometres of imagery much faster than if you looked through everything by hand!</p>
<p>Firstly, we read the image in as a cloud-optimised geotiff (COG), and view it:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#install the library to read a COG as an xarray</span>
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>rioxarray<span class="w"> </span>--quiet
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cog_url</span>  <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;https://homepages.see.leeds.ac.uk/~eesjb/sense_training_march24/&#39;</span>
            <span class="s1">&#39;leeds_cog.tif&#39;</span><span class="p">)</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">rioxarray</span>
<span class="n">rds</span> <span class="o">=</span> <span class="n">rioxarray</span><span class="o">.</span><span class="n">open_rasterio</span><span class="p">(</span><span class="n">cog_url</span><span class="p">)</span>
<span class="n">rds</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div><svg style="position: absolute; width: 0; height: 0; overflow: hidden">
<defs>
<symbol id="icon-database" viewBox="0 0 32 32">
<path d="M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z"></path>
<path d="M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z"></path>
<path d="M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z"></path>
</symbol>
<symbol id="icon-file-text2" viewBox="0 0 32 32">
<path d="M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z"></path>
<path d="M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z"></path>
<path d="M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z"></path>
<path d="M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z"></path>
</symbol>
</defs>
</svg>
<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.
 *
 */

:root {
  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));
  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));
  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));
  --xr-border-color: var(--jp-border-color2, #e0e0e0);
  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);
  --xr-background-color: var(--jp-layout-color0, white);
  --xr-background-color-row-even: var(--jp-layout-color1, white);
  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);
}

html[theme="dark"],
html[data-theme="dark"],
body[data-theme="dark"],
body.vscode-dark {
  --xr-font-color0: rgba(255, 255, 255, 1);
  --xr-font-color2: rgba(255, 255, 255, 0.54);
  --xr-font-color3: rgba(255, 255, 255, 0.38);
  --xr-border-color: #1f1f1f;
  --xr-disabled-color: #515151;
  --xr-background-color: #111111;
  --xr-background-color-row-even: #111111;
  --xr-background-color-row-odd: #313131;
}

.xr-wrap {
  display: block !important;
  min-width: 300px;
  max-width: 700px;
}

.xr-text-repr-fallback {
  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */
  display: none;
}

.xr-header {
  padding-top: 6px;
  padding-bottom: 6px;
  margin-bottom: 4px;
  border-bottom: solid 1px var(--xr-border-color);
}

.xr-header > div,
.xr-header > ul {
  display: inline;
  margin-top: 0;
  margin-bottom: 0;
}

.xr-obj-type,
.xr-array-name {
  margin-left: 2px;
  margin-right: 10px;
}

.xr-obj-type {
  color: var(--xr-font-color2);
}

.xr-sections {
  padding-left: 0 !important;
  display: grid;
  grid-template-columns: 150px auto auto 1fr 0 20px 0 20px;
}

.xr-section-item {
  display: contents;
}

.xr-section-item input {
  display: inline-block;
  opacity: 0;
  height: 0;
}

.xr-section-item input + label {
  color: var(--xr-disabled-color);
}

.xr-section-item input:enabled + label {
  cursor: pointer;
  color: var(--xr-font-color2);
}

.xr-section-item input:focus + label {
  border: 2px solid var(--xr-font-color0);
}

.xr-section-item input:enabled + label:hover {
  color: var(--xr-font-color0);
}

.xr-section-summary {
  grid-column: 1;
  color: var(--xr-font-color2);
  font-weight: 500;
}

.xr-section-summary > span {
  display: inline-block;
  padding-left: 0.5em;
}

.xr-section-summary-in:disabled + label {
  color: var(--xr-font-color2);
}

.xr-section-summary-in + label:before {
  display: inline-block;
  content: "►";
  font-size: 11px;
  width: 15px;
  text-align: center;
}

.xr-section-summary-in:disabled + label:before {
  color: var(--xr-disabled-color);
}

.xr-section-summary-in:checked + label:before {
  content: "▼";
}

.xr-section-summary-in:checked + label > span {
  display: none;
}

.xr-section-summary,
.xr-section-inline-details {
  padding-top: 4px;
  padding-bottom: 4px;
}

.xr-section-inline-details {
  grid-column: 2 / -1;
}

.xr-section-details {
  display: none;
  grid-column: 1 / -1;
  margin-bottom: 5px;
}

.xr-section-summary-in:checked ~ .xr-section-details {
  display: contents;
}

.xr-array-wrap {
  grid-column: 1 / -1;
  display: grid;
  grid-template-columns: 20px auto;
}

.xr-array-wrap > label {
  grid-column: 1;
  vertical-align: top;
}

.xr-preview {
  color: var(--xr-font-color3);
}

.xr-array-preview,
.xr-array-data {
  padding: 0 5px !important;
  grid-column: 2;
}

.xr-array-data,
.xr-array-in:checked ~ .xr-array-preview {
  display: none;
}

.xr-array-in:checked ~ .xr-array-data,
.xr-array-preview {
  display: inline-block;
}

.xr-dim-list {
  display: inline-block !important;
  list-style: none;
  padding: 0 !important;
  margin: 0;
}

.xr-dim-list li {
  display: inline-block;
  padding: 0;
  margin: 0;
}

.xr-dim-list:before {
  content: "(";
}

.xr-dim-list:after {
  content: ")";
}

.xr-dim-list li:not(:last-child):after {
  content: ",";
  padding-right: 5px;
}

.xr-has-index {
  font-weight: bold;
}

.xr-var-list,
.xr-var-item {
  display: contents;
}

.xr-var-item > div,
.xr-var-item label,
.xr-var-item > .xr-var-name span {
  background-color: var(--xr-background-color-row-even);
  margin-bottom: 0;
}

.xr-var-item > .xr-var-name:hover span {
  padding-right: 5px;
}

.xr-var-list > li:nth-child(odd) > div,
.xr-var-list > li:nth-child(odd) > label,
.xr-var-list > li:nth-child(odd) > .xr-var-name span {
  background-color: var(--xr-background-color-row-odd);
}

.xr-var-name {
  grid-column: 1;
}

.xr-var-dims {
  grid-column: 2;
}

.xr-var-dtype {
  grid-column: 3;
  text-align: right;
  color: var(--xr-font-color2);
}

.xr-var-preview {
  grid-column: 4;
}

.xr-index-preview {
  grid-column: 2 / 5;
  color: var(--xr-font-color2);
}

.xr-var-name,
.xr-var-dims,
.xr-var-dtype,
.xr-preview,
.xr-attrs dt {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  padding-right: 10px;
}

.xr-var-name:hover,
.xr-var-dims:hover,
.xr-var-dtype:hover,
.xr-attrs dt:hover {
  overflow: visible;
  width: auto;
  z-index: 1;
}

.xr-var-attrs,
.xr-var-data,
.xr-index-data {
  display: none;
  background-color: var(--xr-background-color) !important;
  padding-bottom: 5px !important;
}

.xr-var-attrs-in:checked ~ .xr-var-attrs,
.xr-var-data-in:checked ~ .xr-var-data,
.xr-index-data-in:checked ~ .xr-index-data {
  display: block;
}

.xr-var-data > table {
  float: right;
}

.xr-var-name span,
.xr-var-data,
.xr-index-name div,
.xr-index-data,
.xr-attrs {
  padding-left: 25px !important;
}

.xr-attrs,
.xr-var-attrs,
.xr-var-data,
.xr-index-data {
  grid-column: 1 / -1;
}

dl.xr-attrs {
  padding: 0;
  margin: 0;
  display: grid;
  grid-template-columns: 125px auto;
}

.xr-attrs dt,
.xr-attrs dd {
  padding: 0;
  margin: 0;
  float: left;
  padding-right: 10px;
  width: auto;
}

.xr-attrs dt {
  font-weight: normal;
  grid-column: 1;
}

.xr-attrs dt:hover span {
  display: inline-block;
  background: var(--xr-background-color);
  padding-right: 10px;
}

.xr-attrs dd {
  grid-column: 2;
  white-space: pre-wrap;
  word-break: break-all;
}

.xr-icon-database,
.xr-icon-file-text2,
.xr-no-icon {
  display: inline-block;
  vertical-align: middle;
  width: 1em;
  height: 1.5em !important;
  stroke-width: 0;
  stroke: currentColor;
  fill: currentColor;
}
</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray (band: 3, y: 5000, x: 3928)&gt; Size: 471MB
[58920000 values with dtype=float64]
Coordinates:
  * band         (band) int64 24B 1 2 3
  * x            (x) float64 31kB 5.705e+05 5.705e+05 ... 6.098e+05 6.098e+05
  * y            (y) float64 40kB 5.987e+06 5.987e+06 ... 5.937e+06 5.937e+06
    spatial_ref  int64 8B 0
Attributes:
    resolution:     10.0
    spec:           RasterSpec(epsg=32630, bounds=(499980.0, 5890200.0, 60978...
    AREA_OR_POINT:  Area
    scale_factor:   1.0
    add_offset:     0.0
    long_name:      stackstac-a59c0526e158aaff38198e5e514e7988</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'></div><ul class='xr-dim-list'><li><span class='xr-has-index'>band</span>: 3</li><li><span class='xr-has-index'>y</span>: 5000</li><li><span class='xr-has-index'>x</span>: 3928</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-2d527bc8-2930-4091-982f-bdb0fb1f835f' class='xr-array-in' type='checkbox' checked><label for='section-2d527bc8-2930-4091-982f-bdb0fb1f835f' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>...</span></div><div class='xr-array-data'><pre>[58920000 values with dtype=float64]</pre></div></div></li><li class='xr-section-item'><input id='section-b64c2e54-3a4c-4850-b6fc-f1054567ed42' class='xr-section-summary-in' type='checkbox'  checked><label for='section-b64c2e54-3a4c-4850-b6fc-f1054567ed42' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>band</span></div><div class='xr-var-dims'>(band)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>1 2 3</div><input id='attrs-b21ac2fa-597e-42bb-b92c-e493e1d3f845' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-b21ac2fa-597e-42bb-b92c-e493e1d3f845' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e3f6dc25-fa06-4866-9d7a-f69fd50e0b11' class='xr-var-data-in' type='checkbox'><label for='data-e3f6dc25-fa06-4866-9d7a-f69fd50e0b11' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([1, 2, 3])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>x</span></div><div class='xr-var-dims'>(x)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>5.705e+05 5.705e+05 ... 6.098e+05</div><input id='attrs-1251b08d-ce21-4923-a073-baca8a668014' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-1251b08d-ce21-4923-a073-baca8a668014' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d1bdf919-6725-4a35-87a8-9987b0702cf5' class='xr-var-data-in' type='checkbox'><label for='data-d1bdf919-6725-4a35-87a8-9987b0702cf5' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([570500., 570510., 570520., ..., 609750., 609760., 609770.],
      shape=(3928,))</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>y</span></div><div class='xr-var-dims'>(y)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>5.987e+06 5.987e+06 ... 5.937e+06</div><input id='attrs-2879bef1-8545-412a-87e3-62c59e23d18b' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-2879bef1-8545-412a-87e3-62c59e23d18b' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-430b735b-d2ed-48f1-89f2-336cfb640992' class='xr-var-data-in' type='checkbox'><label for='data-430b735b-d2ed-48f1-89f2-336cfb640992' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([5987240., 5987230., 5987220., ..., 5937270., 5937260., 5937250.],
      shape=(5000,))</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>spatial_ref</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>0</div><input id='attrs-0db9784b-6a6e-42e0-9b55-75413aeec384' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-0db9784b-6a6e-42e0-9b55-75413aeec384' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-8d6e8a75-0f29-4111-828e-4c205c2ead84' class='xr-var-data-in' type='checkbox'><label for='data-8d6e8a75-0f29-4111-828e-4c205c2ead84' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>crs_wkt :</span></dt><dd>PROJCS[&quot;WGS 84 / UTM zone 30N&quot;,GEOGCS[&quot;WGS 84&quot;,DATUM[&quot;WGS_1984&quot;,SPHEROID[&quot;WGS 84&quot;,6378137,298.257223563,AUTHORITY[&quot;EPSG&quot;,&quot;7030&quot;]],AUTHORITY[&quot;EPSG&quot;,&quot;6326&quot;]],PRIMEM[&quot;Greenwich&quot;,0,AUTHORITY[&quot;EPSG&quot;,&quot;8901&quot;]],UNIT[&quot;degree&quot;,0.0174532925199433,AUTHORITY[&quot;EPSG&quot;,&quot;9122&quot;]],AUTHORITY[&quot;EPSG&quot;,&quot;4326&quot;]],PROJECTION[&quot;Transverse_Mercator&quot;],PARAMETER[&quot;latitude_of_origin&quot;,0],PARAMETER[&quot;central_meridian&quot;,-3],PARAMETER[&quot;scale_factor&quot;,0.9996],PARAMETER[&quot;false_easting&quot;,500000],PARAMETER[&quot;false_northing&quot;,0],UNIT[&quot;metre&quot;,1,AUTHORITY[&quot;EPSG&quot;,&quot;9001&quot;]],AXIS[&quot;Easting&quot;,EAST],AXIS[&quot;Northing&quot;,NORTH],AUTHORITY[&quot;EPSG&quot;,&quot;32630&quot;]]</dd><dt><span>semi_major_axis :</span></dt><dd>6378137.0</dd><dt><span>semi_minor_axis :</span></dt><dd>6356752.314245179</dd><dt><span>inverse_flattening :</span></dt><dd>298.257223563</dd><dt><span>reference_ellipsoid_name :</span></dt><dd>WGS 84</dd><dt><span>longitude_of_prime_meridian :</span></dt><dd>0.0</dd><dt><span>prime_meridian_name :</span></dt><dd>Greenwich</dd><dt><span>geographic_crs_name :</span></dt><dd>WGS 84</dd><dt><span>horizontal_datum_name :</span></dt><dd>World Geodetic System 1984</dd><dt><span>projected_crs_name :</span></dt><dd>WGS 84 / UTM zone 30N</dd><dt><span>grid_mapping_name :</span></dt><dd>transverse_mercator</dd><dt><span>latitude_of_projection_origin :</span></dt><dd>0.0</dd><dt><span>longitude_of_central_meridian :</span></dt><dd>-3.0</dd><dt><span>false_easting :</span></dt><dd>500000.0</dd><dt><span>false_northing :</span></dt><dd>0.0</dd><dt><span>scale_factor_at_central_meridian :</span></dt><dd>0.9996</dd><dt><span>spatial_ref :</span></dt><dd>PROJCS[&quot;WGS 84 / UTM zone 30N&quot;,GEOGCS[&quot;WGS 84&quot;,DATUM[&quot;WGS_1984&quot;,SPHEROID[&quot;WGS 84&quot;,6378137,298.257223563,AUTHORITY[&quot;EPSG&quot;,&quot;7030&quot;]],AUTHORITY[&quot;EPSG&quot;,&quot;6326&quot;]],PRIMEM[&quot;Greenwich&quot;,0,AUTHORITY[&quot;EPSG&quot;,&quot;8901&quot;]],UNIT[&quot;degree&quot;,0.0174532925199433,AUTHORITY[&quot;EPSG&quot;,&quot;9122&quot;]],AUTHORITY[&quot;EPSG&quot;,&quot;4326&quot;]],PROJECTION[&quot;Transverse_Mercator&quot;],PARAMETER[&quot;latitude_of_origin&quot;,0],PARAMETER[&quot;central_meridian&quot;,-3],PARAMETER[&quot;scale_factor&quot;,0.9996],PARAMETER[&quot;false_easting&quot;,500000],PARAMETER[&quot;false_northing&quot;,0],UNIT[&quot;metre&quot;,1,AUTHORITY[&quot;EPSG&quot;,&quot;9001&quot;]],AXIS[&quot;Easting&quot;,EAST],AXIS[&quot;Northing&quot;,NORTH],AUTHORITY[&quot;EPSG&quot;,&quot;32630&quot;]]</dd><dt><span>GeoTransform :</span></dt><dd>570495.0 10.0 0.0 5987245.0 0.0 -10.0</dd></dl></div><div class='xr-var-data'><pre>array(0)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-ff92564d-a9c8-4f18-b9c0-fcd010ef8b17' class='xr-section-summary-in' type='checkbox'  ><label for='section-ff92564d-a9c8-4f18-b9c0-fcd010ef8b17' class='xr-section-summary' >Indexes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>band</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-caa4b580-cac7-4ad1-9f54-28d71115e7fd' class='xr-index-data-in' type='checkbox'/><label for='index-caa4b580-cac7-4ad1-9f54-28d71115e7fd' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([1, 2, 3], dtype=&#x27;int64&#x27;, name=&#x27;band&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>x</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-2eda02e2-dea1-4637-a8a7-a17fd34b99e7' class='xr-index-data-in' type='checkbox'/><label for='index-2eda02e2-dea1-4637-a8a7-a17fd34b99e7' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([570500.0, 570510.0, 570520.0, 570530.0, 570540.0, 570550.0, 570560.0,
       570570.0, 570580.0, 570590.0,
       ...
       609680.0, 609690.0, 609700.0, 609710.0, 609720.0, 609730.0, 609740.0,
       609750.0, 609760.0, 609770.0],
      dtype=&#x27;float64&#x27;, name=&#x27;x&#x27;, length=3928))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>y</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-78af9e25-93f6-4447-9ceb-463d67246759' class='xr-index-data-in' type='checkbox'/><label for='index-78af9e25-93f6-4447-9ceb-463d67246759' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([5987240.0, 5987230.0, 5987220.0, 5987210.0, 5987200.0, 5987190.0,
       5987180.0, 5987170.0, 5987160.0, 5987150.0,
       ...
       5937340.0, 5937330.0, 5937320.0, 5937310.0, 5937300.0, 5937290.0,
       5937280.0, 5937270.0, 5937260.0, 5937250.0],
      dtype=&#x27;float64&#x27;, name=&#x27;y&#x27;, length=5000))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-2c3bb07c-1811-4006-8e37-787635b0f28a' class='xr-section-summary-in' type='checkbox'  checked><label for='section-2c3bb07c-1811-4006-8e37-787635b0f28a' class='xr-section-summary' >Attributes: <span>(6)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>resolution :</span></dt><dd>10.0</dd><dt><span>spec :</span></dt><dd>RasterSpec(epsg=32630, bounds=(499980.0, 5890200.0, 609780.0, 6000000.0), resolutions_xy=(10.0, 10.0))</dd><dt><span>AREA_OR_POINT :</span></dt><dd>Area</dd><dt><span>scale_factor :</span></dt><dd>1.0</dd><dt><span>add_offset :</span></dt><dd>0.0</dd><dt><span>long_name :</span></dt><dd>stackstac-a59c0526e158aaff38198e5e514e7988</dd></dl></div></li></ul></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rds</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">robust</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.image.AxesImage at 0x7f9d8814aba0&gt;
</pre></div>
</div>
<img alt="../../../_images/71b50a1c47afbc82d6bdf9c753b61bd3daec105a0754efa51c060c82ad083120.png" src="../../../_images/71b50a1c47afbc82d6bdf9c753b61bd3daec105a0754efa51c060c82ad083120.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#cut out a 64x64 pixel window from the cog in sliding window fashion</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">rasterio</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">rasterio.windows</span><span class="w"> </span><span class="kn">import</span> <span class="n">Window</span>

<span class="n">imgs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">brightness</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># Open the COG</span>
<span class="k">with</span> <span class="n">rasterio</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">cog_url</span><span class="p">)</span> <span class="k">as</span> <span class="n">src</span><span class="p">:</span>
    <span class="c1"># Loop through the windows</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">5000</span><span class="o">//</span><span class="mi">32</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5000</span><span class="o">//</span><span class="mi">32</span><span class="p">):</span>
            <span class="n">window</span> <span class="o">=</span> <span class="n">Window</span><span class="p">(</span><span class="n">i</span><span class="o">*</span><span class="mi">64</span><span class="p">,</span> <span class="n">j</span><span class="o">*</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
            <span class="n">subset</span> <span class="o">=</span> <span class="n">src</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">window</span><span class="o">=</span><span class="n">window</span><span class="p">)</span>
            <span class="c1"># if subset.shape[1] == 64 and subset.shape[2] == 64:</span>
            <span class="c1">#     plt.imshow(subset.transpose(1,2,0)*brightness)</span>
            <span class="c1">#     plt.show()</span>

            <span class="n">img</span> <span class="o">=</span> <span class="n">subset</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">3</span><span class="p">):</span>
                <span class="n">imgs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

<span class="n">imgs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 156/156 [00:20&lt;00:00,  7.63it/s]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">((</span><span class="n">imgs</span><span class="p">[</span><span class="mi">200</span><span class="p">]</span><span class="o">+</span><span class="mf">0.3</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.image.AxesImage at 0x7f9d76580c20&gt;
</pre></div>
</div>
<img alt="../../../_images/05e09243a730356f31767ec9e6096b9bc9c8f9c6d3f708051ec648ba65dc58dc.png" src="../../../_images/05e09243a730356f31767ec9e6096b9bc9c8f9c6d3f708051ec648ba65dc58dc.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

<span class="c1"># Change to tensor</span>
<span class="n">imgs_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">imgs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Change data to (N, C, H, W) format</span>

<span class="c1"># Normalizing images</span>
<span class="n">normalised_imgs</span> <span class="o">=</span> <span class="p">(</span><span class="n">imgs</span><span class="o">-</span><span class="n">data_mean</span><span class="p">)</span><span class="o">/</span><span class="n">data_std</span>
<span class="n">normalised_imgs_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">normalised_imgs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># Change data to (N, C, H, W) format</span>


<span class="c1"># Get predictions from the VAE (assuming vae is your model name)</span>
<span class="n">vae</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">preds</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">vae</span><span class="p">(</span><span class="n">normalised_imgs_tensor</span><span class="p">)</span>  <span class="c1"># Change based on your model&#39;s output</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">preds</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>  <span class="c1"># Adjust shape if necessary based on output</span>

        <span class="c1"># predicted_img, _, _ = vae(val_tensor[i].unsqueeze(0).to(device))</span>


<span class="c1"># Calculate image-wise mean squared reconstruction error</span>
<span class="n">recon_err</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">normalised_imgs_tensor</span> <span class="o">-</span> <span class="n">preds</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="c1"># Detecting anomalies</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">35</span>
<span class="n">anomalies</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">recon_err</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="n">N</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">recon_err</span><span class="p">)</span>

<span class="c1"># Visualizing anomalies</span>
<span class="c1"># fig, ax = plt.subplots(1, N, figsize=(N, 5))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="n">anomaly_image</span> <span class="o">=</span> <span class="n">imgs_tensor</span><span class="p">[</span><span class="n">anomalies</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># CHW to HWC</span>
    <span class="n">unnormalise</span> <span class="o">=</span> <span class="n">anomaly_image</span> <span class="o">*</span> <span class="n">data_std</span> <span class="o">+</span> <span class="n">data_mean</span> <span class="c1"># Adjust this depending on your normalization</span>
    <span class="c1"># unnormalise = anomaly_image * data_std.reshape(3,1,1) + data_mean.reshape(3,1,1) # Adjust this depending on your normalization</span>
    <span class="c1"># unnormalise = unnormalise(anomaly_image)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">unnormalise</span><span class="o">*</span><span class="n">brightness</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># Clipping values to valid range for imshow</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="c1"># ax[i].imshow(np.clip(unnormalise, 0, 1))  # Clipping values to valid range for imshow</span>
    <span class="c1"># ax[i].axis(&#39;off&#39;)</span>
<span class="c1"># plt.show()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[6417.2866 6408.5244 7141.8467 ... 5969.232  5789.203  5928.8154]
</pre></div>
</div>
<img alt="../../../_images/461fb23af71c3daa9cd7b71877f6d9fa4e9614f0802a073d092faaeb157ee4b2.png" src="../../../_images/461fb23af71c3daa9cd7b71877f6d9fa4e9614f0802a073d092faaeb157ee4b2.png" />
<img alt="../../../_images/c5288c265b431712d408d5909462ae9ae02aa8e6fd4a4f9b4dca3f1bfda65d83.png" src="../../../_images/c5288c265b431712d408d5909462ae9ae02aa8e6fd4a4f9b4dca3f1bfda65d83.png" />
<img alt="../../../_images/486b06b49c8a945d5119445667cd6e6098a5e2a017cce5bad9999a9e46ae389c.png" src="../../../_images/486b06b49c8a945d5119445667cd6e6098a5e2a017cce5bad9999a9e46ae389c.png" />
<img alt="../../../_images/b550aac2ad9f2b4133710a61704073bbfd814c01f437e77fef9a299c9e5b440e.png" src="../../../_images/b550aac2ad9f2b4133710a61704073bbfd814c01f437e77fef9a299c9e5b440e.png" />
<img alt="../../../_images/9ebbc025daa0fd064d640015652f0a0655185f78f3e68804acb54d48cab9f6c2.png" src="../../../_images/9ebbc025daa0fd064d640015652f0a0655185f78f3e68804acb54d48cab9f6c2.png" />
<img alt="../../../_images/f7f4b53e1bd3724b708829cb5d15f9d1fba9d29383e0786e47914969fd0f4caf.png" src="../../../_images/f7f4b53e1bd3724b708829cb5d15f9d1fba9d29383e0786e47914969fd0f4caf.png" />
<img alt="../../../_images/b0eea24580afeee42002184e12e475e6d8676e48c3e9f5d499856744b737c4e9.png" src="../../../_images/b0eea24580afeee42002184e12e475e6d8676e48c3e9f5d499856744b737c4e9.png" />
<img alt="../../../_images/dc3754797079079c20ab8a6b104b5d11699cc8f18385e01734218e2affd6201f.png" src="../../../_images/dc3754797079079c20ab8a6b104b5d11699cc8f18385e01734218e2affd6201f.png" />
<img alt="../../../_images/88d4a847a921e3def2efde6af89d554de753061e70058ec3bd21efe4c1716870.png" src="../../../_images/88d4a847a921e3def2efde6af89d554de753061e70058ec3bd21efe4c1716870.png" />
<img alt="../../../_images/340acda64760a7abde3014628c620d6102438c5dccc0362910a9773a06b5c619.png" src="../../../_images/340acda64760a7abde3014628c620d6102438c5dccc0362910a9773a06b5c619.png" />
<img alt="../../../_images/6b5d564405b381cb6f5ddeb3bee887b37e19f68f29abf13e0e29f9ba2adf9d2e.png" src="../../../_images/6b5d564405b381cb6f5ddeb3bee887b37e19f68f29abf13e0e29f9ba2adf9d2e.png" />
<img alt="../../../_images/9d78b399f1555bfd7f16a95ec09416e1e9ba0c75a95fc708c63fb55840f01c10.png" src="../../../_images/9d78b399f1555bfd7f16a95ec09416e1e9ba0c75a95fc708c63fb55840f01c10.png" />
<img alt="../../../_images/0058723f0fc6de3b106a6acd823d3c8a9441fc4dffde4da1f79126e32f277489.png" src="../../../_images/0058723f0fc6de3b106a6acd823d3c8a9441fc4dffde4da1f79126e32f277489.png" />
<img alt="../../../_images/928c81d4ae4815bb263bcc5f45a2fd1dda24beb5e8719aa00b7282855ff59e8f.png" src="../../../_images/928c81d4ae4815bb263bcc5f45a2fd1dda24beb5e8719aa00b7282855ff59e8f.png" />
<img alt="../../../_images/cb550a2d2cc537dfe02e21e8efd1d04024f971f9cc55ad98a367b328d1f4f763.png" src="../../../_images/cb550a2d2cc537dfe02e21e8efd1d04024f971f9cc55ad98a367b328d1f4f763.png" />
<img alt="../../../_images/6f587b389f08f6ec481fa22cdf39ef6c251d738697c2ce9ff3d67ac54a73bfe8.png" src="../../../_images/6f587b389f08f6ec481fa22cdf39ef6c251d738697c2ce9ff3d67ac54a73bfe8.png" />
<img alt="../../../_images/7b8cc888aef1739b566a48c26cc1efec8a699548aaa6408af0976edd4ba0d371.png" src="../../../_images/7b8cc888aef1739b566a48c26cc1efec8a699548aaa6408af0976edd4ba0d371.png" />
<img alt="../../../_images/df10a2f97bbd1a185085e5eea9028c18719280916c8c9365f80325302c4c1336.png" src="../../../_images/df10a2f97bbd1a185085e5eea9028c18719280916c8c9365f80325302c4c1336.png" />
<img alt="../../../_images/646a257cc686a62e59b9f7482033f58dcf9d06163b4d6508751e7dd84392e2ea.png" src="../../../_images/646a257cc686a62e59b9f7482033f58dcf9d06163b4d6508751e7dd84392e2ea.png" />
<img alt="../../../_images/787ad2528729fccb146e7e11415b992fa67c4ceb2a690df193265dd9e50084e0.png" src="../../../_images/787ad2528729fccb146e7e11415b992fa67c4ceb2a690df193265dd9e50084e0.png" />
<img alt="../../../_images/eeb955c5f3e3b1790ea8f4d58fc0fefba3ca03fe93e80279b18bdeb8b6043c5f.png" src="../../../_images/eeb955c5f3e3b1790ea8f4d58fc0fefba3ca03fe93e80279b18bdeb8b6043c5f.png" />
<img alt="../../../_images/6d42f2a9217d211d36ff49508a41b09f63219cdd33168999d2854f274d6ff77e.png" src="../../../_images/6d42f2a9217d211d36ff49508a41b09f63219cdd33168999d2854f274d6ff77e.png" />
<img alt="../../../_images/7608b8118b6069b130f2c5b36f2921e2693c58618583715bb46010bc35ee5ece.png" src="../../../_images/7608b8118b6069b130f2c5b36f2921e2693c58618583715bb46010bc35ee5ece.png" />
<img alt="../../../_images/329808d2c7400ddf384686b7ac440e99505b93e9897ecae93c6e60c0852c7055.png" src="../../../_images/329808d2c7400ddf384686b7ac440e99505b93e9897ecae93c6e60c0852c7055.png" />
<img alt="../../../_images/2819146266be9bb3420cbd9b9fa64b1781f48c906127461781bd60328d9fcad0.png" src="../../../_images/2819146266be9bb3420cbd9b9fa64b1781f48c906127461781bd60328d9fcad0.png" />
<img alt="../../../_images/441bdfac6cc0edaaed3a851a188b15ad439d935b51c74cdf037cb530e42b2120.png" src="../../../_images/441bdfac6cc0edaaed3a851a188b15ad439d935b51c74cdf037cb530e42b2120.png" />
<img alt="../../../_images/876199b4cb8eae5a188a46941222dcf001179e6985cc47945a20905cbe094156.png" src="../../../_images/876199b4cb8eae5a188a46941222dcf001179e6985cc47945a20905cbe094156.png" />
<img alt="../../../_images/76d61271b1bbb9eaa3154867d1c83e8a464730594bea7df1c840cdf6675b233e.png" src="../../../_images/76d61271b1bbb9eaa3154867d1c83e8a464730594bea7df1c840cdf6675b233e.png" />
<img alt="../../../_images/9ee3a48f83380ac3a9e6afc5d63295e14443c7d730e2b35e9882b72d7cd3c143.png" src="../../../_images/9ee3a48f83380ac3a9e6afc5d63295e14443c7d730e2b35e9882b72d7cd3c143.png" />
<img alt="../../../_images/1f3a423b904e12186c1fc08ba5ed0baacbe016bfde1109b14a7d70b338074aaf.png" src="../../../_images/1f3a423b904e12186c1fc08ba5ed0baacbe016bfde1109b14a7d70b338074aaf.png" />
<img alt="../../../_images/b3d8a7e0be1748604ebeb4ce08b966157e26b0c72f07feba2385fb9e58f042f0.png" src="../../../_images/b3d8a7e0be1748604ebeb4ce08b966157e26b0c72f07feba2385fb9e58f042f0.png" />
<img alt="../../../_images/59e8c72da25b8d9d4d1e0f7803f32b484e8b2eed20a70acecb3e7e47cbe6ef33.png" src="../../../_images/59e8c72da25b8d9d4d1e0f7803f32b484e8b2eed20a70acecb3e7e47cbe6ef33.png" />
<img alt="../../../_images/1ae4e30663dd582b46a2821f54a6c85a7f76c244ebc7d1e1b98ca464df173949.png" src="../../../_images/1ae4e30663dd582b46a2821f54a6c85a7f76c244ebc7d1e1b98ca464df173949.png" />
<img alt="../../../_images/1ae4e30663dd582b46a2821f54a6c85a7f76c244ebc7d1e1b98ca464df173949.png" src="../../../_images/1ae4e30663dd582b46a2821f54a6c85a7f76c244ebc7d1e1b98ca464df173949.png" />
<img alt="../../../_images/1ae4e30663dd582b46a2821f54a6c85a7f76c244ebc7d1e1b98ca464df173949.png" src="../../../_images/1ae4e30663dd582b46a2821f54a6c85a7f76c244ebc7d1e1b98ca464df173949.png" />
</div>
</div>
<p><a name="stretchgoals"></a></p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="pushing-autoencoders-further">
<h1>Pushing autoencoders further<a class="headerlink" href="#pushing-autoencoders-further" title="Link to this heading">#</a></h1>
<ol class="arabic simple">
<li><p>Change the training data to explore new uses for the autoencoder</p></li>
</ol>
<ul class="simple">
<li><p>create a summer to winter image converter. See <a class="reference external" href="https://github.com/sciml-leeds/SENSE_training/blob/main/download_ae_data.ipynb"><strong>download script here</strong></a>.</p></li>
<li><p>create an image denoiser</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Use the VAE as a GCM</p></li>
</ol>
<ul class="simple">
<li><p><a class="reference external" href="https://brohan.org/ML_GCM/">(inspired by this work)</a></p></li>
<li><p>train VAE on weather data where x is atmosphere at <span class="math notranslate nohighlight">\(t\)</span>, and y is atmosphere at <span class="math notranslate nohighlight">\(t+6\)</span> hours</p></li>
<li><p>run the VAE predictor repeatedly to produce a GCM forecast model</p></li>
<li><p><a class="reference external" href="https://github.com/sciml-leeds/SENSE_training/blob/main/download_autoencode_gcm_data.ipynb"><strong>See example notebook here</strong></a></p></li>
</ul>
<ol class="arabic simple" start="3">
<li><p>Detect natural anomalies using the VAE</p></li>
</ol>
<ul class="simple">
<li><p>see papers eg <a class="reference external" href="https://hal.science/hal-02318407/document">eg. detecting avalanches</a>.</p></li>
</ul>
<ol class="arabic simple" start="4">
<li><p>Use the VAE for further semi-supervised learning experiments</p></li>
</ol>
<ul class="simple">
<li><p>initialise the VAE without training</p></li>
<li><p>use the VAE decoder and using <span class="math notranslate nohighlight">\(x\)</span> as your image patches and <span class="math notranslate nohighlight">\(y\)</span> as your class labels, train a model to discriminate between leeds and edinburgh patches (store the results)</p></li>
<li><p>initialise the VAE again, and train the autoencoder where <span class="math notranslate nohighlight">\(x\)</span>=<span class="math notranslate nohighlight">\(y\)</span>. Then take the VAE decoder only and train again to fine-tune to discriminate between leeds and edinburgh patches. What’s the difference in the accuracy?</p></li>
</ul>
<ol class="arabic simple" start="5">
<li><p>Explore the latent space in new ways</p></li>
</ol>
<ul class="simple">
<li><p>define a starting patch, and a target patch. Find the real images that are the stepping stones on a path in the latent space from the start to the target patch. Plot your results to see the journey from ‘car park’ to ‘beach’ eg. <a class="reference external" href="https://ermongroup.github.io/blog/public/img/blog/tile2vec/latent.png">tile2vec latent space exploration</a>.</p></li>
</ul>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./book/3_ml4eo/3_sat_ml_deep"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Autoencoders</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#table-of-contents">Table of contents<font><a class="anchor" id="top"></a></font></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#download-data">Download data</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#preparing-the-data">Preparing the data</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#training-the-autoencoder">Training the autoencoder</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#variational-autoencoder">Variational Autoencoder</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#semi-supervised-learning">Semi-supervised learning</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#autoencoder-treasure-hunt">Autoencoder treasure hunt</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#pushing-autoencoders-further">Pushing autoencoders further</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By SENSE CDT
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>